{"pages":[{"title":"关于本站","text":"我是Oxine, 此站点是基于Hexo+GithubPages搭建的个人博客, 主题是icarus。 2020-8-19 升级到hexo5.0 &amp; icarus4.0.0 2020-8-18 绑定域名 2020-3 魔改样式，自定义font-matter与codeblock的初始行号和diff功能 2020-2 建站","link":"/about/index.html"}],"posts":[{"title":"点到直线最短距离","text":"问题描述:对于三维空间中的直线方程 $p(t) = o + t\\vec{d}$ 其中$o$是原点, $\\vec{d}$是单位方向向量。 对于给定的点$q$, 求出t的值, 使得直线上的点$p^\\prime=p(t)$到$q$点的距离最近。 问题分析:其实我们都知道点到直线垂线最短, 所以垂线与直线的交点即为所求: 如图, 因为$\\vec{d}$为单位向量, 这里所求的t即为点$p^\\prime$到射线原点$o$的距离, 也正是向量$q-o$在向量$\\vec{d}$上的投影, 我们可用$\\cos\\theta|q-o|$表示($\\theta$为$q-o$与$\\vec{d}$的夹角)。 再次因为$\\vec{d}$为单位向量,$|\\vec{d}|=1$ 有: $t=\\cos\\theta|q-o|=\\cos\\theta|q-o||\\vec{d}|=(q-o)\\cdot\\vec{d}$ 当d不为单位向量时, 还需要除去d向量的长度 $t=\\cos\\theta|q-o|=\\frac{\\cos\\theta|q-o||\\vec{d}|}{|\\vec{d}|}=\\frac{(q-o)\\cdot\\vec{d}}{|\\vec{d}|}$ 求出位置参数p后, 回代至对应的直线方程即可求出目标点$p^\\prime=p(t)$ 最后, 对于线段来说, 假设线段的起点为$t0$, 终点为$t1$。当求出的参数$t&lt;t0$时, 则端点$t0$即为所求。当$t&gt;t1$时, 则端点$t1$即为所求。 示例代码:ray.cpp123456789101112131415161718vec3 cloest_point_on_ray(const ray r,const vec3 p)const { float t = dot(p-r.origin(),r.direction()); if (t &lt; t0) return point_on_ray(t0); if (t &gt; t1) return point_on_ray(t1); return point_on_ray(t);}float cloest_distant_to_ray(const ray r,const vec3 p)const { float t = dot(p - r.origin(), r.direction()); if (t &lt; t0) return (p - point_on_ray(t0)).length; if (t &gt; t1) return (p - point_on_ray(t1)).length; return (p - point_on_ray(t)).length; //or simply return (p - cloest_point_on_ray(r, p)).length} reference:3D Math Primer for Graphics and Game Development, 2nd Edition 我画的图好丑啊!TAT凑合着看吧","link":"/Math/Geometry/closest-point-on-line/"},{"title":"开启git对文件名的大小写敏感","text":"git默认是不不开始文件名的大小写敏感的, 当你在上传文件时, 如果你修改了文件名的大小写, git会认为你并没有进行修改 我是在做github pages时修改文件名大小写,发现url无法定位到文件导致404时发现git的这个默认设置的 解决方法如下 打开你的git bash, cd到目标git仓库后, 键入以下指令来开启git对该仓库下文件名的大小写敏感 1$ git config core.ignorecase false 或者在任意目录修改全局设置 1$ git config --global core.ignorecase false 这样你所有的仓库都会开启大小写敏感了, 一劳永逸当然还有一种方法, 先删除文件, push, 再添加文件, push 这种方法太暴力不做推荐最后提一下, git之所以默认不开启文件名的大小写敏感, 可能是在跟随文件系统。因为我使用的windows系统是文件名大小写不敏感的, 如果git允许A.txt与a.txt同时存在, windows的文件系统却认为他们是一个文件,不允许他们共存, 便产生了冲突。相比之下, linux的文件系统的大小写是敏感的, 便又是另一幅光景了。 以下内容截取自git官方文档 core.ignoreCaseInternal variable which enables various workarounds to enable Git to work better on filesystems that are not case sensitive, like APFS, HFS+, FAT, NTFS, etc. For example, if a directory listing finds “makefile” when Git expects “Makefile”, Git will assume it is really the same file, and continue to remember it as “Makefile”.The default is false, except git-clone[1] or git-init[1] will probe and set core.ignoreCase true if appropriate when the repository is created.Git relies on the proper configuration of this variable for your operating and file system. Modifying this value may result in unexpected behavior. reference https://git-scm.com/docs/git-config","link":"/Git/git-ignorecase/"},{"title":"hexo 自定义 front matter, 并通过其控制评论与分享功能的开关","text":"[随着hexo5.0.0 以及icarus4.0的发布，该页面已失效，现在用户可以直接通过以下方法控制] 12share: true //是否打开文章分享? 不填写或删除此行默认打开comments: true //是否打开文章评论? 不填写或删除此行默认打开 在写文章的时候, 有时候希望关闭一些文章的评论和分享功能。那么如何自定义文章评论与分享功能的开启与否呢? 我们需要对主题稍作修改, 我的主题是icarus, 得益于作者优秀的编码习惯, 修改起来十分的方便 注: 不同主题修改的方式不同， 如next主题下, front matter的自定义配置文件在next\\scripts\\filters\\front-matter.js, 整个修改过程也是大相径庭, 基本上所有主题已经完成了一些自定义的front—mattter变量, 我们需要做的就Ctrl+F找到该变量, 然后依样画葫芦 修改打开主题下icarus\\includes\\specs\\article.spec.js, 添加变量 article.spec.js12345678910share: { [type]: 'boolean', [doc]: 'share or not', [defaultValue]: true},// don't forget the commacomment: { [type]: 'boolean', [doc]: 'comment or not', [defaultValue]: true} 打开文章样式文件icarus\\layout\\common\\article.ejs, Ctrl+F 找到以下位置, 并修改 article.ejs first_line:74 diff1234567891011121314-&lt;% if (!index &amp;&amp; has_config('share.type')) { %&gt;+&lt;% if (!index &amp;&amp; has_config('share.type') &amp;&amp; get_config('article.readtime') == true) { %&gt; &lt;%- _partial('share/' + get_config('share.type')) %&gt; &lt;% } %&gt;-&lt;% if (!index &amp;&amp; has_config('comment.type')) { %&gt;+&lt;% if (!index &amp;&amp; has_config('comment.type') &amp;&amp; get_config('article.comment') == true ) { %&gt;&lt;div class=&quot;card&quot;&gt; &lt;div class=&quot;card-content&quot;&gt; &lt;h3 class=&quot;title is-5 has-text-weight-normal&quot;&gt;&lt;%= __('article.comments') %&gt;&lt;/h3&gt; &lt;%- _partial('comment/' + get_config('comment.type')) %&gt; &lt;/div&gt;&lt;/div&gt;&lt;% } %&gt; 使用在文章的font-matter处进行设置, 以本篇文章为例 hexo-costum-frontmatter.md123456789101112---title: hexo 自定义 front matter, 并通过其控制评论与分享功能的开关date: 2020-02-28 19:05:44category:- Web- FrontEndtags:- hexothumbnail: falseshare: true //是否打开文章分享? 不填写或删除此行默认打开comment: true //是否打开文章评论? 不填写或删除此行默认打开---","link":"/Web/FrontEnd/hexo-costum-front-matter/"},{"title":"判断射线与是否球体相交, 并计算交点位置","text":"在Ray-tracing中, 计算并判断射线与球体是否相交是不可少的那么如何来判断一条已知的射线是否交于给定的球体呢?要计算球体射线交点，我们首先要先给出球与直线的方程 首先是球面方程 $$|x-c|^2=r^2$$ x为球面上的点 c为球心 r为球的半径 然后是直线方程 $$x = o +dl$$ x为直线上的点 o为直线起点 d为交点到原点的距离(一个标量) l为射线方向的单位向量 相信方程都很清晰明了，那下面我们要做的就是通过上述两个式子中共有的 X 将方程联立起来 联立，得 $$|o+dl-c|^2=r^2$$ 展开，得 $$d^2l^2+2dl(o-c)+(o-c)^2=r^2$$ 整理，得 $$l^2d^2+2l(o-c)d+(o-c)^2-r^2=0$$ 这时我们便得到了一个关于d的二元一次方程, 不难看出判别式$$\\Delta=B^2-4AC$$其中:$$A=l^2$$$$B=2l*(0-c)$$$$C=(o-c)^2-r^2$$ 根据其解的个数, 我们便能判断射线与球体的相交情况了 根的判别式Δ 交点个数 相交情况 &lt;0 0 直线与球无交点 =0 1 直线与球相切 0 | 2 | 直线传过球体 此时我们根据求根公式, 便能快速算出d的值, 再通过射线的方程$$x=o+dl$$便可求出其交点 一个c++风格的 判断直线与球是否相交的代码实现如下 123456789101112//Line–sphere intersectionbool hit_sphere(const vec3&amp; center, float radius, const ray&amp; r) { vec3 oc = r.Origin() - center; float a = dot(r.Direction(), r.Direction());//2 float b = 2.0f * dot(r.Direction(), oc); float c = dot(oc, oc) - radius*radius; float discriminate = b * b - 4 * a * c; if (discriminate &lt; 0) return false; else return ( - b - sqrtf(discriminate)) /( 2.0f * a)&gt;0;//1} 1 注意, 射线(ray)和直线(line)的区别, 射线是有其方向的, 直线方程的解不一定符合射线, 我们需要将负解舍去 2 r.Direction() 即上述公式中的 L , 其实并不需要一定是单位向量, 只要保证其正负与单位向量一致即可 如果在绘制球体的过程, 需要求出交点的具体位置, 比如根据球面法相来输出像素颜色(将三维向量直接作为颜色输出, 在调试你的程序时是十分常用的), 那么上面的代码就不太够看了, 我们对其略做修改 123456789101112131415161718//Line–sphere intersectionfloat hit_sphere(const vec3&amp; center, float radius, const ray&amp; r) { vec3 oc = r.Origin() - center; float a = dot(r.Direction(), r.Direction());//3 float b = dot(r.Direction(), oc);//1 float c = dot(oc, oc) - radius*radius; float discriminate = b * b - a * c;//1 if (discriminate &lt; 0) return -1.0f; else return ( - b - sqrtf(discriminate)) / a;//1,2}//some code that get normalRay r;...d = hit_sphere(center, radius, r);vec3 normal = Normalize(r.Origin() + r.Direction() * d - center); 1 这里其实可以化简, 判别式上下同时消掉了一个2 2 根据求根公式, 我们会得到两个根, 求交点时, 我们选取较小的根d, 即离射线原点(往往是camera)较近的那个点 3 根据RayTracingInOneWeekend书中的代码, 这里的r.Direction()仍不需一定为单位向量, 只要在后续计算中保持公式 x = r + dl 的一致便仍能得出正确的交点, 读者可自行根据上述公式进行验算。但我个人认为如wikipedia中, 在一开始将Ray类中的方向向量初始化为单位向量会比较方便, 避免一些忘记手动Normalize而导致的潜在的bug 一个初始化的例子 1234Ray(const vec3&amp; origin, const vec3&amp; dir){ ... this-&gt;dir = dir.Normalize();} reference： https://en.wikipedia.org/wiki/Line-sphere_intersectionhttps://raytracing.github.io/books/RayTracingInOneWeekend.html","link":"/Math/Geometry/line-sphere-intersection/"},{"title":"投影矩阵之十万个为什么","text":"part1. 关于概念什么是投影矩阵？投影矩阵是一个4x4齐次矩阵，将点从观察空间(viewing/eye/camera space)变换到裁剪空间(cliping space)（或者理解成空间的变换，这两者本质是一样的） 正交投影与透视投影的区别？由视锥体(frustum)变换到裁剪空间。正交投影是由一个cube变换到裁剪空间。我们这里不讨论正交投影。 什么是裁剪空间？一个四维的齐次空间，从几何上来看还是个视锥，但请不要用看待普通三维空间的方法去看这个空间！它具有一定的拓扑性质。对于透视投影来说，该空间下的点，其w分量有着特殊的意义（其实就是观察空间中的点的深度值$Z_e$，一会儿我们会提到）。 为什么叫裁剪空间？怎么裁剪 因为从视锥体映射到NDC，即x/w,y/w,z/w的值都从原来所在的观察空间被映射到了一个边长为2中心点位于原点的立方体中。所以此时x/w&lt;1 。在divide by w之前，我们可以根据w值直接进行剔除。即$abs(x)&lt;w$，$abs(y)&lt;w$，$abs(z)&lt;w$，不满足条件的点discard，并在裁剪边界生成新的顶点，更新索引，插值得到新顶点attribute的信息(如uv normal color)。但其实这样很慢。据说现代引擎不这样裁剪，而是细分离屏幕近的三角形，然后直接discard三角形。 刚刚提到的divide by w是什么？顾名思义，裁剪空间下的点(x,y,z,w)除以其w分量就能得到其在NDC下的坐标，我们称这步为透视除法，或者divide by w。 NDC是什么？Normalized device coordinates(NDC), 一个立方体where$x\\in[-1,1],y\\in[-1,1],z\\in[-1,1]$ 为什么裁剪空间下的点除以其w分量就能得到在NDC下的坐标？这个是设计上的原因，也正是齐次坐标系的定义与性质。详见part3 NDC是线性空间么？为什么？不是的。其z分量与$1/W_{clip}$（1/Ze）成线性关系。观察空间是最后的线性空间。详见part3 GL与DX中投影矩阵的区别？GL中变换到[-1,1]（摄像机z=-1），而DX中变换到[0,1]（可以理解为只用了NDC的一半，摄像机z=0），于是导致了系数是两倍的关系，另外因为dx使用左手系而gl右手系，而NDC统一为左手系。gl中的z变换会比dx多个符号。详见下面矩阵的推导。有趣的是，因为dx使用行矩阵表示向量，并使用列优先存储矩阵，GL使用列矩阵表示向量并使用行优先存储矩阵，导致虽然完成同一个变换的矩阵在数学表示为互为转置，但在GL与DX的矩阵存储中，元素的顺序却是完全一样的。 什么是齐次矩阵（homogeneous matrix）？为什么要引入齐次矩阵？/ 什么是仿射变换？如何理解？齐次矩阵或者齐次空间，就是原来n维矩阵拓展到n+1维。这里的齐次指的是(x,y,1)与(2x,2y,2)都能表示(x,y)的这种性质。仿射变换是高纬度的线性变换，或者说是低纬度平移与其他线性变换的组合。当我们添加了一个维度，我们就可以在高纬度中使用线性变换来表示低维度中非线性的变换（说的就是你，平移）。使用齐次矩阵，有两个好处（或者说不得不使用的原因）， 首先是为了能在一个四维空间中将平移表示为线性（即可以写出矩阵乘法的形式u = Tv）。本质是为了方便计算，没有平移这种非线性变换（u = Tv + w），就没有加法，就可以使用矩阵的连乘从头乘到尾。这样一个4x4的齐次矩阵就能够表示三维空间下的一个任意的变换了。 第二个原因是，其次坐标的w分量可以表示向量与点的区别，w=0为向量，w!=0为点。大家可以思考向量与点加法或乘法的排列组合，其得到的结果也是正确的。并且我们认为，在齐次坐标下，（x,y,z,w）与（x/w,y/w,z/w,1）是同一个点（这便是divide by w的原理，详见part3）。齐次坐标下的点在z=infinity处翻转，（0,0,0,0）无意义。 为什么高纬度的仿射变换能表示低纬度的线性加平移变换？https://en.wikipedia.org/wiki/Affine_transformation 这里有不错的动图方便理解。https://www.zhihu.com/question/20666664/answer/157400568 这里有不错的讲解。 part2. 关于那些让人头大的左左右右左手系与右手系的区别？使用左手定则与右手定则建系的区别。对于固定的x轴y轴，这两个系的z轴相反。 叉乘方向收到左右手系的影响么？右手系使用右手螺旋定则，左手系使用左手螺旋定则。其实数学运算上的结果一样，cross(x,y) = z。 行矩阵表示向量，列矩阵表示向量与坐标系的选择的关系？没有关系。你可以选择任意的坐标系配合任意的矩阵向量表示法。 行矩阵表示向量、列矩阵表示向量与左乘、右乘的关系？使用行向量一律搭配右乘，行向量在矩阵乘法的最左边。其右乘矩阵的列用来表示向量（或者说构成线性空间，构成一个线性变换等等）。列向量一律搭配左乘，行向量在矩阵乘法的最右边，其左乘矩阵的行用来表示向量。这是由线性代数的法则决定的。一个简单的例子：使用矩阵乘法计算向量dot，我们希望得到一个数。在左乘与列向量中是$V^TV$而在右乘与行向量中是$UU^T$，其中$V=U^T$。表示同一个变换的矩阵（3x3线性也好，4x4仿射也好），在这两个不同的模式下，对应的两个矩阵互为转置。 part3. 关于矩阵的推导投影矩阵是怎么来的？能带着我推一下么？终于到了本文的重点了。其实有不少的思路可以推到这个矩阵，但是万变不离其宗， $$ \\begin{bmatrix} X_{clip}\\\\ Y_{clip} \\\\ Z_{clip} \\\\ W_{clip} \\end{bmatrix}=M_{projection} \\begin{bmatrix} X_{eye} \\\\ Y_{eye} \\\\ Z_{eye} \\\\ 1 \\end{bmatrix}$$ 首先我们把视锥压到一个方盒子，有 $X_{o}= \\frac{nX_{eye}}{-Z_{eye}}$ $Y_{o}= \\frac{nY_{eye}}{-Z_{eye}}$ 然后再从这个方盒子映射到NDC，x由[l,r]映射到[-1,1], y由[t,b]映射到[-1,1]。 显然这是一个线性变换。 $X_{ndc}=-1 + \\frac{(1-(-1))(X_o-l)}{r-l}$ 带入上述的式子，化简有 $X_{ndc} = \\frac{\\frac{2n}{r-l}\\cdot X_{eye}+\\frac{r+l}{r-l}\\cdot X_{eye}}{-Z_{eye}}$ 同理，有 $Y_{ndc} = \\frac{\\frac{2n}{r-l}\\cdot Y_{eye}+\\frac{r+l}{r-l}\\cdot Y_{eye}}{-Z_{eye}}$ 我们知道裁剪空间下除以w分量就能得到ndc。这步也称为divide by w $$ \\begin{bmatrix} X_{ndc}\\\\ Y_{ndc} \\\\ Z_{ndc} \\\\ \\end{bmatrix}= \\begin{bmatrix} X_{clip}/ W_{clip}\\\\ Y_{clip}/ W_{clip}\\\\ Z_{clip}/ W_{clip} \\\\ \\end{bmatrix}$$ 我们观察到$X_{ndc} = \\frac{\\frac{2n}{r-l}\\cdot X_{eye}+\\frac{r+l}{r-l}\\cdot X_{eye}}{-Z_{eye}}$, 于是我们不妨就设分母为$W_{clip}=-Z_{eye}$, 分子为$\\frac{2n}{r-l}\\cdot X_{eye}+\\frac{r+l}{r-l}\\cdot X_{eye}$，这样就能根据线性运算的关系写出矩阵的第一，三，四行了 $$ \\begin{bmatrix} X_{clip}\\\\ Y_{clip} \\\\ Z_{clip} \\\\ W_{clip} \\end{bmatrix}= \\begin{bmatrix} \\frac{2n}{r-l} &amp; 0 &amp; \\frac{r+l}{r-l} &amp; 0\\\\ 0 &amp; \\frac{2n}{t-b} &amp; \\frac{t+b}{t-b} &amp; 0 \\\\ ? &amp; ? &amp; ? &amp; ?\\\\ 0 &amp; 0 &amp; -1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} X_{eye} \\\\ Y_{eye} \\\\ Z_{eye} \\\\ 1 \\end{bmatrix}$$ 又加上我们知道$Z_{clip}$的值是与$X_{eye}$，$Y_{eye}$无关的(物体的xy并不会影响到它的深度)，所以我们可以设第三行为如下: $$ \\begin{bmatrix} X_{clip}\\\\ Y_{clip} \\\\ Z_{clip} \\\\ W_{clip} \\end{bmatrix}= \\begin{bmatrix} \\frac{2n}{r-l} &amp; 0 &amp; \\frac{r+l}{r-l} &amp; 0\\\\ 0 &amp; \\frac{2n}{t-b} &amp; \\frac{t+b}{t-b} &amp; 0 \\\\ 0 &amp; 0 &amp; A &amp; B\\\\ 0 &amp; 0 &amp; -1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} X_{eye} \\\\ Y_{eye} \\\\ Z_{eye} \\\\ 1 \\end{bmatrix}$$ 根据矩阵的运算法则，有 $Z_{ndc} = \\frac{AZ_{eye}+B}{-Z_{eye}}$ 再加上我们知道对于z值来说，从eye空间到ndc实际上是由[n,f]映射到了[-1,1] $$\\begin{cases}\\frac{-An+B}{n}=-1\\\\\\frac{-Af+B}{f}=1\\end{cases}$$ 联立解得: $$\\begin{cases}A=-\\frac{f+n}{f-n}\\\\B=-\\frac{2fn}{f-n}\\end{cases}$$ 于是我们终于得到了这个投影矩阵 $$M_{projection}= \\begin{bmatrix} \\frac{2n}{r-l} &amp; 0 &amp; \\frac{r+l}{r-l} &amp; 0\\\\ 0 &amp; \\frac{2n}{t-b} &amp; \\frac{t+b}{t-b} &amp; 0 \\\\ 0 &amp; 0 &amp; -\\frac{f+n}{f-n} &amp;-\\frac{2fn}{f-n}\\\\ 0 &amp; 0 &amp; -1 &amp; 0 \\end{bmatrix}$$ 一般情况下，视锥的左右和上下边界是等距的，即$r=-l,t=-b$ 于是上面的矩阵可以简化成 $$M_{projection}= \\begin{bmatrix} \\frac{n}{r} &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; \\frac{n}{t} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; -\\frac{f+n}{f-n} &amp;-\\frac{2fn}{f-n}\\\\ 0 &amp; 0 &amp; -1 &amp; 0 \\end{bmatrix}$$ 这便是OpenGL中的投影矩阵了。 上面那是OpenGL的啊，能推一下Dx的么？好的没问题。注意DirectX和OpenGL有三个区别: 左右手系不同，所以$W_{clip}=+Z_{eye}$ NDC的z取值范围不同，DirectX只用一般z，映射到[0,1]而不是[-1,1] 行向量列向量与左乘右乘的区别，在书写时，DirectX的投影矩阵应为OpenGL的转置。 推导过程和刚刚一模一样，注意区别就行了，最终的结果为 $$M_{DirectX}= \\begin{bmatrix} \\frac{n}{r} &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; \\frac{n}{t} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{f}{f-n} &amp;-\\frac{2fn}{f-n}\\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\end{bmatrix}^T$$ 为什么说观察空间是最后的线性空间？NDC中还能使用线性插值么？在搞清楚这个之前，我们先要知道什么是线性插值。 什么是线性插值？如果说对于给定的点v0,v1,对于给定的参数t,vt的值能表示为如下的形式: $v_t = v_0(1-t) + v_1t$ 那么我们称v满足关于参数t的线性插值。 我们回过头来，我们知道 $Z_{ndc} = \\frac{AZ_{eye}+B}{-Z_{eye}}$ 为什么我看不懂我的草稿了。。[To be fixed] 那么如何在NDC中插值呢？需要做一个校正，很简单，关于属性插值有机会我专门写一篇。 如何避免因非线性映射所导致的精度问题？1.对于摄像机来说，使用一个较小znear到zfar的范围2.映射到$[1,0]$而不是$[0,1]$(由浮点数的存储方式所决定的) 我还有别的问题请在评论区留言。 reference:http://www.songho.ca/opengl/gl_projectionmatrix.htmlJim Blinn’s Corner: A Trip Down the Graphics PipelineRiesenfeld. (1981). Homogeneous Coordinates and Projective Planes in Computer Graphics. IEEE Computer Graphics and Applications, 1(1), 50–55.","link":"/Math/projection-matrix/"},{"title":"Ray tracing in one weekend 疑难点解析与拓展","text":"《Ray tracing in one weekend》(一周末搞定光线追踪), 由Peter Shirley所编写的的软渲光追三部曲第一本, 是一本非常好的入门级书籍, 篇幅不多, 一共只有54页, 适合新手学习。 剩下的两本为:Ray tracing: The next week(光线追踪: 下一周)Ray tracing: The rest of your life(光线追踪: 余生) 作者已将本书免费发布到公共领域(cc0协议), 点击这里在线阅读本书 本文将解析书中的一些疑难点, 并对原有的程序稍作修改 有时间的话, 可能会考虑来做个全书翻译翻完啦 1 Overview2 Output an Image作者虽然在本书使用PPM格式来输出图片, 但在本章最后他提到自己对stb_image.h的喜爱, 那我们就顺水推舟, 不妨使用这个常用的图像库把颜色信息储存为更加便于查看的jpg格式。 stb_image.h, stb_image_write.h等是由C语言编写的类库文件,遵从MIT协议开源协议(stb是作者Sean T. Barrett名字的缩写)。我们这里使用stb来将数据写入文件,并不需要读取, 所以仅需要导入stb_image_write.h即可, 点击这里下载 下载完成后将其导入你的项目 1#include &quot;stb_image_write.h&quot; 为我们的图像分配空间 1unsigned char* data = new unsigned char[x * y * 3]; 然后将颜色信息写入 12345678for (int j = 0; j &lt;y; j++) for (int i = 0; i &lt; x; i++) { vec3 col = ......; data[(y - j - 1)*x * 3 + i * 3] = unsigned char(255.99f * col[0]); data[(y - j - 1)*x * 3 + i * 3 + 1] = unsigned char(255.99f * col[1]); data[(y - j - 1)*x * 3 + i * 3 + 2] = unsigned char(255.99f * col[2]); } 最后写入文件并释放空间 12stbi_write_jpg(&quot;..//output.jpg&quot;, x, y, 3, data, 100);delete[] data; 配合github desktop 我们可以很舒服的来观察输出结果的变化 3 The vec3 Classc++ 重载教学 4 Rays, a Simple Camera, and Background5 Adding a Sphere射线与球相交 6 Surface Normals and Multiple Objectsc++ 继承教学 7 Antialiasing这里的抗锯齿做法十分暴力: SSAA, SuperSampling Anti-Aliasing(超级采样抗锯齿), 在每个像素周边发射s条射线然后取颜色的平均值, 本书中s取100 这样程序的运行时间就直接翻了s倍, 十分的慢我们先把程序由Debug切换到Release, 实测可以大幅提升运行速度再通过OpenMP来进行多线程的加速首先我们先打开编译器对OpenMP的支持 右键项目属性C/C++ → 语言 → OpenMP支持(是) 12345678#include &lt;omp.h&gt;int main(){ #pragma omp parallel for num_threads(4) for(){ //your code }} 这里的num_threads在默认情况下是你cpu的核心数, 开启超过cpu核心数的线程并不会提升程序执行效率。原理很简单, 不优化时程序是在单核跑, 优化后OpenMP将代码块编译, 拆分, 让剩下的3个核心也加入了运算, 这时再开启更多线程也没用了, 一共只有4个核心, 而他们全部都在运算中。我们可以省略for num_threads()参数, 直接 1234#pragma omp parallel forfor(){ //your code} 当for循环嵌套时,即两个循环之间存在关连时, 复数的优化指令也无法做到加速 1234567891011121314151617#pragma omp parallel forfor(){ //outer loop #pragma omp parallel for //this line is useless for(){ //inner loop hit(); }}void hit(){ #pragma omp parallel for //this line is also useless for(){ //loop in func }} #pragma omp parallel for 写在哪个循环前, 就会把该循环的工作拆分, 于是就打乱该循环的次序。使用大括号{}将目标代码段括起来, 会将内外部循环次序全部打乱 123456789101112131415161718#pragma omp parallel forfor(i=0;i&lt;10;i++){ cout&lt;&lt;i&lt;&lt;endl;//i will not in order for(j=0;j&lt;10;j++){ cout&lt;&lt;j&lt;&lt;endl;//j will IN order }}//time 0.018#pragma omp parallel for{ for(i=0;i&lt;10;i++){ cout&lt;&lt;i&lt;&lt;endl;//i will not in order for(j=0;j&lt;10;j++){ cout&lt;&lt;j&lt;&lt;endl;//j will NOT IN order } }}//time 0.018 在该项目中加速, 只要在遍历像素前加一句#pragma omp parallel for即可 123456789#include &lt;omp.h&gt;...int main{ ... #pragma omp parallel for for (int j = 0; j &lt;ny; j++) ...} 现在程序的运行速度就会快上大约你核心数的倍数, 再加上切换到Release模式,原来渲上好几个小时的图只需渲上几分钟 8 Diffuse Materials光线打到粗糙不平的物体表面, 会随机的往各个方向散射。在生活中大部分物体都属于这类。生成一个随机的单位向量来模拟光线的无规则散射 9 Metal在计算dot(v,n)时, v与n的夹角大于90°, 运算结果为负值, 所以需要补正 10 Dielectrics求折射光线的方向全内反射Fresnel - Schlick approximation近似求借菲涅尔方程 11 Positionable Camera这里和其他地方的摄像机没有太大的区别fov, depth 12 Defocus Blur和chapter7的做法一样,将摄像机发出每条射线的位置进行偏移, 然后在SSAA时就会暴力的取平均值 13 Where Next?","link":"/Graphic/ray-tracing-in-one-weekend-explanation/"},{"title":"绕任意轴旋转, 绕任意直线旋转矩阵推导","text":"问题描述： 已知空间中的任意轴axis(u,v,w)，点v绕该轴旋转$\\theta$后得到点v’，求满足条件的矩阵$R_\\theta$，使得有$v’ = R_\\theta v$ 思路1:先将旋转到z轴，然后引用绕z轴旋转公式，再将该轴再旋转回原来的地方。思路2：矩阵的本质是线性变换，我们通过几何方法对三个轴分别写出三个线性变换的表达式，再将其拼接成矩阵。 这里我们讲一下思路1，思路2见3D Math Primer for Graphics and Game Development, 2nd Edition，不管采取哪种方法，得到的结果肯定是一样的。 众所周知，把一头大象关进冰箱需要三步1.打开冰箱门2.把大象放进去3.关闭冰箱门 于是按思路一来说的话，把一个点绕任意轴旋转也可以简单的分成三步1.任意轴旋转至z轴2.使用绕z轴旋转矩阵旋转$\\theta$3.任意轴旋转回原来位置 使用公式表达的话，便有$v’ = R^{-1}{to-x}R_zR{to-x} v$ 即我们把$R_\\theta$拆分成了三部分 $R_\\theta = R^{-1}{to-x}R_zR{to-x}$ 其中绕z轴旋转的矩阵我们是知道的 $$R_\\theta= \\begin{bmatrix} cos\\theta &amp; -sin\\theta &amp; 0 &amp; 0\\\\ sin\\theta &amp; cos\\theta &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}$$ emmm，如果你不知道这个式子怎么来的话，推导大致是从二维旋转升到三维。二维的推导可以参考其他的blog或任意一本图形学教材。搜索旋转矩阵就行，大概是由三角和差公式推出来的。 现在问题就转化成了如果将任意轴旋转至z轴了。 这个问题我们也可以分两步走1.任意轴先 绕z轴旋转到xz平面(标记该矩阵为$R_1$)2.再 绕y轴旋转到与z轴重合(标记该矩阵为$R_2$) 于是我们可以很方便的写出$R_1$,$R_2$ $$R_1= \\begin{bmatrix} cos\\alpha &amp; -sin\\alpha &amp; 0 &amp; 0\\\\ sin\\alpha &amp; cos\\alpha &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}$$ $$R_2= \\begin{bmatrix} cos\\beta &amp; 0 &amp; -sin\\beta &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ sin\\beta &amp; 0 &amp; cos\\beta &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}$$ 其中角$\\alpha$不太好理解，这个角是一开始轴上的点投影到XOY平面后与x轴所成的夹角。摆弄一下圆珠笔有助于理解。如果几何上想不太通，可以算一下$R1v$看看是不是等于$(\\sqrt{u^2+v^2},0,w)$ $cos\\alpha=\\frac{u}{\\sqrt{u^2+v^2}}$（特别的，这里的uv不全为零，但是在之后的式子被化简掉） 角$\\beta$就比较好理解了 $cos\\beta=\\frac{w}{\\sqrt{u^2+v^2+w^2}}$ 于是我们就能写出$R_\\theta$了 $R_\\theta = R^{-1}_1R^{-1}_2R_zR_2R_1$ 别忘了旋转矩阵是正交矩阵，其转置等于它的逆，这样会省去求逆的麻烦。 $R_\\theta = R^{T}_1R^{T}_2R_zR_2R_1$ 所有的五个矩阵我们都有了，我们将其连乘，得到$R_\\theta$ $$R_\\theta= \\begin{bmatrix} \\frac{u^2(1-cos\\theta) + cos\\theta}{\\sqrt{u^2+v^2+w^2}} &amp; \\frac{uv(1-cos\\theta) - wsin\\theta}{\\sqrt{u^2+v^2+w^2}} &amp; \\frac{uw(1-cos\\theta) + vsin\\theta}{\\sqrt{u^2+v^2+w^2}} &amp; 0\\\\ \\frac{vu(1-cos\\theta) + w\\theta}{\\sqrt{u^2+v^2+w^2}} &amp; \\frac{v^2(1-cos\\theta) + cos\\theta}{\\sqrt{u^2+v^2+w^2}} &amp; \\frac{vw(1-cos\\theta) - usin\\theta}{\\sqrt{u^2+v^2+w^2}} &amp; 0 \\\\ \\frac{wu(1-cos\\theta) - vsin\\theta}{\\sqrt{u^2+v^2+w^2}} &amp; \\frac{wv(1-cos\\theta) + usin\\theta}{\\sqrt{u^2+v^2+w^2}} &amp; \\frac{w^2(1-cos\\theta) + cos\\theta}{\\sqrt{u^2+v^2+w^2}} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}$$ 我们这里希望$u^2+v^2+w^2 = 1$就好了，式子会简化很多。那么什么样的情况下对于axis(u,v,w)来说，有$u^2+v^2+w^2 = 1$呢？ 其实这就是单位向量的模为1，所以我们设$normal(n_x,n_y,n_z) = axis(u,v,w).Normalized()$并将上面的矩阵改写成以下形式: $$R_\\theta= \\begin{bmatrix} n_xn_x(1-cos\\theta) + cos\\theta &amp; n_xn_y(1-cos\\theta) - n_zsin\\theta &amp; n_xn_z(1-cos\\theta) + n_ysin\\theta &amp; 0\\\\ n_yn_x(1-cos\\theta) + n_zsin\\theta &amp; n_yn_y(1-cos\\theta) + cos\\theta &amp; n_yn_z(1-cos\\theta) - n_xsin\\theta &amp; 0 \\\\ n_zn_x(1-cos\\theta) - n_ysin\\theta &amp; n_zn_y(1-cos\\theta) + n_xsin\\theta &amp; n_zn_z(1-cos\\theta) + cos\\theta &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}$$ 我们就得到绕任意轴旋转的旋转矩阵 1234567891011121314151617181920212223//rotate by the axis cross the world origin(0,0,0)Matrix4f get_rotation(Vector3f axis, float angle) { Matrix4f rotate = Matrix4f::Identity(); float cos_theta = cos(ToRadius(angle)); float sin_theta = sin(ToRadius(angle)); float one_minus_cos_theta = 1- cos_theta; axis = axis.normalized(); rotate &lt;&lt; axis[0]*axis[0]*one_minus_cos_theta + cos_theta, axis[0]*axis[1]*one_minus_cos_theta - axis[2]*sin_theta, axis[0]*axis[2]*one_minus_cos_theta + axis[1]*sin_theta, 0, axis[1] * axis[0] *one_minus_cos_theta + axis[2]*sin_theta, axis[1] * axis[1] *one_minus_cos_theta + cos_theta, axis[1] * axis[2] *one_minus_cos_theta - axis[0]*sin_theta, 0, axis[2] * axis[0] *one_minus_cos_theta - axis[1]*sin_theta, axis[2] * axis[1] *one_minus_cos_theta + axis[0]*sin_theta, axis[2] * axis[2] *one_minus_cos_theta + cos_theta, 0, 0,0,0,1; return rotate;} 但这还不够，这里所谓的绕任意轴旋转，其实是过原点的任意轴旋转。即我们传入的axis经过点(0,0,0)。如果我们想让物体不是沿着过原点的轴，而是沿着任意一条直线，举个例子，让一个三角形沿着自己的一条边旋转，上面的函数显然就不够用了。 从另一个角度来说，我们可以观察到上面的矩阵的格式，其实完全可以不使用齐次矩阵，写成3x3的格式，这也正是印证了这一点。 那么如果我想让点绕着空间中任意的一条直线旋转呢？首先，如何用参数来表示这条直线？我们只需要一个方向向量与直线上的任意一点就能确定空间中唯一的一条直线。所以这里我们就需要至少传入两个vector3作为参数（传入两个点或者传入一个点一个方向向量都行）。 1234567Matrix4f get_rotation(Vector3f from, Vector3f to, float angle){ ...}//or Matrix4f get_rotation(Vector3f any_point_on_line, Vector3f dir, float angle){ ...} 我们之前的函数Matrix4f get_rotation(Vector3f axis, float angle)就是默认了any_point_on_line = Vector3f(0,0,0);。反正直线上的两个点相减就能得出直线的方向，为了方便，下面我们采用第一种传参方法来写。 思考一下在2D空间中我们是怎么将一个点绕任意点旋转的？首先我们将任意点连着坐标系一起平移至原点，然后采用绕任意点旋转矩阵旋转，最后再将任意点从原点移回它本来所在的位置。这又是一个把大象关进冰箱的例子。 $v’ = T^{-1}R_\\theta T*v$ 现在拓展到三维，这个方法依然使用。我们需要将这条直线平移，使其经过原点，然后使用绕任意轴旋转公式旋转，最后再把直线移回去。 $v’ = T^{-1}R_\\theta T*v$ 看，式子完全一样。唯一的不同就是从二维拓展到了三维。 假设点P(a,b,c)为该直线上的一点，那么其中 $$T= \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; -a \\\\ 0 &amp; 1 &amp; 0 &amp; -b \\\\ 0 &amp; 0 &amp; 1 &amp; -c \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}$$ 于是我们可以写出下面的代码: 123456789101112Matrix4f get_rotation(Vector3f from, Vector3f to, float angle) { Matrix4f transform = Matrix4f::Identity(); Vector3f axis = (to - from).normalized(); float cos_theta = cos(ToRadius(angle)); float sin_theta = sin(ToRadius(angle)); transform &lt;&lt; 1, 0, 0, -from[0], 0, 1, 0, -from[1], 0, 0, 1, -from[2], 0, 0, 0, 1; return transform.inverse()*get_rotation(axis, angle)*transform;} 这里有几个需要注意的地方: axis单不单位化都行，反正get_rotation(axis, angle)中会将其单位化。 transform矩阵中不使用from，使用to来平移也行，甚至你可以写成-(to + k*axis)(k为任意浮点数，即直线上的任意点)这种形式，只要平移之后的直线经过原点就行。 但这样就多出了两个矩阵乘法的运算，我们自然很不乐意。所以可以将transform.inverse()*get_rotation(axis, angle)*transform， 即$T^{-1}R_\\theta T$算一算，写成一个矩阵，这也正是齐次坐标系的好处。 这个推导计算的过程不难，但异常的繁杂，我十分不建议大家手推，除非你想锻炼一下计算能力。算完应该是这样的: $$T^{-1}R_\\theta T= \\begin{bmatrix} n_xn_x(1-cos\\theta) + cos\\theta &amp; n_xn_y(1-cos\\theta) - n_zsin\\theta &amp; n_xn_z(1-cos\\theta) + n_ysin\\theta &amp; (a(1-n_xn_x)-n_x(bn_y+cn_z))(1-cos\\theta)+(bn_z-cn_y)sin\\theta\\\\ n_yn_x(1-cos\\theta) + n_zsin\\theta &amp; n_yn_y(1-cos\\theta) + cos\\theta &amp; n_yn_z(1-cos\\theta) - n_xsin\\theta &amp; (b(1-n_yn_y)-n_y(an_x+cn_z))(1-cos\\theta)+(cn_x-an_z)sin\\theta\\\\ n_zn_x(1-cos\\theta) - n_ysin\\theta &amp; n_zn_y(1-cos\\theta) + n_xsin\\theta &amp; n_zn_z(1-cos\\theta) + cos\\theta &amp; (c(1-n_zn_z)-n_z(an_x+bn_y))(1-cos\\theta)+(an_y-bn_x)sin\\theta\\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}$$ 可以看到其实$R_{3x3}$的元素其实没变，只是表示平移的最后一列发生了变化。 于是我们得到了绕任意直线旋转的函数的最终版 12345678910111213141516171819202122232425Matrix4f get_rotation(Vector3f from, Vector3f to, float angle) { Matrix4f rotate = Matrix4f::Identity(); Vector3f axis = (to - from).normalized(); float cos_theta = cos(ToRadius(angle)); float sin_theta = sin(ToRadius(angle)); float one_minus_cos_theta = 1 - cos_theta; float a = from.x(); float b = from.y(); float c = from.z(); rotate &lt;&lt; axis[0] * axis[0] * one_minus_cos_theta + cos_theta, axis[0] * axis[1] * one_minus_cos_theta - axis[2] * sin_theta, axis[0] * axis[2] * one_minus_cos_theta + axis[1] * sin_theta, (a*(1 - axis[0]*axis[0]) - axis[0]*(b*axis[1] + c*axis[2]))*one_minus_cos_theta + (b*axis[2] - c*axis[1])*sin_theta, axis[1] * axis[0] * one_minus_cos_theta + axis[2] * sin_theta, axis[1] * axis[1] * one_minus_cos_theta + cos_theta, axis[1] * axis[2] * one_minus_cos_theta - axis[0] * sin_theta, (b*(1 - axis[1]*axis[1]) - axis[1]*(a*axis[0] + c*axis[2]))*one_minus_cos_theta + (c*axis[0] - a*axis[2])*sin_theta, axis[2] * axis[0] * one_minus_cos_theta - axis[1] * sin_theta, axis[2] * axis[1] * one_minus_cos_theta + axis[0] * sin_theta, axis[2] * axis[2] * one_minus_cos_theta + cos_theta, (c*(1 - axis[2]*axis[2]) - axis[2]*(a*axis[0] + b*axis[1]))*one_minus_cos_theta + (a*axis[1] - b*axis[0])*sin_theta, 0, 0, 0, 1; return rotate;} 这里axis必须normalized，因为上述推导过程中的nx,ny,nz严格满足$n^2_x+n^2_y+n^2_z=1$ 哦，这是透视投影，这种现象是正常的。 reference:Rotation About an Arbitrary Axis in 3 Dimensions,Glenn Murray","link":"/Math/rotate-by-arbitrary-line/"},{"title":"修改html代码块中的tab宽度","text":"在写blog中发现的问题, 我的代码块tab默认的宽度是8个空格, 看起来很不舒服, 并且由于缩进太占空间导致显示不全, 遂改之 方法一 将制表符替换为空格这是一个比较暴力的方法 直接把制表符替换为你需要的指定数目的空格 我这里是用的highlight.js来进行代码块的高亮, 在引用该js文件后直接调用其API, 插入下述代码块 123456&lt;script&gt; hljs.configure({ tabReplace: ' ', // 4 spaces }) hljs.initHighlighting();&lt;/script&gt; hexo用户可以在 _config.yml 文件中直接设置, 省去在ejs模板中添加代码的麻烦 1234567highlight: enable: true line_number: true auto_detect: false #tab_replace://do not replace tab with space tab_replace: ' ' //replace tab with 4 space ... 甚至 你可以自己用JavaScript写个replace函数来替换 12345678var tabReplace = &quot; &quot;;function replaceTab(tabReplace){ $(&quot;pre&quot;).text($(&quot;pre&quot;).text().replace(/\\t/g, tabReplace));}replaceTab(tabReplace);//or do it in one line$(&quot;pre&quot;).text($(&quot;pre&quot;).text().replace(/\\t/g, &quot; &quot;)); 这样做的缺点是会丢失制表符的信息, 其他用户在复制你的代码后, 原先的tab符都变成了空格 方法二 通过修改css样式在CSS3中新增了tab-size属性, 可以指定tab为多少空格的宽度，这个值默认为8 123pre{ tab-size: 4;} 一般来说在pre或者code这样的标签中来设定这个属性 缺点是可能有些上古的浏览器不支持(说的就是你！IE10.0之前的版本), 这个基本可以忽略不计, 所以可以当成是没有缺点 当然, 如果你是一个空格缩进党, 那么太好了, 你将完全不会为tab到底多宽而烦恼 正所谓: 众猿皆谓 tab 巧,无人知晓空格好。大手一拍按到底,爱空多少空多少。","link":"/Web/FrontEnd/tabsize/"},{"title":"Ray tracing the next week 中文翻译","text":"写在前头本书为PeterShirley的Ray tracing入门教学系列的第二本。当前版本v3.0。 译者水平有限, 有些地方读起来难免会感到怪怪的, 还请各位见谅。如果您遇到什么看不懂的地方或者乱七八糟的句子, 那么您很可能是辣鸡翻译的受害者, 这时候请不要犹豫, 直接去阅读原文自救。如果您愿意帮助我改进这个翻译, 请直接在页面底部留言或发送邮件到zgxmy@126.com, 万分感激!!! 目录:1. Overview 概述2. Motion Blur 动态模糊3. Bounding Volume Hierarchies 层次包围盒4. Solid Texture 固体贴图5. Perlin Noise 柏林噪声6. Image Texture Mapping 图像纹理映射7. Rectangles and Lights 矩形和光源8. instance 实例9. volumes 体积体10. A Scene Testing All New Features 一个测试所有新特性的场景译者后记 1. 概述在Ray Tracing in One Weekend中, 你实现了一个暴力的光线路径追踪器。在本部分中, 我们将加入纹理, 体积体(例如烟雾), 矩形, 实例, 光源, 并用BVH来包裹我们的物体。当你完成这些后, 你将拥有一个“真正的”光线追踪器。 在光线追踪方面, 具有启发性的一点是, 许多人(包括作者本人)相信大多数用来优化的代码只会让程序更复杂, 而并不会提升太多的运行速度。我在这本迷你书中将采取最简单直接的方式来实现代码。如果你想看复杂的优化版本, 请点击这里。并且我在这里建议读者不要自己过早的去优化。如果说程序在执行时间上来看并没有太大的变化, 那么它就并不需要你去优化。直到最后所有的功能都被实现前, 你可以一直就这样往里面添加代码。 本书中最难的两部分是BVH和柏林噪声贴图。所以我将标题取名为“一周”而不是像上一本一样的“一个周末”。如果你想一个周末搞定这本书, 那么你可以把这两个部分留到最后。这本书中提到的概念, 各章节的顺序并不是很重要, 没有BVH和柏林噪声贴图你仍然能渲染出属于自己漂亮的Cornell Box! 1.1 致谢感谢 Becker 对草稿的许多建设性意见。感谢 Matthew Heimlich 指出一个严重的动态模糊的错误。感谢 Andrew Kensler, Thiago Ize, and Ingo Wald 对ray-AABB 测试的建议。 感谢 David Hart and Grue Debry 对细节补完上的帮助。 感谢 Jean Buckley 的编辑, 感谢 Dan Drummond 修复代码bug, 感谢 Steve Hollasch and Trevor David Black 将本书翻译为 Markdeep 并挪到该网页上。 2. 动态模糊当你在做光线追踪时, 想要更好的出图质量就意味着更多的程序运行时间。例如上一本书中的反射部分和镜头散焦模糊中, 你需要对每个像素进行多重采样。当你决定在这条路上走得更深一些时, 好消息来了: 几乎所有的特效都能这样暴力实现。动态模糊也是属于能这样实现的特效之一。想象一个真实世界的摄像机, 在快门打开的时间间隔中, 摄像机和物体都有可能移动。那拍出来的结果肯定是这个运动过程每一帧的平均值, 或者说, 一团糊了。我们可以用随机的方法在不同时间发射多条射线来模拟快门的打开。只要物体在那个时间处于其正确的位置, 那么我们就能得出这条光线在那个时间点的精确平均值。这就是为什么随机光追看上去很简单的原因。 一个基础的思路是, 在快门打开时, 随着时间变化随机生成光线, 并同时发出射线与模型相交。一般来说我们让摄像机和物体同时运动, 并让每一条射线都拥有自己存在的一个时间点。这样光线追踪器的“引擎”就能确定, 对于指定的某条光线来说, 在该时刻, 物体到底在哪儿。求射线与球相交的部分写法和之前并没有太多区别。 为了实现刚刚的思路, 我们首先要让每条光线都能储存自己所在的时刻, 就像这样: ray.h diff1234567891011121314151617181920class ray { public: ray() {}+ ray(const vec3&amp; origin, const vec3&amp; direction, double time = 0.0)+ : orig(origin), dir(direction), tm(time)+ {} vec3 origin() const { return orig; } vec3 direction() const { return dir; }+ double time() const { return tm; } vec3 at(double t) const { return orig + t*dir; } public: vec3 orig; vec3 dir;+ double tm;}; 现在我们需要让摄像机在time1到time2的时间段中随机生成射线。光线的生成时刻是让camera类自己来运算追踪呢, 还是说可以让用户来自行指定光线在哪个时刻生成比较好呢? 当出现这样的疑问时, 我喜欢让构造函数更加复杂,同时调用起来会更加简单。所以我让camera类来储存着两个变量。但这只是我的个人喜好。camera类并不需要太多修改, 因为现在它不会动, 只会在一个时间段内发出射线。 camera.h diff1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class camera { public: camera( vec3 lookfrom, vec3 lookat, vec3 vup, double vfov, // top to bottom, in degrees+ double aspect, double aperture, double focus_dist, double t0 = 0, double t1 = 0 ) { origin = lookfrom; lens_radius = aperture / 2;+ time0 = t0;+ time1 = t1; auto theta = degrees_to_radians(vfov); auto half_height = tan(theta/2); auto half_width = aspect * half_height; w = unit_vector(lookfrom - lookat); u = unit_vector(cross(vup, w)); v = cross(w, u); lower_left_corner = origin - half_width*focus_dist*u - half_height*focus_dist*v - focus_dist*w; horizontal = 2*half_width*focus_dist*u; vertical = 2*half_height*focus_dist*v; } ray get_ray(double s, double t) { vec3 rd = lens_radius * random_in_unit_disk(); vec3 offset = u * rd.x() + v * rd.y();+ return ray(+ origin + offset,+ lower_left_corner + s*horizontal + t*vertical - origin - offset,+ random_double(time0, time1)+ ); } public: vec3 origin; vec3 lower_left_corner; vec3 horizontal; vec3 vertical; vec3 u, v, w; double lens_radius;+ double time0, time1; // shutter open/close times}; 我们还需要一个运动中的物体。我建立了一个新的sphere类, 让它的球心在time0到time1的时间段内从center0线性运动到center1。超出这个时间段, 这个球心依然在动, 【译注：就是说在做线性插值的时候t可以大于1.0 也可以小于0】, 所以这里的两个时间变量和摄像机快门的开关时刻并不需要一一对应。 move_sphere.h method 112345678910111213141516171819202122class moving_sphere : public hittable { public: moving_sphere() {} moving_sphere( vec3 cen0, vec3 cen1, double t0, double t1, double r, shared_ptr&lt;material&gt; m) : center0(cen0), center1(cen1), time0(t0), time1(t1), radius(r), mat_ptr(m) {}; virtual bool hit(const ray&amp; r, double tmin, double tmax, hit_record&amp; rec) const; vec3 center(double time) const; public: vec3 center0, center1; double time0, time1; double radius; shared_ptr&lt;material&gt; mat_ptr;};vec3 moving_sphere::center(double time) const{ return center0 + ((time - time0) / (time1 - time0))*(center1 - center0);} 另外一种让球随着时间动起来的方法是, 取代先前新建一个动态球类的做法, 只留一个球类, 让所有的球都动起来, 只是那些静止的球起点与终点位置相同。我在第一种方案和第二种方案间反复很跳。所以就请你们自己根据自己的喜好来选择吧。球与光线求交的代码几乎没有改变: 只要把center改成一个插值函数center(time)就行了 sphere.h method 2 diff12345678910111213141516171819202122232425262728293031323334bool moving_sphere::hit( const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const {+ vec3 oc = r.origin() - center(r.time()); auto a = r.direction().length_squared(); auto half_b = dot(oc, r.direction()); auto c = oc.length_squared() - radius*radius; auto discriminant = half_b*half_b - a*c; if (discriminant &gt; 0) { auto root = sqrt(discriminant); auto temp = (-half_b - root)/a; if (temp &lt; t_max &amp;&amp; temp &gt; t_min) { rec.t = temp; rec.p = r.at(rec.t);+ vec3 outward_normal = (rec.p - center(r.time())) / radius; rec.set_face_normal(r, outward_normal); rec.mat_ptr = mat_ptr; return true; } temp = (-half_b + root) / a; if (temp &lt; t_max &amp;&amp; temp &gt; t_min) { rec.t = temp; rec.p = r.at(rec.t);+ vec3 outward_normal = (rec.p - center(r.time())) / radius; rec.set_face_normal(r, outward_normal); rec.mat_ptr = mat_ptr; return true; } } return false;} 请确保你的材质在运算光线散射时, 散射光线与入射光线所存在的时间点相同。 material.h diff123456789101112131415class lambertian : public material { public: lambertian(const vec3&amp; a) : albedo(a) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { vec3 scatter_direction = rec.normal + random_unit_vector();+ scattered = ray(rec.p, scatter_direction, r_in.time()); attenuation = albedo; return true; } vec3 albedo;}; 下面的代码是在上本书结尾处最终场景的例子上加以改动, 使其中漫反射材质的球动起来。(想象一下摄像机的快门在time0时打开, 在time1时关闭)每个球的中心在time0到time1的时间段内从原始位置$\\mathbf{C}$线性运动到$\\mathbf{C} + (0, r/2, 0)$, 其中r是[0,1)之间的随机数。 main.cc12345678910111213141516171819202122232425262728293031323334353637383940hittable_list random_scene() { hittable_list world; world.add(make_shared&lt;sphere&gt;( vec3(0,-1000,0), 1000, make_shared&lt;lambertian&gt;(vec3(0.5, 0.5, 0.5)))); int i = 1; for (int a = -10; a &lt; 10; a++) { for (int b = -10; b &lt; 10; b++) { auto choose_mat = random_double(); vec3 center(a + 0.9*random_double(), 0.2, b + 0.9*random_double()); if ((center - vec3(4, .2, 0)).length() &gt; 0.9) { if (choose_mat &lt; 0.8) { // diffuse auto albedo = vec3::random() * vec3::random(); world.add(make_shared&lt;moving_sphere&gt;( center, center + vec3(0, random_double(0,.5), 0), 0.0, 1.0, 0.2, make_shared&lt;lambertian&gt;(albedo))); } else if (choose_mat &lt; 0.95) { // metal auto albedo = vec3::random(.5, 1); auto fuzz = random_double(0, .5); world.add( make_shared&lt;sphere&gt;(center, 0.2, make_shared&lt;metal&gt;(albedo, fuzz))); } else { // glass world.add(make_shared&lt;sphere&gt;(center, 0.2, make_shared&lt;dielectric&gt;(1.5))); } } } } world.add(make_shared&lt;sphere&gt;(vec3(0, 1, 0), 1.0, make_shared&lt;dielectric&gt;(1.5))); world.add(make_shared&lt;sphere&gt;( vec3(-4, 1, 0), 1.0, make_shared&lt;lambertian&gt;(vec3(0.4, 0.2, 0.1)))); world.add(make_shared&lt;sphere&gt;( vec3(4, 1, 0), 1.0, make_shared&lt;metal&gt;(vec3(0.7, 0.6, 0.5), 0.0))); return world;} 并使用以下的摄像机参数: main.cc123456789const auto aspect_ratio = double(image_width) / image_height;...vec3 lookfrom(13,2,3);vec3 lookat(0,0,0);vec3 vup(0,1,0);auto dist_to_focus = 10.0;auto aperture = 0.0;camera cam(lookfrom, lookat, vup, 20, aspect_ratio, aperture, dist_to_focus, 0.0, 1.0); 你将会得到类似下面的结果: 3. 层次包围盒这部分是书中最难,也是与我们正在写的光线追踪器关联最深的一部分。我把这部分放在这么前面, 是因为它改写了hittable的部分代码, 程序运行起来更加的快了。而且当我们后面添加三角形和箱子类的时候, 我们也不必回来改写hittable了。 光线的求交运算一直是光线追踪器的主要时间瓶颈, 并且运行时间与场景中的物体数量线性相关。使用遍历反复查找同一个模型会有许多多余的计算, 所以我们应该用二叉搜索的方法来加速查找。我们对每个模型都射出了成千上万的射线, 我们可以对模型的排序进行模拟, 每一次光线求交都是一个亚线性(subliner)的查找 【译注:亚线性指参数的指数小于1, 即不到线性, 平衡查找树的时间复杂度为O(log2(n))】。最常见的两种排序方法是 1) 按空间分割 【译注: 如KD树、八叉树】 2) 按物体分割。后者一般来说实现起来更简单并且对大多数模型来说运行速度都不错。 包围盒的核心思想是去找到一个能包围所有物体的盒子。举例来说, 假设你计算了一个包围10个物体的大球, 那么任何射不到这个大球的射线, 它都射不到球里面的那10个物体。反之亦然, 如果射线碰到大球了, 那么它和里面那10个物体都有可能发生关系。所以包围盒的代码看上去总是这样的: 1234if (ray hits bounding object) return whether ray hits bounded objectselse return false 记住, 我们的核心思想是把很多很多物体分割为子集。我们并不划分屏幕或者是空间。每个物体都只在一个包围盒里面, 并且这些包围盒还可以重叠。 为了做到每次光线求交都是一个亚线性的查找, 我们需要用包围盒构建出层级(hierarchical)。举个例子, 如果我们把一堆物体分成两队, 红队和蓝队, 并使用方方正正的包围盒来包围他们, 你将看到如下场景: 注意蓝盒子和红盒子现在都在紫盒子里面, 他们可以重合, 并且无序 —— 他们都平平等等的躺在紫盒子的肚子里。所以图片里右边的那颗树并没有什么左子树右子树的概念 【译注: 作者这里只是想强调他们属于同一层, 地位平等。等待会实际写这个二叉查找树的时候还是会有左子树右子树的】, 这两个分支是同级的。代码看起来是这样的: 123456if(hits purple) hit0 = hits blue enclosed objects hit1 = hits red enclosed objects if(hit0 or hit1) return true and info of closer hitreturn false 为了能使上述代码良好的跑起来, 我们需要好好规划一下怎么分堆。还得想想怎么去检测光线和包围盒相交。求交计算一定要高效, 并且包围盒要尽量密集。很对大多数模型来说, 轴对齐的包围盒比其他种类的包围盒效果更好。但是当你遇到更复杂的模型种类时, 你就先别想着用这种方法了。 从现在开始, 我们会把轴对齐的包围盒叫成矩形平行管道(讲真的, 这才是他本来该有的精确描述), 或者还是叫他 AABB吧 。你想用啥方法去算光线和AABB是否相交都行。我们现在只要能判断我们能不能射中这个AABB就行了。和击中那些会在屏幕上显示出来的物体时不同, 射线与AABB求交并不需要去获取那些法向啊交点啊这些东西, AABB不需要在屏幕上渲染出来。 大多数人采用一个叫堆叠法(slab)的方法。显然一个n维的AABB盒是由n个平行线所截的区间的重叠拼出来的区域 【译注: 这里看图就行了, 别看字】, 我们管这个叫”slab”。一个区间就是两个端点间的距离。比如对于$x$, $3&lt;x&lt;5$, 或者更加简洁的 $x$ 属于 $(3,5)$ 。在二维的情况下, 两段区间重叠的部分就是一个二维的AABB(一个矩形): 对于检测射线是否射入一段区间来说, 我们首先要看看射线有没有射入这个区间的边界。还是拿二维来举例子, 这是光线变量t0, t1。(在光线和目标平面平行的情况下, 因为并没有交点, 这两个变量将未定义) 在三维的情况下, 这些射入的边界不再是一条线, 而是一个平面。 这两个边界平面的方程分别是 $x=x_0$ 和 $x=x_1$。那么怎样来计算射线和平面相交呢? 让我们回想一下上一本书中我们给出的, 点p关于参数t的方程 $p(t) = A + t·B$ 这个等式用在三个坐标轴上都行, 比如 $x(t) = A_x + t·B_x$ 然后我们把这个方程和平面方程$x=x_0$联立, 使得存在一个值t, 满足下面方程: $x_0 = A_x + t_0·B_x$ 我们稍稍变下形: $t_0=\\frac{x_0-A_x}{B_x}$ 同理, 对于$x_1$的那个平面来说: $t_1=\\frac{x_1-A_x}{B_x}$ 把这个1D的等式运用到我们AABB求交运算的关键是, 你需要把n个维度的t区间重叠在一起。举例来说, 在2D情况下, 绿色的t区间和蓝色的t区间发生重叠的情况如下: 【译注: 这张图挺好的, 上面的那条射线, 蓝色与绿色部分没有重叠, 很自然的就没有穿过这个AABB矩形, 下面那条射线发生了重叠, 说明射线同时传过了蓝色区域和绿色区域, 即穿过了AABB矩形。注意对每一个维度来说, 这里我们解出来的t0, t1都表示直线上一个固定的点的位置, 所以我们可以自然地按照维度拆分计算, 然后在通过t这个统一的标识进行求交运算】 用代码表示”区间们是否重叠”看上去会是这样: 123compute(tx0,tx1)compute(ty0,ty1)return overlap?( (tx0, tx1), (ty0, ty1)) 这看上去真是简洁! 而且放到3D的情况下依旧适用, 所以大家都爱堆叠法: 1234compute(tx0, tx1)compute(ty0, ty1)compute(tz0, tz1)return overlap?( (tx0, tx1), (ty0, ty1), (tz0, tz1)) 当然我们还要对它做一些限制, 这会使它看上去没有一开始那么简洁。首先, 假设射线从$x$轴负方向射入, 这样前面compute的这个区间$(t_x0,t_x1)$就会反过来了, e.g. $(7, 3)$。第二, 除数为零时我们会得到无穷, 如果射线的原点就在这个堆叠的边界上, 我们就会得到$NaN$。不同的光线追踪器的AABB部分解决上述问题的方法多种多样。(这里还有一些矢量平行加速的方面比如SIMD, 我们本书中不讨论。如果你想走得更远些, 使用这种方法加速的话, Ingo Wald的论文将是个不错的选择)。对我们来说, 这并不是一个运算的主要瓶颈。所以直接让我们用最快捷最简单的方式搞起来吧! 首先我们来看看需要计算的这些区间。 $t_x0 = \\frac{x_0-A_x}{B_x}$$t_x1 = \\frac{x_1-A_x}{B_x}$ 我们的麻烦是一些射线恰好$B_x = 0$, 这样就会有除数为0的错误。一些光线在堆叠的里面, 一些不在。浮点$0$在 IEEE 工程标准下是有正负号的。好消息是, 在$x_0$到$x_1$区间内, $t_x0$与$t_x1$要么同为$\\infty$要么同为$-\\infty$。所以使用 min 与 max 函数就能得到正确的结果: $t_x0 = min(\\frac{x_0-A_x}{B_x},\\frac{x_1-A_x}{B_x})$$t_x1 = max(\\frac{x_0-A_x}{B_x},\\frac{x_1-A_x}{B_x})$ 现在只剩下分母$B_x = 0$并且$x_0 - A_x = 0$和$x_1 - A_x = 0$这两个分子之一为零的特殊情况了。这样我们会得到一个NaN【译注: 0/0 = NaN】。这种情况我们认为他射中了或者没射中这个区域都行。我们过会儿再来解决这个问题。 现在让我们先来看看overlap函数, 假设我们能保证区间没有被倒过来(即第一个值比第二个值小), 在这种情况下我们 return true, 那么一个计算$(d,D)$和$(e,E)$的重叠区间$(f,F)$的函数看上去是这样的: 1234bool overlap(d, D, e, E, f, F) f = max(d, e) F = min(D, E) return (f &lt; F) 如果这里出现了任何的NaN, 比较结果都会 return false, 所有如果考虑到那些擦边的情况, 我们要保证我们的包围盒有一些内间距(而且我们也许理应这么做, 因为在光线追踪中所有的情况最终都会发生)。把三个维度都写在一个循环中并传入时间间隔$t_min$,$t_max$我们得到: aabb.h123456789101112131415161718192021222324252627#include &quot;rtweekend.h&quot;class aabb { public: aabb() {} aabb(const vec3&amp; a, const vec3&amp; b) { _min = a; _max = b;} vec3 min() const {return _min; } vec3 max() const {return _max; } bool hit(const ray&amp; r, double tmin, double tmax) const { for (int a = 0; a &lt; 3; a++) { auto t0 = ffmin((_min[a] - r.origin()[a]) / r.direction()[a], (_max[a] - r.origin()[a]) / r.direction()[a]); auto t1 = ffmax((_min[a] - r.origin()[a]) / r.direction()[a], (_max[a] - r.origin()[a]) / r.direction()[a]); tmin = ffmax(t0, tmin); tmax = ffmin(t1, tmax); if (tmax &lt;= tmin) return false; } return true; } vec3 _min; vec3 _max;}; 注意我们把cmath内置的fmax()函数换成了我们自己的ffmax()(在rtweekend中定义)。这样会更快一点， 因为我们自己写的函数并不需要考虑到NaN和其他的异常情况。来自皮克斯的Andrew Kensler在阅读我的这个求交方法时做了一些试验, 并提出了一个自己的版本。这个版本在大多数编译器上都运行的非常好。所以我采用了这个方法作为我们接下来要使用的方法。 Andrew Kensler's hit method123456789101112131415//可以看到在上面的基础上略去了一些重复计算, 优化了不少inline bool aabb::hit(const ray&amp; r, double tmin, double tmax) const { for (int a = 0; a &lt; 3; a++) { auto invD = 1.0f / r.direction()[a]; auto t0 = (min()[a] - r.origin()[a]) * invD; auto t1 = (max()[a] - r.origin()[a]) * invD; if (invD &lt; 0.0f) std::swap(t0, t1); tmin = t0 &gt; tmin ? t0 : tmin; tmax = t1 &lt; tmax ? t1 : tmax; if (tmax &lt;= tmin) return false; } return true;} 现在我们需要加入一个函数来计算这些包裹着hittable类的包围盒。然后我们将做一个层次树。在这个层次树中, 所有的图元, 比如球体, 都会在树的最底端(叶子节点)。这个函数返回值是一个 bool 因为不是所有的图元都有包围盒的(e.g 无限延伸的平面)。另外, 物体会动, 所以他还要接收time1和time2, 包围盒会把在这个时间区间内运动的物体完整的包起来。 hittable.h diff123456class hittable { public: virtual bool hit( const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const = 0;+ virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const = 0;}; 对一个sphere类来说, 求包围盒真的太简单了: 123456bool sphere::bounding_box(double t0, double t1, aabb&amp; output_box) const { output_box = aabb( center - vec3(radius, radius, radius), center + vec3(radius, radius, radius)); return true;} 对于moving_sphere, 我们先求球体在$t_0$时刻的包围盒, 再求球体在$t_1$时刻的包围盒, 然后再计算这两个盒子的包围盒: 12345678910bool moving_sphere::bounding_box(double t0, double t1, aabb&amp; output_box) const { aabb box0( center(t0) - vec3(radius, radius, radius), center(t0) + vec3(radius, radius, radius)); aabb box1( center(t1) - vec3(radius, radius, radius), center(t1) + vec3(radius, radius, radius)); output_box = surrounding_box(box0, box1); return true;} 对于hittable_list来说, 我们可以在构造函数中就进行包围盒的运算, 或者在程序运行时计算。我喜欢在运行时计算, 因为这些包围盒的计算一般只有在BVH构造时才会被调用。 1234567891011121314bool hittable_list::bounding_box(double t0, double t1, aabb&amp; output_box) const { if (objects.empty()) return false; aabb temp_box; bool first_box = true; for (const auto&amp; object : objects) { if (!object-&gt;bounding_box(t0, t1, temp_box)) return false; output_box = first_box ? temp_box : surrounding_box(output_box, temp_box); first_box = false; } return true;} 我们需要一个surrounding_box函数来计算包围盒的包围盒。 123456789aabb surrounding_box(aabb box0, aabb box1) { vec3 small(ffmin(box0.min().x(), box1.min().x()), ffmin(box0.min().y(), box1.min().y()), ffmin(box0.min().z(), box1.min().z())); vec3 big (ffmax(box0.max().x(), box1.max().x()), ffmax(box0.max().y(), box1.max().y()), ffmax(box0.max().z(), box1.max().z())); return aabb(small,big);} BVH也应该是hittable的一员, 就像hittable_list类那样。BVH虽然是个容器, 但也能对于问题“这条光线射中你了么?”做出回答。一个设计上的问题是, 我们是为树和树的节点设计两个不同的类呢, 还是用一个类加上指针来搞定。我是一个类搞定派, 所以这个类会是这样: bvh.h12345678910111213141516171819202122232425class bvh_node : public hittable { public: bvh_node(); bvh_node(hittable_list&amp; list, double time0, double time1) : bvh_node(list.objects, 0, list.objects.size(), time0, time1) {} bvh_node( std::vector&lt;shared_ptr&lt;hittable&gt;&gt;&amp; objects, size_t start, size_t end, double time0, double time1); virtual bool hit(const ray&amp; r, double tmin, double tmax, hit_record&amp; rec) const; virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const; public: shared_ptr&lt;hittable&gt; left; shared_ptr&lt;hittable&gt; right; aabb box;};bool bvh_node::bounding_box(double t0, double t1, aabb&amp; output_box) const { output_box = box; return true;} 注意我们的子节点指针是hittable*, 所以这个指针可以指向所有的hittable类。例如节点bvh_node， 或者是sphere, 或者是其他各种各样的图元。 hit 函数也是十分的直接明了: 检查这个节点的box是否被击中, 如果是的话, 那就对这个节点的子节点进行判断。【译注: 对于二叉树来说, 这样的递归结构相信大家并不陌生】 bvh.h123456789bool bvh_node::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const { if (!box.hit(r, t_min, t_max)) return false; bool hit_left = left-&gt;hit(r, t_min, t_max, rec); bool hit_right = right-&gt;hit(r, t_min, hit_left ? rec.t : t_max, rec); return hit_left || hit_right;} 任何高效的数据结构, 例如BVH, 最复杂的部分就是如何去构建他。我们会在构造函数里完成。 对于BVH来说, 很酷的一点是当你不断地把bvh_node中的物体分割成两个子集的同时, hit函数也会跟着执行。如果说你分割的算法很好, 两个孩子的包围盒都比其父节点的包围盒要小, 那么自然hit函数也会运行的很好。但是这样只是快, 并不正确, 我将在正确和快直接做取舍, 在每次分割时我沿着一个轴把物体列表分成两半。我将采用最简单直接的分割原则: 1.随机选取一个轴来分割2.使用库函数sort()对图元进行排序3.对半分, 每个子树分一半的物体 物体分割过程递归执行, 当数组传入时只剩下两个元素时, 我在两个子树节点各放一个, 并结束递归。为了使遍历算法平滑, 并且不去检查空指针, 当只有一个元素时, 我将其重复的放在每一个子树里。想象一下有三个元素, 然后仔细的一步步递归一遍有助你理解算法, 但我这里先提一下, 之后我们会优化整个算法。现在代码是这样的: 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;algorithm&gt;...bvh_node::bvh_node( std::vector&lt;shared_ptr&lt;hittable&gt;&gt;&amp; objects, size_t start, size_t end, double time0, double time1) { int axis = random_int(0,2); auto comparator = (axis == 0) ? box_x_compare : (axis == 1) ? box_y_compare : box_z_compare; size_t object_span = end - start; if (object_span == 1) { left = right = objects[start]; } else if (object_span == 2) { if (comparator(objects[start], objects[start+1])) { left = objects[start]; right = objects[start+1]; } else { left = objects[start+1]; right = objects[start]; } } else { std::sort(objects.begin() + start, objects.begin() + end, comparator); auto mid = start + object_span/2; left = make_shared&lt;bvh_node&gt;(objects, start, mid, time0, time1); right = make_shared&lt;bvh_node&gt;(objects, mid, end, time0, time1); } aabb box_left, box_right; if ( !left-&gt;bounding_box (time0, time1, box_left) || !right-&gt;bounding_box(time0, time1, box_right) ) std::cerr &lt;&lt; &quot;No bounding box in bvh_node constructor.\\n&quot;; box = surrounding_box(box_left, box_right);} 这边做了一个物体是否有包围盒的检查, 是为了防止你把一些如无限延伸的平面这样没有包围盒的东西传进去当参数。我们现在并没有这样的图元, 所以在你手动添加这样的图元之前, 这个std::cerr并不会被执行。 现在我们需要实现std::sort()使用的比较函数。我们先判断是哪个轴, 然后对应的为我们的比较器赋值。 bvh.h12345678910111213141516171819202122inline bool box_compare(const shared_ptr&lt;hittable&gt; a, const shared_ptr&lt;hittable&gt; b, int axis) { aabb box_a; aabb box_b; if (!a-&gt;bounding_box(0,0, box_a) || !b-&gt;bounding_box(0,0, box_b)) std::cerr &lt;&lt; &quot;No bounding box in bvh_node constructor.\\n&quot;; return box_a.min().e[axis] &lt; box_b.min().e[axis];}bool box_x_compare (const shared_ptr&lt;hittable&gt; a, const shared_ptr&lt;hittable&gt; b) { return box_compare(a, b, 0);}bool box_y_compare (const shared_ptr&lt;hittable&gt; a, const shared_ptr&lt;hittable&gt; b) { return box_compare(a, b, 1);}bool box_z_compare (const shared_ptr&lt;hittable&gt; a, const shared_ptr&lt;hittable&gt; b) { return box_compare(a, b, 2);} 【译注: 使用方法：在random_scene()函数最后return static_cast(make_shared(world,0,1));】 4. 纹理在图形学中, 纹理贴图常常意味着一个将颜色赋予物题表面的一个过程。这个过程可以是纹理生成代码, 或者是一张图片, 或者是两者的结合。我们首先来使用颜色作为贴图。大多数程序员把静态rgb颜色和贴图写成两个不同的类, 以此来区分两者, 但我更加喜欢下面的做法, 因为这样就可以把任何颜色弄成一张贴图, 十分的great。 12345678910111213141516171819#include &quot;rtweekend.h&quot;class texture { public: virtual vec3 value(double u, double v, const vec3&amp; p) const = 0;};class constant_texture : public texture { public: constant_texture() {} constant_texture(vec3 c) : color(c) {} virtual vec3 value(double u, double v, const vec3&amp; p) const { return color; } public: vec3 color;}; 我们需要更新hit_record结构体来储存击中点的uv信息: hittable.h diff123456789struct hit_record { vec3 p; vec3 normal; shared_ptr&lt;material&gt; mat_ptr; double t;+ double u;+ double v; bool front_face; ... 把vec3的颜色换成一个纹理指针, 你将得到一个纹理材质。 12345678910111213141516class lambertian : public material { public: lambertian(shared_ptr&lt;texture&gt; a) : albedo(a) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { vec3 scatter_direction = rec.normal + random_unit_vector(); scattered = ray(rec.p, scatter_direction, r_in.time()); attenuation = albedo-&gt;value(rec.u, rec.v, rec.p); return true; } public: shared_ptr&lt;texture&gt; albedo;}; 在之前一个lambert材质是这样的: 1...make_shared&lt;lambertian&gt;(vec3(0.5, 0.5, 0.5)) 现在我们把vec3(...)换成make_shared&lt;constant_texture&gt;(vec3(...)) 1...make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.5, 0.5, 0.5))) 我们可以使用sine和cosine函数周期性的变化来做一个棋盘格纹理。如果我们在三个维度都乘上这个周期函数, 就会形成一个3D的棋盘格模型。 texture.h1234567891011121314151617class checker_texture : public texture { public: checker_texture() {} checker_texture(shared_ptr&lt;texture&gt; t0, shared_ptr&lt;texture&gt; t1): even(t0), odd(t1) {} virtual vec3 value(double u, double v, const vec3&amp; p) const { auto sines = sin(10*p.x())*sin(10*p.y())*sin(10*p.z()); if (sines &lt; 0) return odd-&gt;value(u, v, p); else return even-&gt;value(u, v, p); } public: shared_ptr&lt;texture&gt; odd; shared_ptr&lt;texture&gt; even;}; 这些奇偶格的指针可以指向一个静态纹理, 也可以指向一些程序生成的纹理。这就是Pat Hanrahan在1980年代提出的着色器网络的核心思想。 如果我们把这个纹理贴在我们random_scene()函数里底下那个大球上: 123456auto checker = make_shared&lt;checker_texture&gt;( make_shared&lt;constant_texture&gt;(vec3(0.2, 0.3, 0.1)), make_shared&lt;constant_texture&gt;(vec3(0.9, 0.9, 0.9)));world.add(make_shared&lt;sphere&gt;(vec3(0,-1000,0), 1000, make_shared&lt;lambertian&gt;(checker))); 就有: 如果我们添加一个新场景: 12345678910111213hittable_list two_spheres() { hittable_list objects; auto checker = make_shared&lt;checker_texture&gt;( make_shared&lt;constant_texture&gt;(vec3(0.2, 0.3, 0.1)), make_shared&lt;constant_texture&gt;(vec3(0.9, 0.9, 0.9)) ); objects.add(make_shared&lt;sphere&gt;(vec3(0,-10, 0), 10, make_shared&lt;lambertian&gt;(checker))); objects.add(make_shared&lt;sphere&gt;(vec3(0, 10, 0), 10, make_shared&lt;lambertian&gt;(checker))); return objects;} 使用以下的摄像机参数 123456789const auto aspect_ratio = double(image_width) / image_height;...vec3 lookfrom(13,2,3);vec3 lookat(0,0,0);vec3 vup(0,1,0);auto dist_to_focus = 10.0;auto aperture = 0.0;camera cam(lookfrom, lookat, vup, 20, aspect_ratio, aperture, dist_to_focus, 0.0, 1.0); 我们将得到: 5. 柏林噪声为了得到一个看上去很cool的纹理, 大部分人使用柏林噪声(Perlin noise)。柏林噪声是以它的发明者Ken Perlin命名的。柏林噪声并不会得到以下的白噪声:取而代之的是一些类似模糊后的白噪声:柏林噪声的关键特点是可复现性。如果输入的是同一个三维空间中的点, 他的输出值总是相同的。柏林噪声的另一个特点是它实现起来简单快捷。所以通常来说我们拿柏林噪声来做一些hack的事情。我会在Andrew Kensler的描述下逐步的实现这些hack的事情。 我们可以用一个随机生成的三维数组铺满(tile)整个空间, 你会得到明显重复的区块:不使用瓷砖贴图的方法, 让我们用哈希表去完成他, 代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class perlin { public: perlin() { ranfloat = new double[point_count]; for (int i = 0; i &lt; point_count; ++i) { ranfloat[i] = random_double(); } perm_x = perlin_generate_perm(); perm_y = perlin_generate_perm(); perm_z = perlin_generate_perm(); } ~perlin() { delete[] ranfloat; delete[] perm_x; delete[] perm_y; delete[] perm_z; } double noise(const vec3&amp; p) const { auto u = p.x() - floor(p.x()); auto v = p.y() - floor(p.y()); auto w = p.z() - floor(p.z()); auto i = static_cast&lt;int&gt;(4*p.x()) &amp; 255; auto j = static_cast&lt;int&gt;(4*p.y()) &amp; 255; auto k = static_cast&lt;int&gt;(4*p.z()) &amp; 255; return ranfloat[perm_x[i] ^ perm_y[j] ^ perm_z[k]]; } private: static const int point_count = 256; double* ranfloat; int* perm_x; int* perm_y; int* perm_z; static int* perlin_generate_perm() { auto p = new int[point_count]; for (int i = 0; i &lt; perlin::point_count; i++) p[i] = i; permute(p, point_count); return p; } static void permute(int* p, int n) { for (int i = n-1; i &gt; 0; i--) { int target = random_int(0, i); int tmp = p[i]; p[i] = p[target]; p[target] = tmp; } }}; 现在让我们来生成一个纹理, 使用范围为0到1的一个float变量来制造灰度图: texture.h12345678910111213#include &quot;perlin.h&quot;class noise_texture : public texture { public: noise_texture() {} virtual vec3 value(double u, double v, const vec3&amp; p) const { return vec3(1,1,1) * noise.noise(p); } public: perlin noise;}; 我们可以把纹理运用在一些球上: main.cc123456789hittable_list two_perlin_spheres() { hittable_list objects; auto pertext = make_shared&lt;noise_texture&gt;(); objects.add(make_shared&lt;sphere&gt;(vec3(0,-1000, 0), 1000, make_shared&lt;lambertian&gt;(pertext))); objects.add(make_shared&lt;sphere&gt;(vec3(0, 2, 0), 2, make_shared&lt;lambertian&gt;(pertext))); return objects;} 并使用和之前相同的摄像机参数: main.cc123456789const auto aspect_ratio = double(image_width) / image_height;...vec3 lookfrom(13,2,3);vec3 lookat(0,0,0);vec3 vup(0,1,0);auto dist_to_focus = 10.0;auto aperture = 0.0;camera cam(lookfrom, lookat, vup, 20, aspect_ratio, aperture, dist_to_focus, 0.0, 1.0); 如我们所愿, 我们成功的使用哈希生成了下面的图案: 为了让它看上去更加平滑, 我们可以采用线性插值: perlin.h12345678910111213141516171819202122232425262728293031323334353637inline double trilinear_interp(double c[2][2][2], double u, double v, double w) { auto accum = 0.0; for (int i=0; i &lt; 2; i++) for (int j=0; j &lt; 2; j++) for (int k=0; k &lt; 2; k++) accum += (i*u + (1-i)*(1-u))* (j*v + (1-j)*(1-v))* (k*w + (1-k)*(1-w))*c[i][j][k]; return accum;}class perlin { public: ... double noise(const vec3&amp; p) const { auto u = p.x() - floor(p.x()); auto v = p.y() - floor(p.y()); auto w = p.z() - floor(p.z()); int i = floor(p.x()); int j = floor(p.y()); int k = floor(p.z()); double c[2][2][2]; for (int di=0; di &lt; 2; di++) for (int dj=0; dj &lt; 2; dj++) for (int dk=0; dk &lt; 2; dk++) c[di][dj][dk] = ranfloat[ perm_x[(i+di) &amp; 255] ^ perm_y[(j+dj) &amp; 255] ^ perm_z[(k+dk) &amp; 255] ]; return trilinear_interp(c, u, v, w); } ... } 我们会得到: 嗯, 现在看上去更好了, 但是还是能明显的看出来有格子的痕迹。其中的一部分是马赫带(Mach bands), 是由线性变化的颜色构成的有名的视觉感知效果。这里我们使用一个标准的解法：用hermite cube来平滑差值。 123456789101112131415class perlin ( public: ... double noise(const vec3&amp; p) const { auto u = p.x() - floor(p.x()); auto v = p.y() - floor(p.y()); auto w = p.z() - floor(p.z()); u = u*u*(3-2*u); v = v*v*(3-2*v); w = w*w*(3-2*w); int i = floor(p.x()); int j = floor(p.y()); int k = floor(p.z()); ... 这样看起来就更加平滑了: 现在这个球看上去变化的频率太低了, 没什么花纹, 我们加入一个scale变量让它更快的发生变化: texture.h12345678910111213class noise_texture : public texture { public: noise_texture() {} noise_texture(double sc) : scale(sc) {} virtual vec3 value(double u, double v, const vec3&amp; p) const {+ return vec3(1,1,1) * noise.noise(scale * p); } public: perlin noise; double scale;}; 会得到: 现在看上去还是有一点格子的感觉, 也许是因为这方法的最大值和最小值总是精确地落在了整数的x/y/z上, Ken Perlin有一个十分聪明的trick, 在网格点使用随机的单位向量替代float(即梯度向量), 用点乘将min和max值推离网格点, 所以我们首先要把random floats改成random vectors。这些梯度向量可以是任意合理的不规则方向的集合, 所以我干脆使用单位向量作为梯度向量: 12345678910111213141516171819202122232425262728class perlin { public: perlin() { ranvec = new vec3[point_count]; for (int i = 0; i &lt; point_count; ++i) { ranvec[i] = unit_vector(vec3::random(-1,1)); } perm_x = perlin_generate_perm(); perm_y = perlin_generate_perm(); perm_z = perlin_generate_perm(); } ~perlin() { delete[] ranvec; delete[] perm_x; delete[] perm_y; delete[] perm_z; } ... private: vec3* ranvec; int* perm_x; int* perm_y; int* perm_z; ...} 现在的Perlin类如下: perlin.h12345678910111213141516171819202122232425class perlin { public: ... double noise(const vec3&amp; p) const { auto u = p.x() - floor(p.x()); auto v = p.y() - floor(p.y()); auto w = p.z() - floor(p.z()); int i = floor(p.x()); int j = floor(p.y()); int k = floor(p.z()); vec3 c[2][2][2]; for (int di=0; di &lt; 2; di++) for (int dj=0; dj &lt; 2; dj++) for (int dk=0; dk &lt; 2; dk++) c[di][dj][dk] = ranvec[ perm_x[(i+di) &amp; 255] ^ perm_y[(j+dj) &amp; 255] ^ pexm_z[(k+dk) &amp; 255] ]; return perlin_interp(c, u, v, w); } ... } 插值部分的代码看上去比之前复杂了一些: 123456789101112131415161718192021222324class perlin { ... private: ... inline double perlin_interp(vec3 c[2][2][2], double u, double v, double w) { auto uu = u*u*(3-2*u); auto vv = v*v*(3-2*v); auto ww = w*w*(3-2*w); auto accum = 0.0; for (int i=0; i &lt; 2; i++) for (int j=0; j &lt; 2; j++) for (int k=0; k &lt; 2; k++) { vec3 weight_v(u-i, v-j, w-k); accum += (i*uu + (1-i)*(1-uu)) * (j*vv + (1-j)*(1-vv)) * (k*ww + (1-k)*(1-ww)) * dot(c[i][j][k], weight_v); } return accum; } ...} 柏林插值的输出结果有可能是负数, 这些负数在伽马校正时经过开平方跟sqrt()会变成NaN。我们将输出结果映射到0与1之间。 perlin.h12345678910111213class noise_texture : public texture { public: noise_texture() {} noise_texture(double sc) : scale(sc) {} virtual vec3 value(double u, double v, const vec3&amp; p) const {+ return vec3(1,1,1) * 0.5 * (1.0 + noise.noise(scale * p)); } public: perlin noise; double scale;}; 最终我们得到一个让人满意的结果: 使用多个频率相加得到复合噪声是一种很常见的做法, 我们常常称之为扰动(turbulence), 是一种由多次噪声运算的结果相加得到的产物。 123456789101112131415161718class perlin { ... public: ... double turb(const vec3&amp; p, int depth=7) const { auto accum = 0.0; vec3 temp_p = p; auto weight = 1.0; for (int i = 0; i &lt; depth; i++) { accum += weight*noise(temp_p); weight *= 0.5; temp_p *= 2; } return fabs(accum); } ... 这里的fabs()是math.h里的求绝对值的函数。 直接使用turb函数来产生纹理, 会得到一个看上去像伪装网一样的东西: 然而扰动函数通常是间接使用的, 在程序生成纹理这方面的”hello world”是一个类似大理石的纹理。基本思路是让颜色与sine函数的值成比例, 并使用扰动函数去调整相位(平移了sin(x)中的x), 使得带状条纹起伏波荡。修正我们直接使用扰动turb或者噪声noise给颜色赋值的方法， 我们会得到一个类似大理石的纹理: 12345678910111213class noise_texture : public texture { public: noise_texture() {} noise_texture(double sc) : scale(sc) {} virtual vec3 value(double u, double v, const vec3&amp; p) const {+ return vec3(1,1,1) * 0.5 * (1 + sin(scale*p.z() + 10*noise.turb(p))); } public: perlin noise; double scale;}; 最终得到: 6. 图片纹理映射我们之前使用射入点p来映射(原文to index)类似大理石那样程序生成的纹理。我们也能读取一张图片, 并将一个2D$(u,v)$的坐标系映射在图片上。 使用$(u,v)$坐标的一个直接的想法是将u与v调整比例后取整, 然后将其对应到像素坐标$(i,j)$上, 这很糟糕, 因为这样每次图片分辨率发生变化时, 我们都要修改代码。所以相对的, 图形学界中广泛认可的非官方标准之一是采用纹理坐标系代替图像坐标系。即使用$[0,1]$的小数来表示图像中的位置。举例来说, 对于一张宽度为$N_x$高度为$N_y$的图像中的像素$(i,j)$ , 其像素坐标系下的坐标为: $$ u = \\frac{i}{N_x-1} $$$$ v = \\frac{j}{N_y-1} $$ 对于一个hittable来说, 我们还需要在hit record中加入 $u$ 和 $v$ 的记录。对于椭圆来说, uv的计算是基于经度和纬度的的, 换句话说, 是基于球面坐标的。所以当我们有一个球面坐标$(\\theta,\\phi)$， 我们只需要按比例转化一下就能得到uv坐标。如果$\\theta$是朝下距离极轴的角度, $\\phi$是绕极轴旋转的角度, 将其映射到$[0,1]$的过程为: $$ u = \\frac{\\phi}{2\\pi} $$$$ v = \\frac{\\theta}{\\pi} $$ 为了计算 $\\theta$ 和 $\\phi$, 对于任意给出的球面上的射入点, 将球面坐标系转化为直角坐标系的方程为: $$ x = \\cos(\\phi) \\cos(\\theta) $$$$ y = \\sin(\\phi) \\cos(\\theta) $$$$ z = \\sin(\\theta) $$ 我们现在只要把它倒过来就行, 因为我们可爱的&lt;cmath&gt;库函数atan2()的关系, 给出任意一个角度的sine和cosine值, 我们就能得到这个角的角度值。 所以我们可以像这样传入x, y的值($\\sin(\\theta)$与$\\cos(\\theta)$相除抵消得到$\\tan(\\theta)$): $$ \\phi = \\text{atan2}(y, x) $$ $atan2$函数的返回值范围为 $-\\pi$ 到 $\\pi$ 【译注:即返回弧度(radius)】所以我们这里还要小心一下。 相对的, 求角$\\theta$更为简单直接: $$ \\theta = \\text{asin}(z) $$ 函数返回值范围为$-\\pi/2$ 到 $\\pi/2$ 所以对于一个球体来说, $(u,v)$ 坐标的计算是由一个工具函数完成的, 该函数假定输入参数为单位圆上的点, 所以我们传入参数时需要注意一下: sphere.h in function hit1+get_sphere_uv((rec.p-center)/radius, rec.u, rec.v); 工具函数的具体实现为: sphere.h123456void get_sphere_uv(const vec3&amp; p, double&amp; u, double&amp; v) { auto phi = atan2(p.z(), p.x()); auto theta = asin(p.y()); u = 1-(phi + pi) / (2*pi); v = (theta + pi/2) / pi;} 现在我们还需要新建一个texture类来存放图片。我现在将使用我最喜欢的图像工具库stb_image.h(点击下载)。它将图片信息读入一个无符号字符类型(unsigned char)的大数组中。unsigned char(8bit, 0255)的值即为RGBs中表示明暗的0255。 surface_texture.h123456789101112131415161718192021222324252627282930313233343536#include &quot;texture.h&quot;class image_texture : public texture { public: image_texture() {} image_texture(unsigned char *pixels, int A, int B) : data(pixels), nx(A), ny(B) {} ~image_texture() { delete data; } virtual vec3 value(double u, double v, const vec3&amp; p) const { // If we have no texture data, then always emit cyan (as a debugging aid). if (data == nullptr) return vec3(0,1,1); auto i = static_cast&lt;int&gt;(( u)*nx); auto j = static_cast&lt;int&gt;((1-v)*ny-0.001); if (i &lt; 0) i = 0; if (j &lt; 0) j = 0; if (i &gt; nx-1) i = nx-1; if (j &gt; ny-1) j = ny-1; auto r = static_cast&lt;int&gt;(data[3*i + 3*nx*j+0]) / 255.0; auto g = static_cast&lt;int&gt;(data[3*i + 3*nx*j+1]) / 255.0; auto b = static_cast&lt;int&gt;(data[3*i + 3*nx*j+2]) / 255.0; return vec3(r, g, b); } public: unsigned char *data; int nx, ny;}; 使用这样的数组来储存图像十分的基础。感谢stb_image.h, 导入图片变得异常简单, 只需在main.cc中包含函数头stb_image.h: 12#define STB_IMAGE_IMPLEMENTATION#include &quot;stb_image.h&quot; 我们earthmap.jpg中从读取数据(这张图是我从网上随便找的 – 这里你使用任何图片都行, 最好符合球体的投影标准), 并将它部署给一个漫反射材质, 代码如下: main.cc12345678910hittable_list earth() { int nx, ny, nn; unsigned char* texture_data = stbi_load(&quot;earthmap.jpg&quot;, &amp;nx, &amp;ny, &amp;nn, 0); auto earth_surface = make_shared&lt;lambertian&gt;(make_shared&lt;image_texture&gt;(texture_data, nx, ny)); auto globe = make_shared&lt;sphere&gt;(vec3(0,0,0), 2, earth_surface); return hittable_list(globe);} 我们现在开始感受texture类的魅力了: 我们现在可以将任意一种类的纹理(贴图, 大理石)运用到lambertian材质上, 并且lambertian材质并不需要关心其输入的是图片还是其他的什么。 如果你想测试的话, 我们先应用这个球, 然后暂时修改ray_color函数, 使其只返回attenuation的值, 你会得到下面的结果: 7. 矩形和光源我们首先来做一个发射光线的材质。我们需要加入一个发射函数(我们可以把这部分内容加在hit_record里 —— 只是设计上的品味不同罢了)。就像背景区域一样, 这个材质只要指定自己发射的光线的颜色, 并且不用考虑任何反射折射的问题。所以它很简单: 1234567891011121314151617class diffuse_light : public material { public: diffuse_light(shared_ptr&lt;texture&gt; a) : emit(a) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { return false; } virtual vec3 emitted(double u, double v, const vec3&amp; p) const { return emit-&gt;value(u, v, p); } public: shared_ptr&lt;texture&gt; emit;}; 为了不去给每个不是光源的材质实现emitted()函数, 我这里并不使用纯虚函数, 并让函数默认返回黑色: diff12345678910class material { public:+ virtual vec3 emitted(double u, double v, const vec3&amp; p) const {+ return vec3(0,0,0);+ } virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const = 0;}; 接下来我们想要一个纯黑的背景, 并让所有光线都来自于我们的光源材质。要实现它, 我们得在ray_color函数中加入一个背景色的变量, 然后注意由emitted函数产生的新的颜色值。【思考一个简单场景, 里面只有几个物体和一个光源, 有助于理解这段递归】 12345678910111213141516171819202122232425262728vec3 ray_color(const ray&amp; r, const vec3&amp; background, const hittable&amp; world, int depth) { hit_record rec; // If we've exceeded the ray bounce limit, no more light is gathered. if (depth &lt;= 0) return vec3(0,0,0); // If the ray hits nothing, return the background color. if (!world.hit(r, 0.001, infinity, rec)) return background; ray scattered; vec3 attenuation; vec3 emitted = rec.mat_ptr-&gt;emitted(rec.u, rec.v, rec.p); if (!rec.mat_ptr-&gt;scatter(r, rec, attenuation, scattered)) return emitted; return emitted + attenuation * ray_color(scattered, background, world, depth-1); } ... int main() { ... const vec3 background(0,0,0); ... color += ray_color(r, background, world, max_depth); ... } 现在我们来加入一些矩形。在建模人为环境时使用矩形会很方便。我超喜欢用轴对齐的矩形因为他们很简单(我们接下来会加入实例(instance)的功能, 待会就可以旋转这些矩形)。 首先将一个矩形放在xy平面, 通常我们使用一个z值来定义这样的平面。举例来说, $z = k$。一个轴对齐的矩形是由 $x=x_0$, $x=x_1$, $y=y_0$, 以及 $y=y_1$ 这四条直线构成的。 为了判断光线是否与这样的矩形相交, 我们先来判断射线击中平面上的哪个点。回想一下射线方程 $p(t) = \\mathbf{a} + t \\cdot \\vec{\\mathbf{b}}$, 其中射线的z值又由平面$z(t) = \\mathbf{a}_z + t \\cdot \\vec{\\mathbf{b}}_z$决定。合并整理我们将获得当$z=k$时t的值 $$ t = \\frac{k-\\mathbf{a}_z}{\\vec{\\mathbf{b}}_z} $$ 一旦我们求出$t$, 我们就能将其带入求解 $x$ 和 $y$的等式$$ x = \\mathbf{a}_x + t \\cdot \\vec{\\mathbf{b}}_x $$$$ y = \\mathbf{a}_y + t \\cdot \\vec{\\mathbf{b}}_y $$ 如果 $x_0 &lt; x &lt; x_1$ 与 $y_0 &lt; y &lt; y_1$, 那么射线就击中了这个矩形。 我们的xy_rect类是这样的： 123456789101112131415161718class xy_rect: public hittable { public: xy_rect() {} xy_rect(double _x0, double _x1, double _y0, double _y1, double _k, shared_ptr&lt;material&gt; mat) : x0(_x0), x1(_x1), y0(_y0), y1(_y1), k(_k), mp(mat) {}; virtual bool hit(const ray&amp; r, double t0, double t1, hit_record&amp; rec) const; virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const { output_box = aabb(vec3(x0,y0, k-0.0001), vec3(x1, y1, k+0.0001)); return true; } public: shared_ptr&lt;material&gt; mp; double x0, x1, y0, y1, k;}; hit函数是这样的: 1234567891011121314151617bool xy_rect::hit(const ray&amp; r, double t0, double t1, hit_record&amp; rec) const { auto t = (k-r.origin().z()) / r.direction().z(); if (t &lt; t0 || t &gt; t1) return false; auto x = r.origin().x() + t*r.direction().x(); auto y = r.origin().y() + t*r.direction().y(); if (x &lt; x0 || x &gt; x1 || y &lt; y0 || y &gt; y1) return false; rec.u = (x-x0)/(x1-x0); rec.v = (y-y0)/(y1-y0); rec.t = t; vec3 outward_normal = vec3(0, 0, 1); rec.set_face_normal(r, outward_normal); rec.mat_ptr = mp; rec.p = r.at(t); return true; } 如果我们把一个矩形设置为光源: 12345678910111213hittable_list simple_light() { hittable_list objects; auto pertext = make_shared&lt;noise_texture&gt;(4); objects.add(make_shared&lt;sphere&gt;(vec3(0,-1000, 0), 1000, make_shared&lt;lambertian&gt;(pertext))); objects.add(make_shared&lt;sphere&gt;(vec3(0,2,0), 2, make_shared&lt;lambertian&gt;(pertext))); auto difflight = make_shared&lt;diffuse_light&gt;(make_shared&lt;constant_texture&gt;(vec3(4,4,4))); objects.add(make_shared&lt;sphere&gt;(vec3(0,7,0), 2, difflight)); objects.add(make_shared&lt;xy_rect&gt;(3, 5, 1, 3, -2, difflight)); return objects; } 我们会得到: 注意现在光比$(1,1,1)$还要亮, 所以这个亮度足够它去照亮其他东西了。 同样的我们在做一些球型光源 现在让我们加入剩下的两个轴, 并完成著名的Cornell Box。 xz和yz平面是这样的:【实话说这样写代码有些冗余了】 aarect.h12345678910111213141516171819202122232425262728293031323334353637class xz_rect: public hittable { public: xz_rect() {} xz_rect(double _x0, double _x1, double _z0, double _z1, double _k, shared_ptr&lt;material&gt; mat) : x0(_x0), x1(_x1), z0(_z0), z1(_z1), k(_k), mp(mat) {}; virtual bool hit(const ray&amp; r, double t0, double t1, hit_record&amp; rec) const; virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const { output_box = aabb(vec3(x0,k-0.0001,z0), vec3(x1, k+0.0001, z1)); return true; } public: shared_ptr&lt;material&gt; mp; double x0, x1, z0, z1, k; }; class yz_rect: public hittable { public: yz_rect() {} yz_rect(double _y0, double _y1, double _z0, double _z1, double _k, shared_ptr&lt;material&gt; mat) : y0(_y0), y1(_y1), z0(_z0), z1(_z1), k(_k), mp(mat) {}; virtual bool hit(const ray&amp; r, double t0, double t1, hit_record&amp; rec) const; virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const { output_box = aabb(vec3(k-0.0001, y0, z0), vec3(k+0.0001, y1, z1)); return true; } public: shared_ptr&lt;material&gt; mp; double y0, y1, z0, z1, k; }; 当然hit函数也和之前一样: aarect.h1234567891011121314151617181920212223242526272829303132333435bool xz_rect::hit(const ray&amp; r, double t0, double t1, hit_record&amp; rec) const { auto t = (k-r.origin().y()) / r.direction().y(); if (t &lt; t0 || t &gt; t1) return false; auto x = r.origin().x() + t*r.direction().x(); auto z = r.origin().z() + t*r.direction().z(); if (x &lt; x0 || x &gt; x1 || z &lt; z0 || z &gt; z1) return false; rec.u = (x-x0)/(x1-x0); rec.v = (z-z0)/(z1-z0); rec.t = t; vec3 outward_normal = vec3(0, 1, 0); rec.set_face_normal(r, outward_normal); rec.mat_ptr = mp; rec.p = r.at(t); return true; } bool yz_rect::hit(const ray&amp; r, double t0, double t1, hit_record&amp; rec) const { auto t = (k-r.origin().x()) / r.direction().x(); if (t &lt; t0 || t &gt; t1) return false; auto y = r.origin().y() + t*r.direction().y(); auto z = r.origin().z() + t*r.direction().z(); if (y &lt; y0 || y &gt; y1 || z &lt; z0 || z &gt; z1) return false; rec.u = (y-y0)/(y1-y0); rec.v = (z-z0)/(z1-z0); rec.t = t; vec3 outward_normal = vec3(1, 0, 0); rec.set_face_normal(r, outward_normal); rec.mat_ptr = mp; rec.p = r.at(t); return true; } 让我们做五堵墙壁, 并点亮这个盒子: 12345678910111213141516hittable_list cornell_box() { hittable_list objects; auto red = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.65, 0.05, 0.05))); auto white = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.73, 0.73, 0.73))); auto green = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.12, 0.45, 0.15))); auto light = make_shared&lt;diffuse_light&gt;(make_shared&lt;constant_texture&gt;(vec3(15, 15, 15))); objects.add(make_shared&lt;yz_rect&gt;(0, 555, 0, 555, 555, green)); objects.add(make_shared&lt;yz_rect&gt;(0, 555, 0, 555, 0, red)); objects.add(make_shared&lt;xz_rect&gt;(213, 343, 227, 332, 554, light)); objects.add(make_shared&lt;xz_rect&gt;(0, 555, 0, 555, 0, white)); objects.add(make_shared&lt;xy_rect&gt;(0, 555, 0, 555, 555, white)); objects.add(make_shared&lt;xz_rect&gt;(0, 555, 0, 555, 555, white)); return objects; } 下面是新的摄像机的参数: mian.cc12345678910const auto aspect_ratio = double(image_width) / image_height;...vec3 lookfrom(278, 278, -800);vec3 lookat(278,278,0);vec3 vup(0,1,0);auto dist_to_focus = 10.0;auto aperture = 0.0;auto vfov = 40.0;camera cam(lookfrom, lookat, vup, vfov, aspect_ratio, aperture, dist_to_focus, 0.0, 1.0); 我们会得到如下的结果: 这看上去都是噪点, 因为光太小了。我们还有一个问题: 一些墙壁的朝向反了。我们还没有让漫反射材质的正反两面有相同的表现。但cornell box的内外部是不同的模式。一个矩形物体的正面往往是$(1, 0, 0)$, $(0, 1, 0)$, 或者 $(0, 0, 1)$ 这几个方向。我们需要一种翻转矩形朝向的方法。所以让我们来一个新的hittable类吧, 别得啥都不干, 专门用来翻转正反面。 12345678910111213141516171819class flip_face : public hittable { public: flip_face(shared_ptr&lt;hittable&gt; p) : ptr(p) {} virtual bool hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const { if (!ptr-&gt;hit(r, t_min, t_max, rec)) return false; rec.front_face = !rec.front_face; return true; } virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const { return ptr-&gt;bounding_box(t0, t1, output_box); } public: shared_ptr&lt;hittable&gt; ptr; }; 这是生成一个cornell box的代码: diff123456789101112131415161718 hittable_list cornell_box() { hittable_list objects; auto red = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.65, 0.05, 0.05))); auto white = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.73, 0.73, 0.73))); auto green = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.12, 0.45, 0.15))); auto light = make_shared&lt;diffuse_light&gt;(make_shared&lt;constant_texture&gt;(vec3(15, 15, 15)));+ objects.add(make_shared&lt;flip_face&gt;(make_shared&lt;yz_rect&gt;(0, 555, 0, 555, 555, green))); objects.add(make_shared&lt;yz_rect&gt;(0, 555, 0, 555, 0, red)); objects.add(make_shared&lt;xz_rect&gt;(213, 343, 227, 332, 554, light));+ objects.add(make_shared&lt;flip_face&gt;(make_shared&lt;xz_rect&gt;(0, 555, 0, 555, 555, white)));+ objects.add(make_shared&lt;xz_rect&gt;(0, 555, 0, 555, 0, white));+ objects.add(make_shared&lt;flip_face&gt;(make_shared&lt;xy_rect&gt;(0, 555, 0, 555, 555, white))); return objects; } 看呀: 8. 实例Cornell Box里面一般都有两个相对墙面有些角度的长方体。首先我们先把轴对齐的长方体图元做出来。每个长方体是由6个平面构成的: box.h1234567891011121314151617181920212223242526272829303132333435363738class box: public hittable { public: box() {} box(const vec3&amp; p0, const vec3&amp; p1, shared_ptr&lt;material&gt; ptr); virtual bool hit(const ray&amp; r, double t0, double t1, hit_record&amp; rec) const; virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const { output_box = aabb(box_min, box_max); return true; } public: vec3 box_min; vec3 box_max; hittable_list sides;};box::box(const vec3&amp; p0, const vec3&amp; p1, shared_ptr&lt;material&gt; ptr) { box_min = p0; box_max = p1; sides.add(make_shared&lt;xy_rect&gt;(p0.x(), p1.x(), p0.y(), p1.y(), p1.z(), ptr)); sides.add(make_shared&lt;flip_face&gt;( make_shared&lt;xy_rect&gt;(p0.x(), p1.x(), p0.y(), p1.y(), p0.z(), ptr))); sides.add(make_shared&lt;xz_rect&gt;(p0.x(), p1.x(), p0.z(), p1.z(), p1.y(), ptr)); sides.add(make_shared&lt;flip_face&gt;( make_shared&lt;xz_rect&gt;(p0.x(), p1.x(), p0.z(), p1.z(), p0.y(), ptr))); sides.add(make_shared&lt;yz_rect&gt;(p0.y(), p1.y(), p0.z(), p1.z(), p1.x(), ptr)); sides.add(make_shared&lt;flip_face&gt;( make_shared&lt;yz_rect&gt;(p0.y(), p1.y(), p0.z(), p1.z(), p0.x(), ptr)));}bool box::hit(const ray&amp; r, double t0, double t1, hit_record&amp; rec) const { return sides.hit(r, t0, t1, rec);} 现在我们可以加入两个长方体了(但是没有旋转的角度) 12objects.add(make_shared&lt;box&gt;(vec3(130, 0, 65), vec3(295, 165, 230), white));objects.add(make_shared&lt;box&gt;(vec3(265, 0, 295), vec3(430, 330, 460), white)); 现在有: 现在我们有了这两个长方体, 为了让它看上去更加接近正宗的Cornell Box, 我们还需要让他旋转一下。在光线追踪中, 我们时常使用实例(instance)来完成这个工作。实例是一种经过旋转过或者平移等操作的几何图元。在光线追踪中, 这其实很简单。我们并不需要去移动任何东西。相对的, 我们只需将射线。举例来说, 想象一个平移操作, 我们可以将位于原点的粉红色盒子所有的组成部分的的x值+2, 或者就把盒子放在那里, 然后在hit函数中, 相对的将射线的原点-2。(这也是我们在ray tracing中惯用的做法) 【译注: 射线原点-2计算出hit record后, 得到是左边盒子, 最后还要将计算结果+2, 才能获得正确的射入点(右边盒子)】 你把刚刚的这个操作当成是平移还是坐标系的转换都行, 随你的喜好。移动hittable类的translate的代码如下 12345678910111213141516171819202122232425262728293031323334class translate : public hittable { public: translate(shared_ptr&lt;hittable&gt; p, const vec3&amp; displacement) : ptr(p), offset(displacement) {} virtual bool hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const; virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const; public: shared_ptr&lt;hittable&gt; ptr; vec3 offset;};bool translate::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const { ray moved_r(r.origin() - offset, r.direction(), r.time()); if (!ptr-&gt;hit(moved_r, t_min, t_max, rec)) return false; rec.p += offset; rec.set_face_normal(moved_r, rec.normal); return true;}bool translate::bounding_box(double t0, double t1, aabb&amp; output_box) const { if (!ptr-&gt;bounding_box(t0, t1, output_box)) return false; output_box = aabb( output_box.min() + offset, output_box.max() + offset); return true;} 旋转就没有那么容易理解或列出算式了。一个常用的图像技巧是将所有的旋转都当成是绕xyz轴旋转。首先, 让我们绕z轴旋转。这样只会改变xy而不会改变z值。 这里包含了一些三角几何. 我这里就不展开了。你要知道这其实很简单, 并不需要太多的几何知识, 你能在任何一本图形学的教材或者课堂笔记中找到它。绕z轴逆时针旋转的公式如下: $$ x’ = \\cos(\\theta) \\cdot x - \\sin(\\theta) \\cdot y $$$$ y’ = \\sin(\\theta) \\cdot x + \\cos(\\theta) \\cdot y $$ 这个公式的伟大之处在于它对任何$\\theta$都成立, 你完全不用去考虑什么象限啊或者别的类似的东西。如果要顺时针旋转, 只需把$\\theta$改成$-\\theta$即可。来, 回想一下$\\cos(\\theta) = \\cos(-\\theta)$ 和 $\\sin(-\\theta) = -\\sin(\\theta)$, 所以逆运算的公式很简单。 类似的, 绕y轴旋转(也正是我们相对这两个长方体做的事情)的公式如下: $$ x’ = \\cos(\\theta) \\cdot x + \\sin(\\theta) \\cdot z $$$$ z’ = -\\sin(\\theta) \\cdot x + \\cos(\\theta) \\cdot z $$ 绕x轴旋转的公式如下: $$ y’ = \\cos(\\theta) \\cdot y - \\sin(\\theta) \\cdot z $$$$ z’ = \\sin(\\theta) \\cdot y + \\cos(\\theta) \\cdot z $$ 和平移变换不同, 旋转时表面法向也发生了变化。所以在计算完hit函数后我们还要重新计算法向量。幸好对于旋转来说, 我们对法向量使用相同的公式变换一下即可。如果你加入了缩放(Scale), 那么这下事情就复杂多了。点击我们的网页 https://in1weekend.blogspot.com/ 了解详细信息。 对一个绕y轴的旋转变换来说, 我们有: hittable.h1234567891011121314151617class rotate_y : public hittable { public: rotate_y(shared_ptr&lt;hittable&gt; p, double angle); virtual bool hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const; virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const { output_box = bbox; return hasbox; } public: shared_ptr&lt;hittable&gt; ptr; double sin_theta; double cos_theta; bool hasbox; aabb bbox;}; 加上构造函数: 12345678910111213141516171819202122232425262728293031rotate_y::rotate_y(shared_ptr&lt;hittable&gt; *p, double angle) : ptr(p) { auto radians = degrees_to_radians(angle); sin_theta = sin(radians); cos_theta = cos(radians); hasbox = ptr-&gt;bounding_box(0, 1, bbox); vec3 min( infinity, infinity, infinity); vec3 max(-infinity, -infinity, -infinity); for (int i = 0; i &lt; 2; i++) { for (int j = 0; j &lt; 2; j++) { for (int k = 0; k &lt; 2; k++) { auto x = i*bbox.max().x() + (1-i)*bbox.min().x(); auto y = j*bbox.max().y() + (1-j)*bbox.min().y(); auto z = k*bbox.max().z() + (1-k)*bbox.min().z(); auto newx = cos_theta*x + sin_theta*z; auto newz = -sin_theta*x + cos_theta*z; vec3 tester(newx, y, newz); for (int c = 0; c &lt; 3; c++) { min[c] = ffmin(min[c], tester[c]); max[c] = ffmax(max[c], tester[c]); } } } } bbox = aabb(min, max);} 以及hit函数: 1234567891011121314151617181920212223242526272829bool rotate_y::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const { vec3 origin = r.origin(); vec3 direction = r.direction(); origin[0] = cos_theta*r.origin()[0] - sin_theta*r.origin()[2]; origin[2] = sin_theta*r.origin()[0] + cos_theta*r.origin()[2]; direction[0] = cos_theta*r.direction()[0] - sin_theta*r.direction()[2]; direction[2] = sin_theta*r.direction()[0] + cos_theta*r.direction()[2]; ray rotated_r(origin, direction, r.time()); if (!ptr-&gt;hit(rotated_r, t_min, t_max, rec)) return false; vec3 p = rec.p; vec3 normal = rec.normal; p[0] = cos_theta*rec.p[0] + sin_theta*rec.p[2]; p[2] = -sin_theta*rec.p[0] + cos_theta*rec.p[2]; normal[0] = cos_theta*rec.normal[0] + sin_theta*rec.normal[2]; normal[2] = -sin_theta*rec.normal[0] + cos_theta*rec.normal[2]; rec.p = p; rec.set_face_normal(rotated_r, normal); return true;} 并且修改一下生成cornell box的Cornell函数: 123456789shared_ptr&lt;hittable&gt; box1 = make_shared&lt;box&gt;(vec3(0, 0, 0), vec3(165, 330, 165), white);box1 = make_shared&lt;rotate_y&gt;(box1, 15);box1 = make_shared&lt;translate&gt;(box1, vec3(265,0,295));objects.add(box1);shared_ptr&lt;hittable&gt; box2 = make_shared&lt;box&gt;(vec3(0,0,0), vec3(165,165,165), white);box2 = make_shared&lt;rotate_y&gt;(box2, -18);box2 = make_shared&lt;translate&gt;(box2, vec3(130,0,65));objects.add(box2); 最后得到: 9. 体积体给光线追踪器加入烟/雾/水汽是一件很不错的事情。这些东西常常被称为体积体(volumes)或者可参与介质(participating media)。次表面散射(sub surface scatter, SSS)是另一个不错的特性, 有点像物体内部的浓雾。加入这部分内容会导致代码结构的混乱。因为体积体和平面表面是完全不同的两种东西。但我们有一个可爱的小技巧: 将体积体表示为一个随机表面。一团烟雾在其实可以用一个概率上不确定在什么位置的平面来代替。当你看到代码后, 你就会更有感觉了。 首先让我们来生成一个固定密度的体积体。光线可以在体积体内部发生散射, 也可以像图中的中间那条射线一样直接穿过去。体积体越薄越透明, 直接穿过去的情况就越有可能会发生。光线在体积体中直线传播所经过的距离也决定了光线采用图中哪种方式通过体积体。 当光线射入体积体时, 它可能在任意一点发生散射。体积体越浓, 越可能发生散射。在任意微小的距离差$\\Delta L$发生散射的概率如下: $$ \\text{probability} = C \\cdot \\Delta L $$ 其中$C$是体积体的光学密度比例常数。 经过了一系列不同的等式运算, 你将会随机的得到一个光线发生散射的距离值。如果根据这个距离来说, 散射点在体积体外, 那么我们认为没有相交, 不调用hit函数。对于一个静态的体积体来说, 我们只需要他的密度C和边界。我会用另一个hittable物体来表示体积体的边界: 12345678910111213141516171819class constant_medium : public hittable { public: constant_medium(shared_ptr&lt;hittable&gt; b, double d, shared_ptr&lt;texture&gt; a) : boundary(b), neg_inv_density(-1/d) { phase_function = make_shared&lt;isotropic&gt;(a); } virtual bool hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const; virtual bool bounding_box(double t0, double t1, aabb&amp; output_box) const { return boundary-&gt;bounding_box(t0, t1, output_box); } public: shared_ptr&lt;hittable&gt; boundary; shared_ptr&lt;material&gt; phase_function; double neg_inv_density;}; 对于散射的方向来说, 我们采用各项同性(isotropic)的随机单位向量大法 123456789101112131415class isotropic : public material { public: isotropic(shared_ptr&lt;texture&gt; a) : albedo(a) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { scattered = ray(rec.p, random_in_unit_sphere(), r_in.time()); attenuation = albedo-&gt;value(rec.u, rec.v, rec.p); return true; } public: shared_ptr&lt;texture&gt; albedo;}; hit函数如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546bool constant_medium::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const { // Print occasional samples when debugging. To enable, set enableDebug true. const bool enableDebug = false; const bool debugging = enableDebug &amp;&amp; random_double() &lt; 0.00001; hit_record rec1, rec2; if (!boundary-&gt;hit(r, -infinity, infinity, rec1)) return false; if (!boundary-&gt;hit(r, rec1.t+0.0001, infinity, rec2)) return false; if (debugging) std::cerr &lt;&lt; &quot;\\nt0=&quot; &lt;&lt; rec1.t &lt;&lt; &quot;, t1=&quot; &lt;&lt; rec2.t &lt;&lt; '\\n'; if (rec1.t &lt; t_min) rec1.t = t_min; if (rec2.t &gt; t_max) rec2.t = t_max; if (rec1.t &gt;= rec2.t) return false; if (rec1.t &lt; 0) rec1.t = 0; const auto ray_length = r.direction().length(); const auto distance_inside_boundary = (rec2.t - rec1.t) * ray_length; const auto hit_distance = neg_inv_density * log(random_double()); if (hit_distance &gt; distance_inside_boundary) return false; rec.t = rec1.t + hit_distance / ray_length; rec.p = r.at(rec.t); if (debugging) { std::cerr &lt;&lt; &quot;hit_distance = &quot; &lt;&lt; hit_distance &lt;&lt; '\\n' &lt;&lt; &quot;rec.t = &quot; &lt;&lt; rec.t &lt;&lt; '\\n' &lt;&lt; &quot;rec.p = &quot; &lt;&lt; rec.p &lt;&lt; '\\n'; } rec.normal = vec3(1,0,0); // arbitrary rec.front_face = true; // also arbitrary rec.mat_ptr = phase_function; return true;} 我们一定要小心与边界相关的逻辑, 因为我们要确保当射线原点在体积体内部时, 光线依然会发生散射。在云中, 光线反复发生散射, 这是一种很常见的现象。 另外, 上述代码只能确保射线只会射入体积体一次, 之后再也不进入体积体的情况。换句话说, 它假定体积体的边界是一个凸几何体。所以这个狭义的实现只对球体或者长方体这样的物体生效。但是对于当中有洞的那种形状, 如甜甜圈就不行了。写一个能处理任意形状的实现是完全可行的, 但我们把这部分内容留给我们的读者作为练习。 如果我们将两个长方体替换为烟和雾(深色与浅色的粒子)并使用一个更大的灯光(同时更加昏暗以至于不会炸了这个场景)让场景更快的融合在一起。 123456789101112131415161718192021222324252627282930hittable_list cornell_smoke() { hittable_list objects; auto red = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.65, 0.05, 0.05))); auto white = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.73, 0.73, 0.73))); auto green = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.12, 0.45, 0.15))); auto light = make_shared&lt;diffuse_light&gt;(make_shared&lt;constant_texture&gt;(vec3(7, 7, 7))); objects.add(make_shared&lt;flip_face&gt;(make_shared&lt;yz_rect&gt;(0, 555, 0, 555, 555, green))); objects.add(make_shared&lt;yz_rect&gt;(0, 555, 0, 555, 0, red)); objects.add(make_shared&lt;xz_rect&gt;(113, 443, 127, 432, 554, light)); objects.add(make_shared&lt;flip_face&gt;(make_shared&lt;xz_rect&gt;(0, 555, 0, 555, 555, white))); objects.add(make_shared&lt;xz_rect&gt;(0, 555, 0, 555, 0, white)); objects.add(make_shared&lt;flip_face&gt;(make_shared&lt;xy_rect&gt;(0, 555, 0, 555, 555, white))); shared_ptr&lt;hittable&gt; box1 = make_shared&lt;box&gt;(vec3(0,0,0), vec3(165,330,165), white); box1 = make_shared&lt;rotate_y&gt;(box1, 15); box1 = make_shared&lt;translate&gt;(box1, vec3(265,0,295)); shared_ptr&lt;hittable&gt; box2 = make_shared&lt;box&gt;(vec3(0,0,0), vec3(165,165,165), white); box2 = make_shared&lt;rotate_y&gt;(box2, -18); box2 = make_shared&lt;translate&gt;(box2, vec3(130,0,65)); objects.add( make_shared&lt;constant_medium&gt;(box1, 0.01, make_shared&lt;constant_texture&gt;(vec3(0,0,0)))); objects.add( make_shared&lt;constant_medium&gt;(box2, 0.01, make_shared&lt;constant_texture&gt;(vec3(1,1,1)))); return objects;} 我们会得到: 10. 一个测试所有新特性的场景让我们把所有东西放在一起吧!使用一个薄雾盖住所有东西, 并加入一个蓝色的次表面反射球体(这种说法不太清楚, 实际上次表面材质就是在电介质内部填充体积体)。现在这个渲染器的最大局限就是没有阴影光线。但是因此我们能不花代价的得到散焦和次表面。这是一把设计上的双刃剑。 main.cc12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970hittable_list final_scene() { hittable_list boxes1; auto ground = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.48, 0.83, 0.53))); const int boxes_per_side = 20; for (int i = 0; i &lt; boxes_per_side; i++) { for (int j = 0; j &lt; boxes_per_side; j++) { auto w = 100.0; auto x0 = -1000.0 + i*w; auto z0 = -1000.0 + j*w; auto y0 = 0.0; auto x1 = x0 + w; auto y1 = random_double(1,101); auto z1 = z0 + w; boxes1.add(make_shared&lt;box&gt;(vec3(x0,y0,z0), vec3(x1,y1,z1), ground)); } } hittable_list objects; objects.add(make_shared&lt;bvh_node&gt;(boxes1, 0, 1)); auto light = make_shared&lt;diffuse_light&gt;(make_shared&lt;constant_texture&gt;(vec3(7, 7, 7))); objects.add(make_shared&lt;xz_rect&gt;(123, 423, 147, 412, 554, light)); auto center1 = vec3(400, 400, 200); auto center2 = center1 + vec3(30,0,0); auto moving_sphere_material = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.7, 0.3, 0.1))); objects.add(make_shared&lt;moving_sphere&gt;(center1, center2, 0, 1, 50, moving_sphere_material)); objects.add(make_shared&lt;sphere&gt;(vec3(260, 150, 45), 50, make_shared&lt;dielectric&gt;(1.5))); objects.add(make_shared&lt;sphere&gt;( vec3(0, 150, 145), 50, make_shared&lt;metal&gt;(vec3(0.8, 0.8, 0.9), 10.0) )); auto boundary = make_shared&lt;sphere&gt;(vec3(360, 150, 145), 70, make_shared&lt;dielectric&gt;(1.5)); objects.add(boundary); objects.add(make_shared&lt;constant_medium&gt;( boundary, 0.2, make_shared&lt;constant_texture&gt;(vec3(0.2, 0.4, 0.9)) )); boundary = make_shared&lt;sphere&gt;(vec3(0, 0, 0), 5000, make_shared&lt;dielectric&gt;(1.5)); objects.add(make_shared&lt;constant_medium&gt;( boundary, .0001, make_shared&lt;constant_texture&gt;(vec3(1,1,1)))); int nx, ny, nn; auto tex_data = stbi_load(&quot;earthmap.jpg&quot;, &amp;nx, &amp;ny, &amp;nn, 0); auto emat = make_shared&lt;lambertian&gt;(make_shared&lt;image_texture&gt;(tex_data, nx, ny)); objects.add(make_shared&lt;sphere&gt;(vec3(400,200, 400), 100, emat)); auto pertext = make_shared&lt;noise_texture&gt;(0.1); objects.add(make_shared&lt;sphere&gt;(vec3(220,280, 300), 80, make_shared&lt;lambertian&gt;(pertext))); hittable_list boxes2; auto white = make_shared&lt;lambertian&gt;(make_shared&lt;constant_texture&gt;(vec3(0.73, 0.73, 0.73))); int ns = 1000; for (int j = 0; j &lt; ns; j++) { boxes2.add(make_shared&lt;sphere&gt;(vec3::random(0,165), 10, white)); } objects.add(make_shared&lt;translate&gt;( make_shared&lt;rotate_y&gt;( make_shared&lt;bvh_node&gt;(boxes2, 0.0, 1.0), 15), vec3(-100,270,395) ) ); return objects;} 每个像素点采样10,000次, 得到下图的结果: 现在你可以合上这本书, 开始生成属于你自己的炫酷图片! 在 https://in1weekend.blogspot.com/ 获取后续阅读内容和新特性, 如果你在阅读过程中遇到了问题, 或对本书有什么看法或评价, 或者想分享你的炫酷图片, 欢迎发送邮件到 ptrshrl@gmail.com ##译者后记","link":"/Graphic/Ray-tracing-the-next-week/"},{"title":"ray tracing in one weekend 中文翻译","text":"写在前头: 2020年3月23日, 本书的全新版本上线啦, 当时笔者正好翻译完第二本书, 提issue的时候得知这个消息, 顿时心态崩了。浏览了一下develop分支下的新版本, 和旧版差异还不少。没办法, 返工吧。 本文翻译自新版本v3.0.1, 相较之前的版本, 新版本改进了许多细节, 修复了一些bug, 并对原来一些比较模糊的地方加以详细的阐释, 并使用了智能指针等c++特性。 译者水平有限, 有些地方读起来难免会感到怪怪的, 还请各位见谅。如果您遇到什么看不懂的地方或者乱七八糟的句子, 那么您很可能是辣鸡翻译的受害者, 这时候请不要犹豫, 直接去阅读原文自救。如果您愿意帮助我改进这个翻译, 请直接在页面底部留言或发送邮件到zgxmy@126.com, 万分感激!!! 1. Overview 概述2. Output a Image 输出你的图像3. The vec3 Class vec3向量类4. Rays, a Simple Camera, and Background 光线, 简单摄像机, 以及背景5. Adding a Sphere 加入球体6. Suface Normals and Multiple Objects 面法相与多个物体7. Antialiasing 反走样8. Diffuse Material 漫反射材质9. Metal 金属材质10. Dielectric 绝缘体材质11. Positionable Camera 可自定义位置的摄像机12. Defocus Blur 对焦模糊13. Where Next? 接下来学什么? 1. 概述这些年来我开过不少图形学的课。我常常把光线追踪作为课堂上的教学内容。因为对于光线追踪来说, 在不使用任何API的情况下, 你不得不被迫手撸全部的代码, 但你仍然能渲染出炫酷的图片。我决定将我的课堂笔记改写成本教程, 让你能尽可能快的实现一个炫酷的光线追踪器(ray tracer)。这并不是一个功能完备的光线追踪器。但是它却拥用让光线追踪在电影行业成为主流的非直接光照(indirect lighting)。跟随本教程循序渐进, 你的光线追踪器的代码构筑将会变得易于拓展。如果之后你对这方面燃起了兴趣, 你可以将它拓展成一个更加完备的光线追踪器。 当大家提起”光线追踪”, 可能指的是很多不同的东西。我对这个词的描述是, 光线追踪在技术上就是一个路径追踪器, 事实上大部分情况下这个词都是这个意思。光线追踪器的代码也是十分的简单(让电脑帮我们算去吧!)。当你看到你渲染的图片时, 你一定会感到高兴的。 接下来我会带你一步步的实现这个光线追踪, 并加入一些我的debug建议。最后你会得到一个能渲染出漂亮图片的光线追踪器。你认为你应该能在一个周末的时间内搞定。如果你花的时间比这长, 别担心, 也没太大问题。我使用C++作为本光线追踪器的实现语言。你其实不必, 但我还是推荐你用C++, 因为C++快速, 平台移植性好, 并且大部分的工业级电影和游戏渲染器都是使用C++编写的。注意这里我避免了大部分C++的新特性。但是继承和重载运算符我们保留, 对光线追踪器来说这个太有用了。网上的那些代码不是我提供的, 但是这些代码是真的可以跑的。除了vec3类中的一些简单的操作, 我将所有的代码都公开了。我是”学习编程要亲自动手敲代码”派。但是如果有一份代码摆在我面前, 我可以直接用, 我还是会用的。所以我只在没代码用的时候, 我才奉行我刚刚说的话。好啦, 别提这个了! 我没把上面一段删了, 因为我的态度180°大转变太好玩了。读者们帮我修复了一些次要的编译错误, 所以还是请你亲手来敲一下代码吧!但是你如果你想看看我的代码:点击这里 我假定你有一定的向量知识(比如说点乘和叉乘)。如果你记不太清楚, 回顾一下就行。如果你需要回顾, 或者你是第一次听说这个东西, 你可以看我或者Marschner的图像教材, Foley, Van Dam等也行。或者McGuire的codex。 如果你遇到的麻烦, 或者你弄出了很cooool的东西想要分享给大家看, 请给我发邮件。我的邮箱是ptrshrl@gmail.com点我发邮件 我会维护一个有关本书的博客网站, 网站里有一些拓展阅读和一些链接资源。网址是 https://in1weekend.blogspot.com 好了不多BB, 让我们开始吧! 2. 输出你的图像当你开始写渲染器的时候, 你首先得能有办法看到你渲染的图像。最直接了当的方法就行把图像信息写入文件。问题是, 有那么多图片格式, 而且许多格式都挺复杂的。在开始部分, 我常常使用最简单的ppm文件。这里引用Wikipedia上面的简明介绍: 我们来写一下输出这种图片格式的C++代码: main.cc 创建你的第一个图像1234567891011121314151617181920#include &lt;iostream&gt;int main() { const int image_width = 200; const int image_height = 100; std::cout &lt;&lt; &quot;P3\\n&quot; &lt;&lt; image_width &lt;&lt; ' ' &lt;&lt; image_height &lt;&lt; &quot;\\n255\\n&quot;; for (int j = image_height-1; j &gt;= 0; --j) { for (int i = 0; i &lt; image_width; ++i) { auto r = double(i) / image_width; auto g = double(j) / image_height; auto b = 0.2; int ir = static_cast&lt;int&gt;(255.999 * r); int ig = static_cast&lt;int&gt;(255.999 * g); int ib = static_cast&lt;int&gt;(255.999 * b); std::cout &lt;&lt; ir &lt;&lt; ' ' &lt;&lt; ig &lt;&lt; ' ' &lt;&lt; ib &lt;&lt; '\\n'; } }} 代码里有一些我们要注意的事情: 1.对于像素来说, 每一行是从左往右写入的。 2.行从上开始往下写入的。 3.通常我们把RGB通道的值限定在0.0到1.0。我们之后计算颜色值的时候将使用一个动态的范围, 这个范围并不是0到1。但是在使用这段代码输出图像之前, 我们将把颜色映射到0到1。所以这部分输出图像代码不会改变。【译注: 这里挺重要的, 别忘了忘掉这个在第一本书并不会出现任何问题, 直到第二本书前大半也没问题, 但是一到cornell box与光源的引入, 事情就糟糕了, 不少人都踩进去了,详见issue-94】 4.下方的红色从左到右由黑边红, 左侧的绿色从上到下由黑到绿。红+绿变黄, 所以我们的右上角应该是黄的。 现在我们要把cout的输出流写入文件中。幸好我们有命令行操作符&gt;来定向输出流。在windows操作系统中差不多这样的: 1build\\Release\\inOneWeekend.exe &gt; image.ppm 在Mac或者Linux操作系统中, 大概是这个样子的 1build/inOneWeekend &gt; image.ppm 打开我们输出的文件(我是Mac系统, 我是用ToyViewer打开的, 你可以用你喜欢的任意看图软件来打开。如果你默认的看图软件(比如windows下的图片)不支持ppm格式, 只要Google一下”ppm viewer”装个新的就行。)打开后的结果如下: 好耶!这便是图形学中的”hello world”了【吐槽：图形学的hello world不是三角形嘛】。如果你的图像看上去不是这样的, 用文本编辑器打开你的输出文件, 看看里面内容是啥样的。不出意外的话, 正确格式应该是这样的: 1234567891011P3200 1002550 253 511 253 512 253 513 253 515 253 516 253 517 253 518 253 51 如果不是这样的, 你可能当中多了些空行或者类似的什么东西, 因此你的看图软件识别不出来。 如果你想生成别的图像格式来代替基础的PPM, 我强烈安利stb_image.h, 你可以免费在github上获取。 2.1. 加入进度提示在我们往下走之前, 我们先来加个输出的进度提示。对于查看一次长时间渲染的进度来说, 这不失为一种简便的做法。也可以通过这个进度来判断程序是否卡住或者进入一个死循环。 我们的程序将图片信息写入标准输出流(std::cout), 所以我们不能用这个流输出进度。我们换用错误输出流(std::cerr)来输出进度: main.cc diff 带进度条的渲染循环12345678910111213for (int j = image_height-1; j &gt;= 0; --j) {+ std::cerr &lt;&lt; &quot;\\rScanlines remaining: &quot; &lt;&lt; j &lt;&lt; ' ' &lt;&lt; std::flush; for (int i = 0; i &lt; image_width; ++i) { auto r = double(i) / image_width; auto g = double(j) / image_height; auto b = 0.2; int ir = static_cast&lt;int&gt;(255.999 * r); int ig = static_cast&lt;int&gt;(255.999 * g); int ib = static_cast&lt;int&gt;(255.999 * b); std::cout &lt;&lt; ir &lt;&lt; ' ' &lt;&lt; ig &lt;&lt; ' ' &lt;&lt; ib &lt;&lt; '\\n'; } }+std::cerr &lt;&lt; &quot;\\nDone.\\n&quot;; 3. vec3向量类几乎所有的图形程序都使用类似的类来储存几何向量和颜色。在许多程序中这些向量是四维的(对于位置或者几何向量来说是三维的齐次拓展, 对于颜色来说是RGB加透明通道)。对我们现在这个程序来说, 三维就足够了。我们用一个vec3类来储存所有的颜色, 位置, 方向, 位置偏移, 或者别的什么东西。一些人可能不太喜欢这样做, 因为全都用一个类, 没有限制, 写代码的时候难免会犯二, 比如你把颜色和位置加在一起。他们的想法挺好的, 但是我们想在避免明显错误的同时让代码量尽量的精简。所以这里就先一个类吧。【译注: 之后有添加新的color类】 下面是我的vec3的头文件: vec.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;class vec3 { public: vec3() : e{0,0,0} {} vec3(double e0, double e1, double e2) : e{e0, e1, e2} {} double x() const { return e[0]; } double y() const { return e[1]; } double z() const { return e[2]; } vec3 operator-() const { return vec3(-e[0], -e[1], -e[2]); } double operator[](int i) const { return e[i]; } double&amp; operator[](int i) { return e[i]; } vec3&amp; operator+=(const vec3 &amp;v) { e[0] += v.e[0]; e[1] += v.e[1]; e[2] += v.e[2]; return *this; } vec3&amp; operator*=(const double t) { e[0] *= t; e[1] *= t; e[2] *= t; return *this; } vec3&amp; operator/=(const double t) { return *this *= 1/t; } double length() const { return sqrt(length_squared()); } double length_squared() const { return e[0]*e[0] + e[1]*e[1] + e[2]*e[2]; } void write_color(std::ostream &amp;out) { // Write the translated [0,255] value of each color component. out &lt;&lt; static_cast&lt;int&gt;(255.999 * e[0]) &lt;&lt; ' ' &lt;&lt; static_cast&lt;int&gt;(255.999 * e[1]) &lt;&lt; ' ' &lt;&lt; static_cast&lt;int&gt;(255.999 * e[2]) &lt;&lt; '\\n'; } public: double e[3];}; 我们使用双精度浮点double, 但是有些光线追踪器使用单精度浮点float。这里其实都行, 你喜欢哪个就用那个。头文件的第二部分包括一些向量操作工具函数: vec3.h123456789101112131415161718192021222324252627282930313233343536373839404142434445// vec3 Utility Functionsinline std::ostream&amp; operator&lt;&lt;(std::ostream &amp;out, const vec3 &amp;v) { return out &lt;&lt; v.e[0] &lt;&lt; ' ' &lt;&lt; v.e[1] &lt;&lt; ' ' &lt;&lt; v.e[2];}inline vec3 operator+(const vec3 &amp;u, const vec3 &amp;v) { return vec3(u.e[0] + v.e[0], u.e[1] + v.e[1], u.e[2] + v.e[2]);}inline vec3 operator-(const vec3 &amp;u, const vec3 &amp;v) { return vec3(u.e[0] - v.e[0], u.e[1] - v.e[1], u.e[2] - v.e[2]);}inline vec3 operator*(const vec3 &amp;u, const vec3 &amp;v) { return vec3(u.e[0] * v.e[0], u.e[1] * v.e[1], u.e[2] * v.e[2]);}inline vec3 operator*(double t, const vec3 &amp;v) { return vec3(t*v.e[0], t*v.e[1], t*v.e[2]);}inline vec3 operator*(const vec3 &amp;v, double t) { return t * v;}inline vec3 operator/(vec3 v, double t) { return (1/t) * v;}inline double dot(const vec3 &amp;u, const vec3 &amp;v) { return u.e[0] * v.e[0] + u.e[1] * v.e[1] + u.e[2] * v.e[2];}inline vec3 cross(const vec3 &amp;u, const vec3 &amp;v) { return vec3(u.e[1] * v.e[2] - u.e[2] * v.e[1], u.e[2] * v.e[0] - u.e[0] * v.e[2], u.e[0] * v.e[1] - u.e[1] * v.e[0]);}inline vec3 unit_vector(vec3 v) { return v / v.length();} 现在我们可以使用vec3类将我们的main函数改成这样啦: main.cc diff 创建一张颜色渐变的图片1234567891011121314151617181920#include &quot;vec3.h&quot;#include &lt;iostream&gt;int main() { const int image_width = 200; const int image_height = 100; std::cout &lt;&lt; &quot;P3\\n&quot; &lt;&lt; image_width &lt;&lt; ' ' &lt;&lt; image_height &lt;&lt; &quot;\\n255\\n&quot;; for (int j = image_height-1; j &gt;= 0; --j) { std::cerr &lt;&lt; &quot;\\rScanlines remaining: &quot; &lt;&lt; j &lt;&lt; ' ' &lt;&lt; std::flush; for (int i = 0; i &lt; image_width; ++i) {+ vec3 color(double(i)/image_width, double(j)/image_height, 0.2);+ color.write_color(std::cout); } } std::cerr &lt;&lt; &quot;\\nDone.\\n&quot;;} 4. 光线, 简单摄像机, 以及背景所有的光线追踪器都有个一个ray类, 我们假定光线的公式为$\\mathbf{p}(t) = \\mathbf{a} + t \\vec{\\mathbf{b}}$。这里的$\\mathbf{p}$是三维射线上的一个点。$\\mathbf{a}$是射线的原点, $\\vec{\\mathbf{b}}$是射线的方向。类中的变量$t$是一个实数(代码中为double类型)。$p(t)$接受任意的$t$做为变量, 返回射线上的对应点。如果允许$t$取负值你可以得到整条直线。对于一个正数$t$, 你只能得到原点前部分$\\mathbf{a}$, 这常常被称为半条直线, 或者说射线。 我在代码中使用复杂命名, 将函数$p(t)$扩写为ray::at(t)【吐糟: 你之前版本中那个ray::point_at_parameter(t)才叫复杂】 ray.h12345678910111213141516171819202122232425#ifndef RAY_H#define RAY_H#include &quot;vec3.h&quot;class ray { public: ray() {} ray(const vec3&amp; origin, const vec3&amp; direction) : orig(origin), dir(direction) {} vec3 origin() const { return orig; } vec3 direction() const { return dir; } vec3 at(double t) const { return orig + t*dir; } public: vec3 orig; vec3 dir;};#endif 现在我们再拐回来做我们的光线追踪器。光线追踪器的核心是从像素发射射线, 并计算这些射线得到的颜色。这包括如下的步骤: (1)将射线从视点转化为像素坐标 (2)计算光线是否与场景中的物体相交 (3)如果有, 计算交点的颜色。在做光线追踪器的初期, 我会先弄个简单摄像机让代码能跑起来。我也会编写一个简单的color(ray)函数来返回背景颜色值(一个简单的渐变色)。 在使用正方形的图像Debug时我时常会遇到问题, 因为我老是把$x$和$y$弄反。所以我坚持使用200x100这样长宽不等的图像。我会把视点(或者说摄像机, 如果你认为它是个摄像机的话)放在$(0,0,0)$。这里y轴向上, x轴向右, 为了准守使用左手系的规范, 摄像机看向的方向为z轴的负方向。我会把发出射线的原点从图像的左下角开始沿着xy方向做增量直至遍历全图。注意我这里并没有将射线的向量设置为单位向量, 因为我认为这样代码会更加简单快捷。 Figure 2: Camera geometry 下面是代码, 射线r现在只是近似的从各个像素的中心射出(现在不必担心精度问题, 因为我们一会儿就会加入抗锯齿): main.cc diff1234567891011121314151617181920212223242526272829303132#include &quot;ray.h&quot;#include &lt;iostream&gt;vec3 ray_color(const ray&amp; r) { vec3 unit_direction = unit_vector(r.direction()); auto t = 0.5*(unit_direction.y() + 1.0); return (1.0-t)*vec3(1.0, 1.0, 1.0) + t*vec3(0.5, 0.7, 1.0);}int main() { const int image_width = 200; const int image_height = 100; std::cout &lt;&lt; &quot;P3\\n&quot; &lt;&lt; image_width &lt;&lt; &quot; &quot; &lt;&lt; image_height &lt;&lt; &quot;\\n255\\n&quot;;+ vec3 lower_left_corner(-2.0, -1.0, -1.0);+ vec3 horizontal(4.0, 0.0, 0.0);+ vec3 vertical(0.0, 2.0, 0.0);+ vec3 origin(0.0, 0.0, 0.0); for (int j = image_height-1; j &gt;= 0; --j) { std::cerr &lt;&lt; &quot;\\rScanlines remaining: &quot; &lt;&lt; j &lt;&lt; ' ' &lt;&lt; std::flush; for (int i = 0; i &lt; image_width; ++i) {+ auto u = double(i) / image_width;+ auto v = double(j) / image_height;+ ray r(origin, lower_left_corner + u*horizontal + v*vertical);+ vec3 color = ray_color(r); color.write_color(std::cout); } } std::cerr &lt;&lt; &quot;\\nDone.\\n&quot;;} ray_color(ray)函数根据y值将蓝白做了个线性差值的混合, 我们这里把射线做了个单位化, 以保证y的取值范围$(-1.0&lt;y&lt;1.0)$。因为我们使用y轴做渐变, 所以你可以看到这个蓝白渐变也是竖直的。 我接下来使用了一个标准的小技巧将y的范围从$-1.0 ≤ y ≤ 1.0$映射到了$0 ≤ y ≤ 1.0$。这样$t=1.0$时就是蓝色, 而$t=0.0$时就是白色。在蓝白之间我想要一个混合效果(blend)。现在我们采用的是线性混合(linear blend)或者说线性插值(liner interpolation)。或者简称其为lerp。一个lerp一般来说会是下面的形式: $$ \\text{blendedValue} = (1-t)\\cdot\\text{startValue} + t\\cdot\\text{endValue}$$ 当$t$从0到1, 我们会渲染出这样的图像: 5. 加入球体让我们为我们的光线追踪器加入一个物体吧!人们通常使用的球体, 因为计算射线是否与球体相交是十分简洁明了的。回想一下我们中学时期学过的球体表面方程, 对于一个半径为$r$的球体来说, 有方程$x^2 + y^2 + z^2 = R^2$, 其中$(x,y,z)$是球面上的点。如果我们想要表示点$(x,y,z)$在球体的内部, 那便有方程$x^2 + y^2 + z^2 &lt; R^2$, 类似的, 如果要表示球体外部的点, 则有$x^2 + y^2 + z^2 &gt; R^2$。 如果球体的球心在$(\\mathbf{c}_x, \\mathbf{c}_y, \\mathbf{c}_z)$, 那么这个式子就会变得丑陋一些: $$ (x-\\mathbf{c}_x)^2 + (y-\\mathbf{c}_y)^2 + (z-\\mathbf{c}_z)^2 = R^2 $$ 在图形学中, 你总希望你方程里面所有东西都是用向量表达的, 这样我们就能用vec3这个类来存储所有的这些xyz相关的东西了。你也许会意识到, 对于到球面上的点$\\mathbf{P} = (x,y,z)$到球心$\\mathbf{c} = (\\mathbf{c}_x,\\mathbf{c}_y,\\mathbf{c}_z)$的距离可以使用向量表示为$(\\mathbf{p} - \\mathbf{c})$, 于是就有 $$ (\\mathbf{p} - \\mathbf{c}) \\cdot (\\mathbf{p} - \\mathbf{c}) = (x-\\mathbf{c}_x)^2 + (y-\\mathbf{c}_y)^2 + (z-\\mathbf{c}_z)^2 $$ 于是我们就能得到球面方程的向量形式: $$ (\\mathbf{p} - \\mathbf{c}) \\cdot (\\mathbf{p} - \\mathbf{c}) = R^2 $$ 我们可以将其解读为”满足方程上述方程的任意一点$\\mathbf{p}$一定位于球面上”。我们还要知道射线$p(t) = \\mathbf{a} + t\\vec{\\mathbf{b}}$是否与球体相交。如果说它相交了, 那么肯定有一个$t$使直线上的点$p(t)$满足球面方程。所以我们先来计算满足条件的任意$t$值: $$ (p(t) - \\mathbf{c})\\cdot(p(t) - \\mathbf{c}) = R^2 $$ 或者将$p(t)$展开为射线方程: $$ (\\mathbf{a} + t \\vec{\\mathbf{b}} - \\mathbf{c}) \\cdot (\\mathbf{a} + t \\vec{\\mathbf{b}} - \\mathbf{c}) = R^2 $$ 好啦, 我们需要的代数部分就到这里。现在我们来展开表达式并移项, 得: $$ t^2 \\vec{\\mathbf{b}}\\cdot\\vec{\\mathbf{b}} + 2t \\vec{\\mathbf{b}} \\cdot \\vec{(\\mathbf{a}-\\mathbf{c})} + \\vec{(\\mathbf{a}-\\mathbf{c})} \\cdot \\vec{(\\mathbf{a}-\\mathbf{c})} - R^2 = 0 $$ 方程中的向量和半径$R$都是已知的常量, 唯一的未知数就是$t$, 并且这个等式是关于$t$的一个一元二次方程, 就像你在高中数学课上【？？？】学到的那样。你可以用求根公式来判别交点个数, 为正则2个交点, 为负则1个交点, 为0则没有交点。在图形学中, 代数与几何往往密切相关, 你看图: 如果我们使用代码来求解, 并使用红色来表示射线击中我们放在(0,0,-1)的小球: main.cc diff Rendering a red sphere12345678910111213141516bool hit_sphere(const vec3&amp; center, double radius, const ray&amp; r) { vec3 oc = r.origin() - center; auto a = dot(r.direction(), r.direction()); auto b = 2.0 * dot(oc, r.direction()); auto c = dot(oc, oc) - radius*radius; auto discriminant = b*b - 4*a*c; return (discriminant &gt; 0);}+vec3 ray_color(const ray&amp; r) {+ if (hit_sphere(vec3(0,0,-1), 0.5, r))+ return vec3(1, 0, 0); vec3 unit_direction = unit_vector(r.direction()); auto t = 0.5*(unit_direction.y() + 1.0); return (1.0-t)*vec3(1.0, 1.0, 1.0) + t*vec3(0.5, 0.7, 1.0);} 我们会得到: 现在我们啥都缺: 例如光照, 反射, 加入更多的物体, 但是我们离成功又近了一步!现在你要注意我们其实求的是直线与球相交的解, $t&lt;0$的那些情况也计算进去了, 而我们只想要直线中一段射线的解。如果你将你的球心设置在$(0,0,1)$你会得到完全相同的结果。这不是一个特性(feature)!【吐槽: 直接说it’s a bug嘛】我们会在接下来的章节修复这个bug。 6. 面法相与复数物体为了来给球体着色, 首先我们来定义一下面法相。面法相应该是一种垂直于交点所在平面的三维向量。关于面法相我们存在两个设计抉择。首先是是否将其设计为单位向量, 这样对于着色器来说, 所以我会说”yes!”但是我并没有在代码里这么做, 这部分差异可能会导致一些潜在的bug。所以记住, 这个是个人喜好, 大多数的人喜好使用单位法相。对于球体来说, 朝外的法相是直线与球的交点减去球心: 说到底, 其实就是从球心到交点再向外延伸的那个方向。让我们把这部分转变成代码并开始着色。我们暂时还没有光源这样的东西, 所以让我们直接将法相值作为颜色输出吧。对于法相可视化来说, 我们常常将xyz分量的值先映射到0到1的范围(假定$vec{\\mathbf{N}}$是一个单位向量, 它的取值范围是-1到1的),再把它赋值给rgb。对于法相来说, 光能判断射线是否与球体相交是不够的, 我们还需求出交点的坐标。在有两个交点的情况下, 我们选取最近的交点smallest(t)。计算与可视化球的法向量的代码如下: main.cc diff Rendering surface nornals on a sphere1234567891011121314151617181920212223+double hit_sphere(const vec3&amp; center, double radius, const ray&amp; r) { vec3 oc = r.origin() - center; auto a = dot(r.direction(), r.direction()); auto b = 2.0 * dot(oc, r.direction()); auto c = dot(oc, oc) - radius*radius; auto discriminant = b*b - 4*a*c;+ if (discriminant &lt; 0) {+ return -1.0;+ } else {+ return (-b - sqrt(discriminant) ) / (2.0*a);+ }}vec3 ray_color(const ray&amp; r) {+ auto t = hit_sphere(vec3(0,0,-1), 0.5, r);+ if (t &gt; 0.0) {+ vec3 N = unit_vector(r.at(t) - vec3(0,0,-1));+ return 0.5*vec3(N.x()+1, N.y()+1, N.z()+1);+ } vec3 unit_direction = unit_vector(r.direction());+ t = 0.5*(unit_direction.y() + 1.0); return (1.0-t)*vec3(1.0, 1.0, 1.0) + t*vec3(0.5, 0.7, 1.0);} 这会得到下面的结果: 我们再来回顾上面的直线方程: main.cc12345vec3 oc = r.origin() - center;auto a = dot(r.direction(), r.direction());auto b = 2.0 * dot(oc, r.direction());auto c = dot(oc, oc) - radius*radius;auto discriminant = b*b - 4*a*c; 首先, 回想一下一个向量与自己的点积就是它的长度的平方(都是$x^2+y^2+z^2$) 其次, 注意其实我们的b有一个系数2, 我们设b=2h, 有: $$ \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$ $$ = \\frac{-2h \\pm \\sqrt{(2h)^2 - 4ac}}{2a} $$ $$ = \\frac{-2h \\pm 2\\sqrt{h^2 - ac}}{2a} $$ $$ = \\frac{-h \\pm \\sqrt{h^2 - ac}}{a} $$ 所以射线与球体求交的代码其实可以简化成下面这样: main.cc diff12345678910111213141516vec3 oc = r.origin() - center;-auto a = dot(r.direction(), r.direction());-auto b = 2.0 * dot(oc, r.direction());-auto c = dot(oc, oc) - radius*radius;-auto discriminant = b*b - 4*a*c;+auto a = r.direction().length_squared();+auto half_b = dot(oc, r.direction());+auto c = oc.length_squared() - radius*radius;+auto discriminant = half_b*half_b - a*c;if (discriminant &lt; 0) { return -1.0;} else {- return (-b - sqrt(discriminant) ) / (2.0*a);+ return (-half_b - sqrt(discriminant) ) / a;} 好啦, 那么怎么在场景中渲染不止一个球呢? 很直接的我们想到使用一个sphere数组, 这里有个很简洁的好方法: 使用一个抽象类, 任何可能与光线求交的东西实现时都继承这个类, 并且让球以及球列表也都继承这个类。我们该给这个类起个什么样的名字呢? 叫它object好像不错但现在我们使用面向对象编程(oop)。suface是时常被翻牌, 但是如果我们想要体积体(volumes)的话就不太适合了。hittable又过于强调了自己的成员函数hit。所以我哪个都不喜欢, 但是总得给它个名字的嘛, 那我就叫它hittable: hittable类理应有个接受射线为参数的函数, 许多光线追踪器为了便利, 加入了一个区间$t_{min}&lt;t&lt;t_{max}$来判断相交是否有效。对于一开始的光线来说, 这个$t$值总是正的, 但加入这部分对代码实现的一些细节有着不错的帮助。现在有个设计上的问题:我们是否在每次计算求交的时候都要去计算法相?但其实我们只需要计算离射线原点最近的那个交点的法相就行了, 后面的东西会被遮挡。接下来我会给出我的代码, 并将一些计算的结果存在一个结构体里, 来看, 这就是那个抽象类: 1234567891011121314151617#ifndef HITTABLE_H#define HITTABLE_H#include &quot;ray.h&quot;struct hit_record { vec3 p; vec3 normal; double t;};class hittable { public: virtual bool hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const = 0;};#endif 这是继承自它的sphere球体类: sphere.h1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#ifndef SPHERE_H#define SPHERE_H#include &quot;hittable.h&quot;#include &quot;vec3.h&quot;class sphere: public hittable { public: sphere() {} sphere(vec3 cen, double r) : center(cen), radius(r) {}; virtual bool hit(const ray&amp; r, double tmin, double tmax, hit_record&amp; rec) const; public: vec3 center; double radius;};bool sphere::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const { vec3 oc = r.origin() - center; auto a = r.direction().length_squared(); auto half_b = dot(oc, r.direction()); auto c = oc.length_squared() - radius*radius; auto discriminant = half_b*half_b - a*c; if (discriminant &gt; 0) { auto root = sqrt(discriminant); auto temp = (-half_b - root)/a; if (temp &lt; t_max &amp;&amp; temp &gt; t_min) { rec.t = temp; rec.p = r.at(rec.t); rec.normal = (rec.p - center) / radius; return true; } temp = (-half_b + root) / a; if (temp &lt; t_max &amp;&amp; temp &gt; t_min) { rec.t = temp; rec.p = r.at(rec.t); rec.normal = (rec.p - center) / radius; return true; } } return false;}#endif 好了, 让我们来谈谈第二个关于面法相设计上的问题吧， 那就是面法相的朝向问题。对于现在来说, 如果光线从球体外部击中球体, 那么法相也是朝外的, 与射线的方向相反(不是数学意义上的严格相反, 只是大致逆着)。如果光线从内部射向球面时, 此时的面法相依然朝外, 与射线方向相同。相对的, 我们也可以总是让法相向量与射线方向相反, 即射线从外部射向球面, 法向量朝外, 射线从内部射向球面, 法向量向着球心。 在我们着色前, 我们需要仔细考虑一下采用上面哪种方式, 这对于双面材质来说至关重要。例如一张双面打印的A4纸, 或者玻璃球这样的同时具有内表面和外表面的物体。 如果我们决定让法相永远朝外, 那在我们就得在射入的时候判断是从表面的哪一侧射入的, 我们可以简单的将光线与法相做点乘来判断。如果法相与光线方向相同, 那就是从内部击中内表面, 如果相反则是从外部击中外表面。【译注: $dot(a,b) = cos\\theta|a||b|$】 sphere.h1234567if (dot(ray_direction, outward_normal) &gt; 0.0) { // ray is inside the sphere ...} else { // ray is outside the sphere ...} 如果我们永远让法相与入射方向相反, 我们就不用去用点乘来判断射入面是内侧还是外侧了, 但相对的, 我们需要用一个变量储存摄入面的信息: sphere.h1234567891011bool front_face;if (dot(ray_direction, outward_normal) &gt; 0.0) { // ray is inside the sphere normal = -outward_normal; front_face = false;}else { // ray is outside the sphere normal = outward_normal; front_face = true;} 其实采取哪种策略, 关键在于你想把这部分放在着色阶段还是几何求交的阶段。【译注:反正都要算的, v2.0的时候是在着色阶段判别的, v3.0把它放在了求交阶段】。在本书中我们我们的材质类型会比我们的几何图元类型多, 所以为了有更少的代码量, 我们会在几何部分先判别射入面是内侧还是外侧。这当然也是一种个人喜好。 我们在结构体hit_record中加入front_face变量, 我们接下来还会弄一些动态模糊相关的事情(Book2 chapter1),所以我还会加入一个时间变量: hittable.h diff The hittable class with time and side12345678910111213141516171819202122ifndef HITTABLE_H#define HITTABLE_H#include &quot;ray.h&quot;struct hit_record { vec3 p; vec3 normal;+ double t;+ bool front_face;+ inline void set_face_normal(const ray&amp; r, const vec3&amp; outward_normal) { front_face = dot(r.direction(), outward_normal) &lt; 0; normal = front_face ? outward_normal :-outward_normal; }};class hittable { public: virtual bool hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const = 0;};#endif 接下来我们在求交时加入射入面的判别: sphere.h diff The sphere class with normal determination12345678910111213141516171819202122232425262728bool sphere::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const { vec3 oc = r.origin() - center; auto a = r.direction().length_squared(); auto half_b = dot(oc, r.direction()); auto c = oc.length_squared() - radius*radius; auto discriminant = half_b*half_b - a*c; if (discriminant &gt; 0) { auto root = sqrt(discriminant); auto temp = (-half_b - root)/a; if (temp &lt; t_max &amp;&amp; temp &gt; t_min) { rec.t = temp; rec.p = r.at(rec.t);+ vec3 outward_normal = (rec.p - center) / radius;+ rec.set_face_normal(r, outward_normal); return true; } temp = (-half_b + root) / a; if (temp &lt; t_max &amp;&amp; temp &gt; t_min) { rec.t = temp; rec.p = r.at(rec.t);+ vec3 outward_normal = (rec.p - center) / radius;+ rec.set_face_normal(r, outward_normal); return true; } } return false;} 我们加入存放物体的列表 hittable_list.h The hittable_list classs1234567891011121314151617181920212223242526272829303132333435363738394041#ifndef HITTABLE_LIST_H#define HITTABLE_LIST_H#include &quot;hittable.h&quot;#include &lt;memory&gt;#include &lt;vector&gt;using std::shared_ptr;using std::make_shared;class hittable_list: public hittable { public: hittable_list() {} hittable_list(shared_ptr&lt;hittable&gt; object) { add(object); } void clear() { objects.clear(); } void add(shared_ptr&lt;hittable&gt; object) { objects.push_back(object); } virtual bool hit(const ray&amp; r, double tmin, double tmax, hit_record&amp; rec) const; public: std::vector&lt;shared_ptr&lt;hittable&gt;&gt; objects;};bool hittable_list::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const { hit_record temp_rec; bool hit_anything = false; auto closest_so_far = t_max; for (const auto&amp; object : objects) { if (object-&gt;hit(r, t_min, closest_so_far, temp_rec)) { hit_anything = true; closest_so_far = temp_rec.t; rec = temp_rec; } } return hit_anything;}#endif 6.1. 一些C++的新特性hittable_list类使用了两种C++的特性:vector和shared_ptr, 如果你并不熟悉C++, 你可能会感到有些困惑。 shared_ptr&lt;type&gt;是指向一些已分配内存的类型的指针。每当你将它的值赋值给另一个智能指针时, 物体的引用计数器就会+1。当智能指针离开它所在的生存范围(例如代码块或者函数外), 物体的引用计数器就会-1。一旦引用计数器为0, 即没有任何智能指针指向该物体时, 该物体就会被销毁 一般来说, 智能指针首先由一个刚刚新分配好内存的物体来初始化: 123shared_ptr&lt;double&gt; double_ptr = make_shared&lt;double&gt;(0.37);shared_ptr&lt;vec3&gt; vec3_ptr = make_shared&lt;vec3&gt;(1.414214, 2.718281, 1.618034);shared_ptr&lt;sphere&gt; sphere_ptr = make_shared&lt;sphere&gt;(vec3(0,0,0), 1.0); make_shared&lt;thing&gt;(thing_constructor_params ...)为指定的类型分配一段内存, 使用你指定的构造函数与参数来创建这个类, 并返回一个智能指针shared_ptr&lt;thing&gt; 使用C++的auto类型关键字, 可以自动推断make_shared&lt;type&gt;返回的智能指针类型, 于是我们可以把上面的代码简化为: 123auto double_ptr = make_shared&lt;double&gt;(0.37);auto vec3_ptr = make_shared&lt;vec3&gt;(1.414214, 2.718281, 1.618034);auto sphere_ptr = make_shared&lt;sphere&gt;(vec3(0,0,0), 1.0); 我们在代码中使用智能指针的目的是为了能让多个几何图元共享一个实例(举个栗子, 一堆不同球体使用同一个纹理材质), 并且这样内存管理比起普通的指针更加的简单方便。 std::shared_ptr在头文件&lt;memory&gt;中 1#include&lt;memory&gt; 第二个你可能不太熟悉的C++特性是std::vector。这是一个类似数组的结构类型, 可以存储任意指定的类型。在上面的代码中, 我们将hittable类型的智能指针存入vector中, 随着objects.push_back(object)的调用, object被存入vector的末尾, 同时vector的储存空间会自动增加。 std::vector在头文件&lt;vector&gt;中 1#include&lt;vector&gt; 最后, 位于hittable_list.h文件开头部分的using语句告诉编译器, shared_ptr与make_shared是来自std库的。这样我们在使用它们之前就不用每次都加上前缀std::。 6.2. 常用的常数与工具函数我们需要在头文件中定义一些常用的常数。目前为止我们只需要定义无穷。但是我们先把pi在这里定义好, 之后要用的。对于pi来说并没有什么跨平台的标准定义【译注: 这就是为什么不使用之前版本中M_PI宏定义的原因】, 所以我们自己来定义一下。我们在rtweekend.h中给出了一些未来常用的常数和函数: rtweekend.h12345678910111213141516171819202122232425262728293031323334#ifndef RTWEEKEND_H#define RTWEEKEND_H#include &lt;cmath&gt;#include &lt;cstdlib&gt;#include &lt;limits&gt;#include &lt;memory&gt;// Usingsusing std::shared_ptr;using std::make_shared;// Constantsconst double infinity = std::numeric_limits&lt;double&gt;::infinity();const double pi = 3.1415926535897932385;// Utility Functionsinline double degrees_to_radians(double degrees) { return degrees * pi / 180;}inline double ffmin(double a, double b) { return a &lt;= b ? a : b; }inline double ffmax(double a, double b) { return a &gt;= b ? a : b; }// Common Headers#include &quot;ray.h&quot;#include &quot;vec3.h&quot;#endif 以及这是更新后的main函数: main.cc diff12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &quot;rtweekend.h&quot;#include &quot;hittable_list.h&quot;#include &quot;sphere.h&quot;#include &lt;iostream&gt;vec3 ray_color(const ray&amp; r, const hittable&amp; world) {+ hit_record rec;+ if (world.hit(r, 0, infinity, rec)) {+ return 0.5 * (rec.normal + vec3(1,1,1));+ } vec3 unit_direction = unit_vector(r.direction());+ auto t = 0.5*(unit_direction.y() + 1.0); return (1.0-t)*vec3(1.0, 1.0, 1.0) + t*vec3(0.5, 0.7, 1.0);}int main() { const int image_width = 200; const int image_height = 100; std::cout &lt;&lt; &quot;P3\\n&quot; &lt;&lt; image_width &lt;&lt; ' ' &lt;&lt; image_height &lt;&lt; &quot;\\n255\\n&quot;; vec3 lower_left_corner(-2.0, -1.0, -1.0); vec3 horizontal(4.0, 0.0, 0.0); vec3 vertical(0.0, 2.0, 0.0); vec3 origin(0.0, 0.0, 0.0);+ hittable_list world;+ world.add(make_shared&lt;sphere&gt;(vec3(0,0,-1), 0.5));+ world.add(make_shared&lt;sphere&gt;(vec3(0,-100.5,-1), 100)); for (int j = image_height-1; j &gt;= 0; --j) { std::cerr &lt;&lt; &quot;\\rScanlines remaining: &quot; &lt;&lt; j &lt;&lt; ' ' &lt;&lt; std::flush; for (int i = 0; i &lt; image_width; ++i) { auto u = double(i) / image_width; auto v = double(j) / image_height; ray r(origin, lower_left_corner + u*horizontal + v*vertical);+ vec3 color = ray_color(r, world); color.write_color(std::cout); } } std::cerr &lt;&lt; &quot;\\nDone.\\n&quot;;} 这样我们就会得到一张使用法向作为球体颜色值的图片。当你想查看模型的特征细节与瑕疵时, 输出面法向作为颜色值不失为一种很好的方法。 7. 反走样(抗锯齿)真实世界中的摄像机拍摄出来的照片是没有像素状的锯齿的。因为边缘像素是由背景和前景混合而成的。我们也可以在程序中简单的对每个边缘像素多次采样取平均达到类似的效果。我们这里不会使用分层采样。尽管我自己常常在我的程序里使用这种有争议的方法。对某些光线追踪器来说分层采样是很关键的部分, 但是对于我们写的这个小光线追踪器并不会有什么很大的提升, 只会让代码更加丑陋。我们会在这里将摄像机类抽象一下, 以便于后续能有一个更酷的摄像机。 我们还需要一个能够返回真随机数的一个随机数生成器。默认来说这个函数应该返回$0≤r&lt;1$的随机数。注意这个范围取不到1是很重要的。有时候我们能从这个特性中获得好处。 一个简单的实现方法是, 使用&lt;cstdlib&gt;中的rand()函数。这个函数会返回0到RAND_MAX中的一个任意整数。我们将下面的一小段代码加到rtweekend.h中, 就能得到我们想要的随机函数了: rtweekend.h123456789101112#include &lt;cstdlib&gt;...inline double random_double() { // Returns a random real in [0,1). return rand() / (RAND_MAX + 1.0);}inline double random_double(double min, double max) { // Returns a random real in [min,max). return min + (max-min)*random_double();} 传统C++并没有随机数生成器, 但是新版C++中的头实现了这个功能(某些专家觉得这种方法不太完美)。如果你想使用这种方法, 你可以参照下面的代码: rtweekend.h12345678910#include &lt;functional&gt;#include &lt;random&gt;inline double random_double() { static std::uniform_real_distribution&lt;double&gt; distribution(0.0, 1.0); static std::mt19937 generator; static std::function&lt;double()&gt; rand_generator = std::bind(distribution, generator); return rand_generator();} 对于给定的像素, 我们发射多条射线进行多次采样。然后我们对颜色结果求一个平均值: 综上, 我们对我们的简单的轴对齐摄像机类进行了一次封装: camera.h12345678910111213141516171819202122232425#ifndef CAMERA_H#define CAMERA_H#include &quot;rtweekend.h&quot;class camera { public: camera() { lower_left_corner = vec3(-2.0, -1.0, -1.0); horizontal = vec3(4.0, 0.0, 0.0); vertical = vec3(0.0, 2.0, 0.0); origin = vec3(0.0, 0.0, 0.0); } ray get_ray(double u, double v) { return ray(origin, lower_left_corner + u*horizontal + v*vertical - origin); } public: vec3 origin; vec3 lower_left_corner; vec3 horizontal; vec3 vertical;};#endif 为了对多重采样的颜色值进行计算, 我们升级了vec3::write_color()函数。我们不会在每次发出射线采样时都计算一个0-1之间的颜色值, 而是一次性把所有的颜色都加在一起, 然后最后只需要简单的一除(除以采样点个数)。另外, 我们给头文件rtweekend.h加入了一个新函数clamp(x,min,max), 用来将x限制在[min,max]区间之中: rtweekend.h12345inline double clamp(double x, double min, double max) { if (x &lt; min) return min; if (x &gt; max) return max; return x;} vec.h123456789101112void write_color(std::ostream &amp;out, int samples_per_pixel) { // Divide the color total by the number of samples. auto scale = 1.0 / samples_per_pixel; auto r = scale * e[0]; auto g = scale * e[1]; auto b = scale * e[2]; // Write the translated [0,255] value of each color component. out &lt;&lt; static_cast&lt;int&gt;(256 * clamp(r, 0.0, 0.999)) &lt;&lt; ' ' &lt;&lt; static_cast&lt;int&gt;(256 * clamp(g, 0.0, 0.999)) &lt;&lt; ' ' &lt;&lt; static_cast&lt;int&gt;(256 * clamp(b, 0.0, 0.999)) &lt;&lt; '\\n';} main函数也发生了变化: main.cc123456789101112131415161718192021222324252627int main() { const int image_width = 200; const int image_height = 100; const int samples_per_pixel = 100; std::cout &lt;&lt; &quot;P3\\n&quot; &lt;&lt; image_width &lt;&lt; &quot; &quot; &lt;&lt; image_height &lt;&lt; &quot;\\n255\\n&quot;; hittable_list world; world.add(make_shared&lt;sphere&gt;(vec3(0,0,-1), 0.5)); world.add(make_shared&lt;sphere&gt;(vec3(0,-100.5,-1), 100)); camera cam; for (int j = image_height-1; j &gt;= 0; --j) { std::cerr &lt;&lt; &quot;\\rScanlines remaining: &quot; &lt;&lt; j &lt;&lt; ' ' &lt;&lt; std::flush; for (int i = 0; i &lt; image_width; ++i) { vec3 color(0, 0, 0); for (int s = 0; s &lt; samples_per_pixel; ++s) { auto u = (i + random_double()) / image_width; auto v = (j + random_double()) / image_height; ray r = cam.get_ray(u, v); color += ray_color(r, world); } color.write_color(std::cout, samples_per_pixel); } } std::cerr &lt;&lt; &quot;\\nDone.\\n&quot;;} 停, 放大放大再放大, 看啊, 每一个像素都是背景和前景的混合: 8. 漫反射材质既然我们已经有了物体的类和多重采样, 我们不妨再加入一些逼真的材质吧。我们先从漫反射材质开始。设计上的问题又来了:我们是把材质和物体设计成两个类, 这样就可以将材质赋值给物体类的成员变量, 还是说让它们紧密结合,这对于使用几何信息来生成纹理的程序来说是很便利的 。我们会采取将其分开的做法————实际上大多数的渲染器都是这样做的————但是记得注意的确是有两种设计方法的。 漫反射材质不仅仅接受其周围环境的光线, 还会在散射时使光线变成自己本身的颜色。光线射入漫反射材质后, 其反射方向是随机的。所以如果我们为下面这两个漫发射的球射入三条光线, 光线都会有不同的反射角度: 并且大部分的光线都会被吸收, 而不是被反射。表面越暗, 吸收就越有可能发生。我们使用任意的算法生成随机的反射方向, 就能让其看上去像一个粗糙不平的漫反射材质。这里我们采用最简单的算法就能得到一个理想的漫反射表面(其实是懒得写lambertian所以用了一个数学上近似的方法)。 (读者Vassillen Chizhov 提供了这个方法, 虽然并不是很精确。我们会在章节最后提准确的lambertian表达式, 而且其并不会很复杂) 好, 现在有两个单位球相切于点$p$, 这两个球体的球心为$(p+\\vec{N})$和$(p-\\vec{N})$, $\\vec{N}$是球体表面的法向量。球心为$(p-\\vec{N})$的那个球在表面的内部, 球心为$(p+\\vec{N})$的球在表面的外部。选择和光线原点位于表面同一侧的那个单位球, 并从球中随机选取一点$s$, 向量$(s-p)$就是我们要求的反射光线的方向: 我们需要一个算法来生成球体内的随机点。我们会采用最简单的做法:否定法(rejection method)。首先, 在一个xyz取值范围为-1到+1的单位立方体中选取一个随机点, 如果这个点在球外就重新生成直到该点在球内: vec3.h12345678910class vec3 { public: ... inline static vec3 random() { return vec3(random_double(), random_double(), random_double()); } inline static vec3 random(double min, double max) { return vec3(random_double(min,max), random_double(min,max), random_double(min,max)); } vec.h1234567vec3 random_in_unit_sphere() { while (true) { auto p = vec3::random(-1,1); if (p.length_squared() &gt;= 1) continue; return p; }} 然后使用我们新的生成随机随机反射方向的函数来更新一下我们的ray_color()函数: main.cc123456789101112vec3 ray_color(const ray&amp; r, const hittable&amp; world) { hit_record rec; if (world.hit(r, 0, infinity, rec)) { vec3 target = rec.p + rec.normal + random_in_unit_sphere(); return 0.5 * ray_color(ray(rec.p, target - rec.p), world); } vec3 unit_direction = unit_vector(r.direction()); auto t = 0.5*(unit_direction.y() + 1.0); return (1.0-t)*vec3(1.0, 1.0, 1.0) + t*vec3(0.5, 0.7, 1.0);} 这里还有个潜在的问题: 注意ray_color函数是一个递归函数。那么递归终止的条件是什么呢?当它没有击中任何东西。但是, 在某些条件下, 达到这个终止条件的时间会非常长, 长到足够爆了函数栈【译注:想象一下一条光线在一个镜子材质的密封的盒子(并不吸收光线)中反复折射, 永无尽头】。为了避免这种情况的发生, 我们使用一个变量depth限制递归层数。当递归层数达到限制值时我们终止递归, 返回黑色:【译注: 可以试试返回纯红(1,0,0), 然后渲染一下, 大致看一下是哪里在不停的发生散射】 main.cc diff12345678910111213141516171819202122232425262728293031323334353637383940+vec3 ray_color(const ray&amp; r, const hittable&amp; world, int depth) {+ hit_record rec;+ // If we've exceeded the ray bounce limit, no more light is gathered.+ if (depth &lt;= 0)+ return vec3(0,0,0);+ if (world.hit(r, 0, infinity, rec)) {+ vec3 target = rec.p + rec.normal + random_in_unit_sphere();+ return 0.5 * ray_color(ray(rec.p, target - rec.p), world, depth-1); } vec3 unit_direction = unit_vector(r.direction()); auto t = 0.5*(unit_direction.y() + 1.0); return (1.0-t)*vec3(1.0, 1.0, 1.0) + t*vec3(0.5, 0.7, 1.0);}...int main() { const int image_width = 200; const int image_height = 100; const int samples_per_pixel = 100;+ const int max_depth = 50; ... for (int j = image_height-1; j &gt;= 0; --j) { std::cerr &lt;&lt; &quot;\\rScanlines remaining: &quot; &lt;&lt; j &lt;&lt; ' ' &lt;&lt; std::flush; for (int i = 0; i &lt; image_width; ++i) { vec3 color(0, 0, 0); for (int s = 0; s &lt; samples_per_pixel; ++s) { auto u = (i + random_double()) / image_width; auto v = (j + random_double()) / image_height; ray r = cam.get_ray(u, v);+ color += ray_color(r, world, max_depth); } color.write_color(std::cout, samples_per_pixel); } } std::cerr &lt;&lt; &quot;\\nDone.\\n&quot;;} 我们会得到: 注意球下面是有影子的。这个图片非常的暗, 但是我们的球在散射的时候只吸收了一半的能量。如果你看不见这个阴影, 别担心, 我们现在来修复一下。现实世界中的这个球明显是应该更加亮一些的。这是因为所有的看图软件都默认图像已经经过了伽马校正(gamma corrected)。即在图片存入字节之前, 颜色值发生了一次转化。这么做有许多好处, 但这并不是我们这里所讨论的重点。我们使用”gamma 2”空间, 就意味着最终的颜色值要加上指数$1/gamma$, 在我们的例子里就是 ½, 即开平方根: vec.h12345678910111213void write_color(std::ostream &amp;out, int samples_per_pixel) { // Divide the color total by the number of samples and gamma-correct // for a gamma value of 2.0. auto scale = 1.0 / samples_per_pixel; auto r = sqrt(scale * e[0]); auto g = sqrt(scale * e[1]); auto b = sqrt(scale * e[2]); // Write the translated [0,255] value of each color component. out &lt;&lt; static_cast&lt;int&gt;(256 * clamp(r, 0.0, 0.999)) &lt;&lt; ' ' &lt;&lt; static_cast&lt;int&gt;(256 * clamp(g, 0.0, 0.999)) &lt;&lt; ' ' &lt;&lt; static_cast&lt;int&gt;(256 * clamp(b, 0.0, 0.999)) &lt;&lt; '\\n';} 好了, 现在看上去更灰了, 如我们所愿: 这里还有个不太重要的潜在bug。有些物体反射的光线会在$t=0$时再次击中自己。然而由于精度问题, 这个值可能是$t=-0.000001$或者是$t=0.0000000001$或者任意接近0的浮点数。所以我们要忽略掉0附近的一部分范围, 防止物体发出的光线再次与自己相交。【译注: 小心自相交问题】 main.cc1if (world.hit(r, 0.001, infinity, rec)) { 这样我们就能避免阴影痤疮(shadow ance)的产生。是滴, 这种现象的确是叫这个名字。 拒绝法生成的点是单位球体积内的的随机点, 这样生成的向量大概率上会和法线方向相近, 并且极小概率会沿着入射方向反射回去。这个分布律的表达式有一个$\\cos^3 (\\phi)$的系数, 其中 $\\phi$ 是反射光线距离法向量的夹角。这样当光线从一个离表面很小的角度射入时, 也会散射到一片很大的区域, 对最终颜色值的影响也会更低。 然而, 事实上的lambertian的分布律并不是这样的, 它的系数是$\\cos (\\phi)$。真正的lambertian散射后的光线距离法相比较近的概率会更高, 但是分布律会更加均衡。这是因为我们选取的是单位球面上的点。我们可以通过在单位球内选取一个随机点, 然后将其单位化来获得该点。【译注: 然而下面的代码却用了极坐标的形式】 vec3.h123456vec3 random_unit_vector() { auto a = random_double(0, 2*pi); auto z = random_double(-1, 1); auto r = sqrt(1 - z*z); return vec3(r*cos(a), r*sin(a), z);} 我们使用新函数random_unit_vector()替换现存的random_unit_sphere(): main.cc12345678910111213141516vec3 ray_color(const ray&amp; r, const hittable&amp; world, int depth) { hit_record rec; // If we've exceeded the ray bounce limit, no more light is gathered. if (depth &lt;= 0) return vec3(0,0,0); if (world.hit(r, 0.001, infinity, rec)) { vec3 target = rec.p + rec.normal + random_unit_vector(); return 0.5 * ray_color(ray(rec.p, target - rec.p), world, depth-1); } vec3 unit_direction = unit_vector(r.direction()); auto t = 0.5*(unit_direction.y() + 1.0); return (1.0-t)*vec3(1.0, 1.0, 1.0) + t*vec3(0.5, 0.7, 1.0);} 我们会得到这样的图片, 和之前很相像: 我们的场景太简单, 区分这两种方法是比较难的。但你应该能够注意到视觉上的一些差异: 1.阴影部分少了2.大球和小球都变亮了 这些变化都是由散射光线的单位规整化引起的, 现在更少的光线会朝着发现方向散射。对于漫发射的物体来说, 他们会变得更亮。因为更多光线朝着摄像机反射。对于阴影部分来说, 更少的光线朝上反射, 所以小球下方的大球区域会变得更加明亮。 这本书很长一段时间都采用的是先前的版本, 直到后来有一天大家发现它其实只是理想lambertian漫发射的近似, 其并不正确。这个错误在本书中留存了那么长时间, 主要是因为: 1.概率分布的数学证明算错了2.视觉上来说, 并不能直接看出$\\cos (\\phi)$的概率分配是我们所需要的 因为大家日常生活中的物体都是发生了完美的漫反射, 所以我们很难养成对光照下物体是如何表现的视觉直觉。 为了便于大家理解, 简单来说两种方法都选取了一个随机方向的向量, 不过一种是从单位球体内取的, 其长度是随机的, 另一种是从单位球面上取的, 长度固定为单位向量长度。为什么要采取单位球面并不是能很直观的一眼看出。 另一种具有启发性的方法是, 直接从入射点开始选取一个随机的方向, 然后再判断是否在法向量所在的那个半球。在使用lambertian漫发射模型前, 早期的光线追踪论文中大部分使用的都是这个方法: vec3.h1234567vec3 random_in_hemisphere(const vec3&amp; normal) { vec3 in_unit_sphere = random_in_unit_sphere(); if (dot(in_unit_sphere, normal) &gt; 0.0) // In the same hemisphere as the normal return in_unit_sphere; else return -in_unit_sphere;} 将我们的新函数套入ray_color()函数: main.cc12345678910111213141516vec3 ray_color(const ray&amp; r, const hittable&amp; world, int depth) { hit_record rec; // If we've exceeded the ray bounce limit, no more light is gathered. if (depth &lt;= 0) return vec3(0,0,0); if (world.hit(r, 0.001, infinity, rec)) { vec3 target = rec.p + random_in_hemisphere(rec.normal); return 0.5 * ray_color(ray(rec.p, target - rec.p), world, depth-1); } vec3 unit_direction = unit_vector(r.direction()); auto t = 0.5*(unit_direction.y() + 1.0); return (1.0-t)*vec3(1.0, 1.0, 1.0) + t*vec3(0.5, 0.7, 1.0);} 我们会得到如下的图片: 我们的场景会随着本书的深入会变得越来越复杂。这里鼓励大家在之后都试一下这几种不同的漫反射渲染法。大多数场景都会有许多的漫反射材质。你可以从中培养出你对这几种方法的敏感程度。 9. 金属材质如果我们想让不同的物体能拥有不同的材质, 我们又面临着一个设计上的抉择。我们可以设计一个宇宙无敌大材质, 这个材质里面有数不胜数的参数和材质类型可供选择。这样其实也不错, 但我们还可以设计并封装一个抽象的材质类。我反正喜欢后面一种, 对于我们的程序来说, 一个材质类应该封装两个功能进去: 1.生成散射后的光线(或者说它吸收了入射光线)2.如果发生散射, 决定光线会变暗多少(attenuate) 下面来看一下这个抽象类: material.h123456class material { public: virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const = 0;}; 我们在函数中使用hit_record作为传入参数, 就可以不用传入一大堆变量了。当然如果你想传一堆变量进去的话也行。这也是个人喜好。当然物体和材质还要能够联系在一起。在C++中你只要告诉编译器, 我们在hit_record里面存了个材质的指针。 hittable.h123456789101112131415161718192021222324252627#ifndef HITTABLE_H#define HITTABLE_H#include &quot;rtweekend.h&quot;#include &quot;ray.h&quot;class material;struct hit_record { vec3 p; vec3 normal; shared_ptr&lt;material&gt; mat_ptr; double t; bool front_face; inline void set_face_normal(const ray&amp; r, const vec3&amp; outward_normal) { front_face = dot(r.direction(), outward_normal) &lt; 0; normal = front_face ? outward_normal :-outward_normal; }};class hittable { public: virtual bool hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const = 0;};#endif 光线会如何与表面交互是由具体的材质所决定的。hit_record在设计上就是为了把一堆要传的参数给打包在了一起。当光线射入一个表面(比如一个球体), hit_record中的材质指针会被球体的材质指针所赋值, 而球体的材质指针是在main()函数中构造时传入的。当color()函数获取到hit_record时, 他可以找到这个材质的指针, 然后由材质的函数来决定光线是否发生散射, 怎么散射。 所以我们必须在球体的构造函数和变量区域中加入材质指针, 以便之后传给hit_record。见下面高亮的代码行: sphere.h diff1234567891011121314151617181920212223242526272829303132333435363738394041424344class sphere: public hittable { public: sphere() {}+ sphere(vec3 cen, double r, shared_ptr&lt;material&gt; m)+ : center(cen), radius(r), mat_ptr(m) {}; virtual bool hit(const ray&amp; r, double tmin, double tmax, hit_record&amp; rec) const; public: vec3 center; double radius;+ shared_ptr&lt;material&gt; mat_ptr;};bool sphere::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const { vec3 oc = r.origin() - center; auto a = r.direction().length_squared(); auto half_b = dot(oc, r.direction()); auto c = oc.length_squared() - radius*radius; auto discriminant = half_b*half_b - a*c; if (discriminant &gt; 0) { auto root = sqrt(discriminant); auto temp = (-half_b - root)/a; if (temp &lt; t_max &amp;&amp; temp &gt; t_min) { rec.t = temp; rec.p = r.at(rec.t); vec3 outward_normal = (rec.p - center) / radius; rec.set_face_normal(r, outward_normal); rec.mat_ptr = mat_ptr; return true; } temp = (-half_b + root) / a; if (temp &lt; t_max &amp;&amp; temp &gt; t_min) { rec.t = temp; rec.p = r.at(rec.t); vec3 outward_normal = (rec.p - center) / radius; rec.set_face_normal(r, outward_normal);+ rec.mat_ptr = mat_ptr; return true; } } return false;} 对于我们之前写过的Lambertian(漫反射)材质来说, 这里有两种理解方法, 要么是光线永远发生散射, 每次散射衰减至R, 要么是光线并不衰减, 转而物体吸收(1-R)的光线。你也可以当成是这两种的结合。于是我们可以写出Lambertian的材质类: material.h12345678910111213141516class lambertian : public material { public: lambertian(const vec3&amp; a) : albedo(a) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { vec3 scatter_direction = rec.normal + random_unit_vector(); scattered = ray(rec.p, scatter_direction); attenuation = albedo; return true; } public: vec3 albedo;}; 注意我们也可以让光线根据一定的概率$p$发生散射【译注: 若判断没有散射, 光线直接消失】, 并使光线的衰减率(代码中的attenuation)为$albedo/p$。随你的喜好来。 对于光滑的金属材质来说, 光线是不会像漫反射那样随机散射的, 而是产生反射。关键是:对于一个金属状的镜子, 光线具体是怎么反射的呢?向量数学是我们的好朋友: 反射方向的向量如图所示为$\\vec{V}+2\\vec{B}$, 其中我们规定向量$\\vec{N}$是单位向量, 但$\\vec{V}$不一定是。向量B的长度应为$\\vec{V}\\cdot\\vec{N}$, 因为向量$\\vec{V}$与向量$\\vec{N}$的方向相反, 这里我们需要再加上一个负号, 于是有: vec3.h123vec3 reflect(const vec3&amp; v, const vec3&amp; n) { return v - 2*dot(v,n)*n;} 金属材质使用上面的公式来计算反射方向: material.h12345678910111213141516class metal : public material { public: metal(const vec3&amp; a) : albedo(a) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { vec3 reflected = reflect(unit_vector(r_in.direction()), rec.normal); scattered = ray(rec.p, reflected); attenuation = albedo; return (dot(scattered.direction(), rec.normal) &gt; 0); } public: vec3 albedo;}; 我们还需要修改一下color函数: main.cc diff12345678910111213141516171819vec3 ray_color(const ray&amp; r, const hittable&amp; world, int depth) { hit_record rec; // If we've exceeded the ray bounce limit, no more light is gathered. if (depth &lt;= 0) return vec3(0,0,0); if (world.hit(r, 0.001, infinity, rec)) {+ ray scattered;+ vec3 attenuation;+ if (rec.mat_ptr-&gt;scatter(r, rec, attenuation, scattered))+ return attenuation * ray_color(scattered, world, depth-1);+ return vec3(0,0,0); } vec3 unit_direction = unit_vector(r.direction()); auto t = 0.5*(unit_direction.y() + 1.0); return (1.0-t)*vec3(1.0, 1.0, 1.0) + t*vec3(0.5, 0.7, 1.0);} 现在我们给场景加入一些金属球: main.cc diff123456789101112131415161718192021222324252627282930313233343536int main() { const int image_width = 200; const int image_height = 100; const int samples_per_pixel = 100; const int max_depth = 50; std::cout &lt;&lt; &quot;P3\\n&quot; &lt;&lt; image_width &lt;&lt; &quot; &quot; &lt;&lt; image_height &lt;&lt; &quot;\\n255\\n&quot;;+ hittable_list world;+ world.add(make_shared&lt;sphere&gt;(+ vec3(0,0,-1), 0.5, make_shared&lt;lambertian&gt;(vec3(0.7, 0.3, 0.3))));++ world.add(make_shared&lt;sphere&gt;(+ vec3(0,-100.5,-1), 100, make_shared&lt;lambertian&gt;(vec3(0.8, 0.8, 0.0))));+ world.add(make_shared&lt;sphere&gt;(vec3(1,0,-1), 0.5, make_shared&lt;metal&gt;(vec3(0.8, 0.6, 0.2))));+ world.add(make_shared&lt;sphere&gt;(vec3(-1,0,-1), 0.5, make_shared&lt;metal&gt;(vec3(0.8, 0.8, 0.8)))); camera cam; for (int j = image_height-1; j &gt;= 0; --j) { std::cerr &lt;&lt; &quot;\\rScanlines remaining: &quot; &lt;&lt; j &lt;&lt; ' ' &lt;&lt; std::flush; for (int i = 0; i &lt; image_width; ++i) { vec3 color(0, 0, 0); for (int s = 0; s &lt; samples_per_pixel; ++s) { auto u = (i + random_double()) / image_width; auto v = (j + random_double()) / image_height; ray r = cam.get_ray(u, v); color += ray_color(r, world, max_depth); } color.write_color(std::cout, samples_per_pixel); } } std::cerr &lt;&lt; &quot;\\nDone.\\n&quot;;} 我们就能得到这样的图片: 我们还可以给反射方向加入一点点随机性, 只要在算出反射向量后, 在其终点为球心的球内随机选取一个点作为最终的终点: 当然这个球越大, 金属看上去就更加模糊(fuzzy, 或者说粗糙)。所以我们这里引入一个变量来表示模糊的程度(fuzziness)(所以当fuzz=0时不会产生模糊)。如果fuzz, 也就是随机球的半径很大, 光线可能会散射到物体内部去。这时候我们可以认为物体吸收了光线。 material.h diff1234567891011121314151617class metal : public material { public:+ metal(const vec3&amp; a, double f) : albedo(a), fuzz(f &lt; 1 ? f : 1) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { vec3 reflected = reflect(unit_vector(r_in.direction()), rec.normal);+ scattered = ray(rec.p, reflected + fuzz*random_in_unit_sphere()); attenuation = albedo; return (dot(scattered.direction(), rec.normal) &gt; 0);//dot&lt;0我们认为吸收 } public: vec3 albedo;+ double fuzz;}; 我们可以将模糊值设置为0.3和1.0, 图片会变成这样: 10. 绝缘体材质透明的材料, 例如水, 玻璃, 和钻石都是绝缘体。当光线击中这类材料时, 一条光线会分成两条, 一条发生反射, 一条发生折射。我们会采取这样的策略: 每次光线与物体相交时, 要么反射要么折射, 一次只发生一种情况,随机选取。反正最后采样次数多, 会给这些结果取个平均值。 折射部分是最难去debug的部分。我常常一开始让所有的光线只发生折射来调试。在这个项目中, 我加入了两个这样的玻璃球, 并且得到下图(我还没教你怎么弄出这样的玻璃球, 你先往下读, 一会儿你就知道了): 这图看上去是对的么? 玻璃球在现实世界中看上去和这差不多。但是, 其实这图不对。玻璃球应该会翻转上下, 也不会有这种奇怪的黑圈。我输出了图片中心的一条光线来debug, 发现它完全错了, 你调试的时候也可以这样来。 折射法则是由Snell法则定义的: $$ \\eta \\cdot \\sin\\theta = \\eta’ \\cdot \\sin\\theta’ $$ $\\theta$与$\\theta’$是入射光线与折射光线距离法相的夹角,$\\eta$与$\\eta’$(读作eta和eta prime)是介质的折射率(规定空气为1.0, 玻璃为1.3-1.7,钻石为2.4), 如图: 为了解出折射光线的方向, 我们需要解出$\\sin\\theta$: $$ \\sin\\theta’ = \\frac{\\eta}{\\eta’} \\cdot \\sin\\theta $$ 在折射介质部分有射线光线$\\mathbf{R’}$与法向量$\\mathbf{N’}$, 它们的夹角为$\\theta’$。我们可以把光线$\\mathbf{R’}$分解成垂直和水平与法向量$\\mathbf{N’}$的两个向量: $$ \\mathbf{R’} = \\mathbf{R’}{\\parallel} + \\mathbf{R’}{\\bot} $$ 如果要解出这两个向量, 有: $$ \\mathbf{R’}_{\\parallel} = \\frac{\\eta}{\\eta’} (\\mathbf{R} + \\cos\\theta \\mathbf{N}) $$ $$ \\mathbf{R’}{\\bot} = -\\sqrt{1 - |\\mathbf{R’}{\\parallel}|^2} \\mathbf{N} $$ 你可以自己推导,证明。我们这里先直接拿来当结论用了。这本书有些别的地方也是, 并不需要你完全会证明。【译注: 自己推推也没坏处】 然后我们来解$\\cos\\theta$, 下面是著名的点乘的公式定义: $$ \\mathbf{A} \\cdot \\mathbf{B} = |\\mathbf{A}| |\\mathbf{B}| \\cos\\theta $$ 如果我们将$\\mathbf{A}$与$\\mathbf{B}$归一化为单位向量: $$ \\mathbf{A} \\cdot \\mathbf{B} = \\cos\\theta $$ 于是我们可以这样表达垂直的那个向量: $$ \\mathbf{R’}_{\\parallel} = \\frac{\\eta}{\\eta’} (\\mathbf{R} + (\\mathbf{-R} \\cdot \\mathbf{N}) \\mathbf{N}) $$ 根据上述公式, 我们就能写出计算折射光线$\\mathbf{R’}$的函数: vec3.h123456vec3 refract(const vec3&amp; uv, const vec3&amp; n, double etai_over_etat) { auto cos_theta = dot(-uv, n); vec3 r_out_parallel = etai_over_etat * (uv + cos_theta*n); vec3 r_out_perp = -sqrt(1.0 - r_out_parallel.length_squared()) * n; return r_out_parallel + r_out_perp;} 一个只会发生折射的绝缘体材质为: material.h1234567891011121314151617181920212223class dielectric : public material { public: dielectric(double ri) : ref_idx(ri) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { attenuation = vec3(1.0, 1.0, 1.0); double etai_over_etat; if (rec.front_face) { etai_over_etat = 1.0 / ref_idx; } else { etai_over_etat = ref_idx; } vec3 unit_direction = unit_vector(r_in.direction()); vec3 refracted = refract(unit_direction, rec.normal, etai_over_etat); scattered = ray(rec.p, refracted); return true; } double ref_idx;}; 现在看上去图好像不太对, 这是因为当光线从高折射律介质射入低折射率介质时, 对于上述的Snell方程可能没有实解【$\\sin\\theta&gt;1$】。这时候就不会发生折射, 所以就会出现许多小黑点。我们回头看一下snell法则的式子: $$ \\sin\\theta’ = \\frac{\\eta}{\\eta’} \\cdot \\sin\\theta $$ 如果光线从玻璃($\\eta = 1.5$)射入空气($\\eta = 1.0$) $$ \\sin\\theta’ = \\frac{1.5}{1.0} \\cdot \\sin\\theta $$ 又因为$\\sin\\theta’$是不可能比1大的,所以一旦这种情况发生了: $$ \\frac{1.5}{1.0} \\cdot \\sin\\theta &gt; 1.0 $$ 那就完蛋了, 方程无解了。所以我们认为光线无法发生折射的时候, 他发生了反射: material.h12345678if(etai_over_etat * sin_theta &gt; 1.0) { // Must Reflect ...}else { // Can Refract ...} 这里所有的光线都不发生折射, 转而发生了反射。因为这种情况常常在实心物体的内部发生, 所以我们称这种情况被称为”全内反射”。这也当你浸入水中时, 你发现水与空气的交界处看上去像一面镜子的原因。 我们可以用三角函数解出sin_theta $$ \\sin\\theta = \\sqrt{1 - \\cos^2\\theta} $$ 其中的cos_theta为 $$ \\cos\\theta = \\mathbf{R} \\cdot \\mathbf{N} $$ material.h12345678910double cos_theta = ffmin(dot(-unit_direction, rec.normal), 1.0);double sin_theta = sqrt(1.0 - cos_theta*cos_theta);if(etai_over_etat * sin_theta &gt; 1.0) { // Must Reflect ...}else { // Can Refract ...} 一个在可以偏折的情况下总是偏折, 其余情况发生反射的绝缘体材质为: material.h diff123456789101112131415161718192021222324252627class dielectric : public material { public: dielectric(double ri) : ref_idx(ri) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { attenuation = vec3(1.0, 1.0, 1.0); double etai_over_etat = (rec.front_face) ? (1.0 / ref_idx) : (ref_idx); vec3 unit_direction = unit_vector(r_in.direction());+ double cos_theta = ffmin(dot(-unit_direction, rec.normal), 1.0);+ double sin_theta = sqrt(1.0 - cos_theta*cos_theta);+ if (etai_over_etat * sin_theta &gt; 1.0 ) {+ vec3 reflected = reflect(unit_direction, rec.normal);+ scattered = ray(rec.p, reflected);+ return true;+ }+ vec3 refracted = refract(unit_direction, rec.normal, etai_over_etat);+ scattered = ray(rec.p, refracted);+ return true; } public: double ref_idx;}; 这里的光线衰减率为1——就是不衰减, 玻璃表面不吸收光的能量。如果我们使用下面的参数: main.cc12345678world.add(make_shared&lt;sphere&gt;( vec3(0,0,-1), 0.5, make_shared&lt;lambertian&gt;(vec3(0.1, 0.2, 0.5))));world.add(make_shared&lt;sphere&gt;( vec3(0,-100.5,-1), 100, make_shared&lt;lambertian&gt;(vec3(0.8, 0.8, 0.0))));world.add(make_shared&lt;sphere&gt;(vec3(1,0,-1), 0.5, make_shared&lt;metal&gt;(vec3(0.8, 0.6, 0.2), 0.0)));world.add(make_shared&lt;sphere&gt;(vec3(-1,0,-1), 0.5, make_shared&lt;dielectric&gt;(1.5))); 我们会得到: 现实世界中的玻璃, 发生折射的概率会随着入射角而改变——从一个很狭窄的角度去看玻璃窗, 它会变成一面镜子。这个式子又丑又长, 好在我们有个数学上近似的等式, 它是由Christophe Schlick提出的: 12345double schlick(double cosine, double ref_idx) { auto r0 = (1-ref_idx) / (1+ref_idx); r0 = r0*r0; return r0 + (1-r0)*pow((1 - cosine),5);} 下面就是我们完整版的玻璃材质: material.h diff123456789101112131415161718192021222324252627282930313233class dielectric : public material { public: dielectric(double ri) : ref_idx(ri) {} virtual bool scatter( const ray&amp; r_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered ) const { attenuation = vec3(1.0, 1.0, 1.0); double etai_over_etat = (rec.front_face) ? (1.0 / ref_idx) : (ref_idx); vec3 unit_direction = unit_vector(r_in.direction()); double cos_theta = ffmin(dot(-unit_direction, rec.normal), 1.0); double sin_theta = sqrt(1.0 - cos_theta*cos_theta); if (etai_over_etat * sin_theta &gt; 1.0 ) { vec3 reflected = reflect(unit_direction, rec.normal); scattered = ray(rec.p, reflected); return true; }+ double reflect_prob = schlick(cos_theta, etai_over_etat);+ if (random_double() &lt; reflect_prob)+ {+ vec3 reflected = reflect(unit_direction, rec.normal);+ scattered = ray(rec.p, reflected);+ return true;+ } vec3 refracted = refract(unit_direction, rec.normal, etai_over_etat); scattered = ray(rec.p, refracted); return true; } public: double ref_idx;}; 这里有个简单又好用的trick, 如果你将球的半径设为负值, 形状看上去并没什么变化, 但是法相全都翻转到内部去了。所以就可以用这个特性来做出一个通透的玻璃球:【把一个小球套在大球里, 光线发生两次折射, 于是负负得正, 上下不会颠倒】 123456world.add(make_shared&lt;sphere&gt;(vec3(0,0,-1), 0.5, make_shared&lt;lambertian&gt;(vec3(0.1, 0.2, 0.5))));world.add(make_shared&lt;sphere&gt;( vec3(0,-100.5,-1), 100, make_shared&lt;lambertian&gt;(vec3(0.8, 0.8, 0.0))));world.add(make_shared&lt;sphere&gt;(vec3(1,0,-1), 0.5, make_shared&lt;metal&gt;(vec3(0.8, 0.6, 0.2), 0.3)));world.add(make_shared&lt;sphere&gt;(vec3(-1,0,-1), 0.5, make_shared&lt;dielectric&gt;(1.5)));world.add(make_shared&lt;sphere&gt;(vec3(-1,0,-1), -0.45, make_shared&lt;dielectric&gt;(1.5))); 就有: 11. 可自定义位置的摄像机摄像机总是和绝缘体一样难以debug。所以我总是一步步搭建我的摄像机类。首先, 我们使摄像机能调整其视野范围(field of view, fov)。fov是你的视角。因为我们的图片不是方的, 所以垂直和水平的fov值是不同的。我总是使用垂直方向的fov。并且我总是使用角度制来传参, 在构造函数中再将其转化为弧度——这也是我的个人喜好。 首先我让射线从原点射向$z=-1$平面。我们当然也可以让其射向$z=-2$的平面,或者其他的什么值都行, 反正$h$和这个距离$d$是成比例的。 显然, $h = \\tan(\\frac{\\theta}{2})$。我们的摄像机类现在变成: camera.h12345678910111213141516171819202122232425262728class camera { public:+ camera(+ double vfov, // top to bottom, in degrees+ double aspect+ ) {+ origin = vec3(0.0, 0.0, 0.0);+ auto theta = degrees_to_radians(vfov);+ auto half_height = tan(theta/2);+ auto half_width = aspect * half_height;++ lower_left_corner = vec3(-half_width, -half_height, -1.0);++ horizontal = vec3(2*half_width, 0.0, 0.0);+ vertical = vec3(0.0, 2*half_height, 0.0);+ } ray get_ray(double u, double v) { return ray(origin, lower_left_corner + u*horizontal + v*vertical - origin); } public: vec3 origin; vec3 lower_left_corner; vec3 horizontal; vec3 vertical;}; 当我们使用一个cam(90, double(image_width)/image_height)的摄像机去拍下面的球: main.cc1234auto R = cos(pi/4);hittable_list world;world.add(make_shared&lt;sphere&gt;(vec3(-R,0,-1), R, make_shared&lt;lambertian&gt;(vec3(0, 0, 1))));world.add(make_shared&lt;sphere&gt;(vec3( R,0,-1), R, make_shared&lt;lambertian&gt;(vec3(1, 0, 0)))); 我们会得到: 为了能将我们的摄像机设置在任意位置, 我们先来给这个位置点起个名字。我们管摄像机所在的这个位置叫做 lookfrom , 我们看向的点叫做lookat(如果你不想用世界坐标下的点, 想用向量来表示这个方向的话也完全ok)。 我们还需要一个变量去描述摄像机的倾斜程度, 或者说摄像机绕着轴lookfrom - lookat旋转的角度【想象下图中红色平面绕这个轴旋转】。就好比你站直了, 但是你的头还是可以左右转动。为了去描述这个倾斜程度, 我们需要一个向量来指定摄像机坐标系的正上方方向(up vector)。这里注意:这个向量就在视线方向正交投影过来的那个平面上: 我们可以使用任意的方向向量, 将其投影到上图的平面中来获得摄像机的up vector。我这里给他起名叫vup向量。经过一系列的点乘操作, 我们会有完整的u,v,w三个向量来描述摄像机的旋向【这里要结合着代码看与下面的图片看】。 注意vup,v,w处于同一平面内。和先前我们的摄像机面对着-Z方向一样, 修改后的任意视角摄像机面对着-w方向。记得使用世界坐标系的上方向向量(0,1,0)(不是一定要用这个向量)指定vup。这样会比较方便, 并且你的摄像机镜头会保持水平。如果你想试试那些奇怪的摄像角度, 你可以放心大胆的传入别的值。 camera.h diff123456789101112131415161718192021222324252627282930313233class camera { public: camera(+ vec3 lookfrom, vec3 lookat, vec3 vup, double vfov, // top to bottom, in degrees double aspect ) {+ origin = lookfrom; vec3 u, v, w; auto theta = degrees_to_radians(vfov); auto half_height = tan(theta/2); auto half_width = aspect * half_height;+ w = unit_vector(lookfrom - lookat);+ u = unit_vector(cross(vup, w));+ v = cross(w, u);+ lower_left_corner = origin - half_width*u - half_height*v - w;+ horizontal = 2*half_width*u;+ vertical = 2*half_height*v; } ray get_ray(double s, double t) { return ray(origin, lower_left_corner + s*horizontal + t*vertical - origin); } public: vec3 origin; vec3 lower_left_corner; vec3 horizontal; vec3 vertical;}; 现在我们就可以改变我们的视角了: main.cc123const auto aspect_ratio = double(image_width) / image_height;...camera cam(vec3(-2,2,1), vec3(0,0,-1), vup, 90, aspect_ratio); 我们会得到: 然后我们在改变一下fov:【这里缩小了fov】 12. 散焦模糊终于到了我们最后的特性了: 散焦模糊(defocus blur)。基本上所有的摄影师都它叫景深(depth of field)。所以你和你朋友聊天的时候可别提什么defocus blur啊。 现实世界中的摄像机产生对焦模糊的原因是因为他们需要一个很大的孔, 而不是一个针眼大小的小孔来聚集光线。这会导致所有的东西都被散焦了。但如果我们在孔内加入一块透镜, 在一段距离内的所有物体都会被对焦。你可以这样来想象透镜:所有的光线从同一点分散射出, 击中透镜后又聚焦在图像传感器上的一个点上。 在现实世界的相机中, 物体在哪里被聚焦是由透镜距离成像平面与聚焦平面这两个平面的距离所决定的。当你改变对焦设置时,相机中的这个透镜位置就会发生改变(你手机上的摄像头也是这个原理, 只不过透镜不动, 改成了成像传感器动)。快门光圈(aperture)是一个孔, 它控制这块透镜应该多大比较好。如果你需要更多的光线, 你的这个快门光圈就大一点, 景深也会随之加大。对于一个虚拟的摄像机来说, 我们只需要一个传感器就够了。所以我们只需要传入快门光圈的大小就行【即透镜大小】。 现实世界中的摄像机的透镜组是很复杂的。但对于我们写代码来说, 我们只需要模拟上述的顺序: 图像传感器, 透镜, 快门, 然后射出光线, 最后记得翻转图片(进过透镜成像会被上下翻转)。图形学中人们常常使用一块薄片透镜近似模拟: 但是我们根本不用模拟任何摄像机内部的东西, 对于我们渲染摄像机外的物体来说, 这些都没必要。我们只要从一个虚拟的透镜范围中发射光线到我们的摄像机平面就能模拟了,这个透镜与平面的距离成为焦距(focus_dist) 之前我们所有的光线都是从lookfrom发出的, 但现在加入了散焦模糊, 所有光线都从内部的一个虚拟透镜发出, 经过lookfrom点, 这个透镜的半径越大, 图像就越模糊。你可以认为之前的摄像机, 这个半径为0。 vec3.h 从一个单位小圆盘射出光线1234567vec3 random_in_unit_disk() { while (true) { auto p = vec3(random_double(-1,1), random_double(-1,1), 0); if (p.length_squared() &gt;= 1) continue; return p; }} 下面给出完整的camera类 camera.h diff1234567891011121314151617181920212223242526272829303132333435363738394041424344class camera { public: camera( vec3 lookfrom, vec3 lookat, vec3 vup, double vfov, // top to bottom, in degrees+ double aspect, double aperture, double focus_dist+ ) {+ origin = lookfrom;+ lens_radius = aperture / 2; auto theta = degrees_to_radians(vfov); auto half_height = tan(theta/2); auto half_width = aspect * half_height; w = unit_vector(lookfrom - lookat); u = unit_vector(cross(vup, w)); v = cross(w, u);+ lower_left_corner = origin+ - half_width * focus_dist * u+ - half_height * focus_dist * v+ - focus_dist * w;+ horizontal = 2*half_width*focus_dist*u;+ vertical = 2*half_height*focus_dist*v; } ray get_ray(double s, double t) {+ vec3 rd = lens_radius * random_in_unit_disk();+ vec3 offset = u * rd.x() + v * rd.y();+ return ray(+ origin + offset,+ lower_left_corner + s*horizontal + t*vertical - origin - offset+ ); } public: vec3 origin; vec3 lower_left_corner; vec3 horizontal; vec3 vertical;+ vec3 u, v, w;+ double lens_radius;}; 我们使用一个大大的快门光圈: main.cc123456789const auto aspect_ratio = double(image_width) / image_height;...vec3 lookfrom(3,3,2);vec3 lookat(0,0,-1);vec3 vup(0,1,0);auto dist_to_focus = (lookfrom-lookat).length();auto aperture = 2.0;camera cam(lookfrom, lookat, vup, 20, aspect_ratio, aperture, dist_to_focus); 就有: 13. 接下来学什么?首先我们把书的封面图——许多许多的随机球渲染出来: main.cc12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455hittable_list random_scene() { hittable_list world; world.add(make_shared&lt;sphere&gt;( vec3(0,-1000,0), 1000, make_shared&lt;lambertian&gt;(vec3(0.5, 0.5, 0.5)))); int i = 1; for (int a = -11; a &lt; 11; a++) { for (int b = -11; b &lt; 11; b++) { auto choose_mat = random_double(); vec3 center(a + 0.9*random_double(), 0.2, b + 0.9*random_double()); if ((center - vec3(4, 0.2, 0)).length() &gt; 0.9) { if (choose_mat &lt; 0.8) { // diffuse auto albedo = vec3::random() * vec3::random(); world.add( make_shared&lt;sphere&gt;(center, 0.2, make_shared&lt;lambertian&gt;(albedo))); } else if (choose_mat &lt; 0.95) { // metal auto albedo = vec3::random(.5, 1); auto fuzz = random_double(0, .5); world.add( make_shared&lt;sphere&gt;(center, 0.2, make_shared&lt;metal&gt;(albedo, fuzz))); } else { // glass world.add(make_shared&lt;sphere&gt;(center, 0.2, make_shared&lt;dielectric&gt;(1.5))); } } } } world.add(make_shared&lt;sphere&gt;(vec3(0, 1, 0), 1.0, make_shared&lt;dielectric&gt;(1.5))); world.add( make_shared&lt;sphere&gt;(vec3(-4, 1, 0), 1.0, make_shared&lt;lambertian&gt;(vec3(0.4, 0.2, 0.1)))); world.add( make_shared&lt;sphere&gt;(vec3(4, 1, 0), 1.0, make_shared&lt;metal&gt;(vec3(0.7, 0.6, 0.5), 0.0))); return world;}int main() { ... auto world = random_scene(); vec3 lookfrom(13,2,3); vec3 lookat(0,0,0); vec3 vup(0,1,0); auto dist_to_focus = 10.0; auto aperture = 0.1; camera cam(lookfrom, lookat, vup, 20, aspect_ratio, aperture, dist_to_focus); ...} 我们会得到: 你可能会发现玻璃球没有阴影, 使得他们看上去像漂浮在空中似得。这不是bug(你在现实世界中很少有机会见到真正的玻璃球, 它们看起来的确就是这样的)。玻璃球下的那个作为地板的大球仍然能被那么多光线击中, 玻璃球下的那个作为地板的大球仍然能被那么多光线击中, 因为光线并不会被玻璃球阻挡，经由玻璃球的折射最终射向天空。【the sky is re-ordered rather than blocked. 感谢评论区Kanichiyaoba 的翻译解答】 现在你拥有一个coooool毙了的光线追踪器了! 那接下来我该何去何从呢?【标*为下本书中的内容】 1.光照。你可以使用阴影光线来显式实现这部分, 也可以使用产生光线的材质来隐式实现*。 2.偏移散射光线, 然后降低这些光线的权重来消除偏移。这两种都行。硬要说的话, 我偏向后者一点点。【我猜这句话是在说消除自相交所导致的阴影 即Shadow Ance, 如果有人知道这是在说什么请教教我吧！】 3.加入三角形。大部分模型都是三角网格。模型的IO部分是最恶心的, 基本上所有人都不想自己写, 都去找别人的代码用。 4.表面纹理*。这可以让你像贴墙纸一样把图片贴到物体上去。实现起来也很简单。 5.固体纹理*。可以参见Ken Perlin的在线代码, Andrew Kensler的blog中也有关于这部分的信息。 6.体积体(volumes 即雾等)*与其他介质。很Cool, 但是会改变你的代码构筑。我喜欢把体积体也设计成hittable的子类, 根据其密度来随机决定光线是否与其相交。使用这个方法, 你的渲染器甚至不用知道你渲的是体积体就渲出来了。 7.并行优化。使用不同的随机种子, 把你的代码复制上$N$份跑在$N$个核心上,然后再求平均值。你可以分层来完成这部分工作, 比如分成$N/2$对, 每次平均求出$N/4$【为什么是N/4啊？？这翻译翻不下去了！】的图片, 然后在对这些对之间求平均值。这应该用不了多少代码【试试CUDA吧】。 记得把你渲染出的炫酷图片发给我!祝你愉快!","link":"/Graphic/ray-tracing-in-one-weekend/"},{"title":"当我们自签名时，我们其实是在做什么","text":"摘自自己计网的实验报告 为了确保自己是真的理解了密码学相关的一些内容，而不是简单的调用OpenSSL生成两个文件糊上去用，我在这里写一下自己对这方面的理解，从下面这些名词逐步深入： 对称加密：保证机密性 一个经典的例子 凯撒加密 典型算法：3DES AES。 散列函数：保证消息的完整性 SHA-1 MD5 等 非对称性加密：非对称性加密是用来解决对称加密中秘钥传输的痛点的。它的机密性是由数学上的复杂度决定的，比如RSA是质数分解。在数学上目前没什么很快的方法（不代表以后没有，或者直接绕过质数分解的破解RSA的方法）。其算法实现中的随机数生成，暴力位数破解或者暴力质数分解都是可以攻击的地方。 非对称加密的缺点是太慢了，比如RSA，又是幂运算又取mod，于是我们可以用非对称加密传对称加密的私钥，对于消息本身还是使用对称加密。 不管对于对称加密还是非对称加密来说，算法+时间=明文，就看信息的价值，值不值得花这个时间。即信息的时效性失效前能否破解。 数字签名：plain text+signature，实质上是非对称加密的一种应用，签名=加密，验证=解密，和消息传输正好反过来。它可以保证消息来源可靠，可以拒绝否认，但不保证机密性（课上对这个地方产生了疑问，后来想通了）。假如你去签消息的散列值，豁豁，不仅签的快了，签名短了，还可以保证消息的完整性。 证书：非对称加密（包括数字签名）虽然解决了秘钥分发问题，但还有一个致命弱点，就是中间者攻击，或者说你拿到的公钥到底是不是真的公钥。为了避免这个问题，我们拿可信第三方的私钥给目标公钥签个名，这就是证书。这个第三方我们管它叫CA， 至于CA的公钥可不可信，这就是个套娃问题了。操作系统会预带一些信任的跟证书。 证书的组成：目标公钥 ，CA的一些信息（颁布人，散列算法，有效期）， 用CA的私钥对前面部分的散列值进行的签名 最后是SSL/TLS，基本上就是上述概念的总集合，混用了上述所有的概念。 使用对称加密保证机密性 使用非对称加密解决秘钥分发问题 使用散列函数保证消息不被修改（完整性） 使用证书保证消息来源 另外还有很多降维打击，比如肉身偷私钥啊，收到邮件瞎签名啊。密码学也救不了。 哎，感慨一下，虽然现在理的很清楚，过几个月估计就都忘的一干二净了。 回到正题，当我们给网站自签名的时候，我们其实是在做什么？ 1.生成网站的私钥（公钥可以先不做，后面根据X.509生成证书时，OpenSSL会根据私钥生成） openssl genrsa -out private.key 4096 2.成为一个CA，生成CA的公钥私钥(这里有个野路子：直接拿网站的私钥做CA的私钥，真·自签名。网上很多帖子都是这么做的，也不解释自己做了什么) openssl genrsa -out ca.key 4096 3.生成证书，用CA的私钥对网站公钥进行加密 先使用网站私钥private.key，生成mycsr.csr证书请求文件 openssl req -new -key private.key -out mycsr.csr 这个时候会让你填很多很多信息，我们填个Beijing Foresty University待会验证 然后使用ca私钥ca.key与证书请求mycsr.csr生成ca.crt证书文件(或者说使用ca的私钥对证书进行签名) openssl x509 -req -days 365 -in mycsr.csr -signkey ca.key -out ca.crt 4.把证书提供给用户(见下节) 5.实际访问，用户发起https请求，浏览器开始验证证书是否有效（ca公钥是否可信）。因为我们先前将crt文件导入了浏览器的信任列表，所以我们的证书通过了验证（但域名不同，浏览器还是报了警） 验证有效后，用证书中的网站公钥public.key加密一个对称秘钥，传给网站。 网站自己这边用自己的私钥private.key去解密，之后的消息就用这个秘钥进行对称加密的传输。 验证：我们在windows下打开证书文件，不出意外的话，证书内应该存放着网站的公钥。我们先把private.key的公钥public.key做出来。 openssl rsa -in private.key -out public.key -pubout 再使用在线工具验证一下（证书内公钥的编码格式是ASN.1，而openssl生成的公钥的格式是PKCS8，要转化到同一格式才能对比，这里我选择{N, E}来验证）： 果不其然，两个公钥的N，E吻合，符合预期。 3.配置nginx还是实验一的那个配置文件 1vim /usr/local/nginx/conf/nginx.conf 1234567891011121314151617181920# HTTPS server#server { listen 443 ssl; server_name matrix4f.com; ssl_certificate ../ssl/ca.crt; ssl_certificate_key ../ssl/private.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { root html; index index.html index.htm; }} 记得打开阿里防火墙的443端口 4.为浏览器导入证书Chrome为例， 之后会弹出一个资源浏览器，选中先前生成的crt文件即可导入成功。 5.测试这次的测试就没有那么顺利了。重启nginx不到一分钟就给GFW墙了。又是自签名，我还没备案，难免的。 我的直觉是收到了dns污染，于是写host文件，未果。没办法，只能直接使用IP访问了。 可以看到，哪怕手动添加了证书，我依旧没有得到我的小绿锁。点开证书查看详情，一切正常，只是我的证书是颁发给matrix4f.com的，域名不匹配了。就好比你直接使用IP，通过https://140.82.113.4访问github一样，你会发现github的证书也失效了，也是不受信任的。 我去网上了解了一下，ca都是给域名签名，对ip签名基本上是见不到的。只能做到这步停下来了。备案要等挺长时间，大概两三周，算啦算啦。 最后点开详情，看看我们生成的证书吧。 好歹在IE上还是有小锁的","link":"/Network/self-sign/"},{"title":"使阿里云服务器支持ipv6","text":"App Store的游戏上线需要支持ipv6。我这里使用的是阿里云学生服务器，便宜好用，怎么折腾都不心疼，服务器OS为Ubuntu16.04LTS。顺带一提阿里云有直接支持IPV6并分配了公网IP的服务器，不过价格嘛…… ipv4地址：47.95.210.48 ipv6地址：2001:470:35:81a::2 1.开启ipv6阿里云的ipv6默认关闭，首先打开linux服务器的ipv6功能 vim /etc/sysctl.conf 修改以下三行 123net.ipv6.conf.all.disable_ipv6 = 0net.ipv6.conf.default.disable_ipv6 = 0net.ipv6.conf.lo.disable_ipv6 = 0 重启网络，这时执行ifconfig就能看到网卡的ipv6的IP了。 测试的话，可以自己ping6一下自己，或者ping6一下 ipv6.baidu.com 或者 he.net(或者用桌面版浏览器访问)。如果自己能ping通，v6的域名ping6不通，多半是dns有问题，试着直接ping地址。 我们可以写一下DNS vim /etc/resolv.conf 阿里： 12nameserver 2400:3200::1nameserver 2400:3200:baba::1 谷歌： 12nameserver 2001:4860:4860::8888nameserver 2001:4860:4860::8844 github上好用的ipv6 host表https://github.com/lennylxx/ipv6-hosts 2.搭建隧道咱普通人还是搞不到IPV6的固定公网IP的（蹭学校的IP除外）。但为了能从外网访问，我们需要一个IPV6的公网IP，这里我选择了he.net旗下的 tunnelbroker，架设免费的6in4隧道。 下面是wiki上关于he的介绍 Hurricane Electric是一家位于美国的全球互联网服务提供商。该公司提供IPv4和IPv6接入以及位于美国圣荷西（公司总部地址）的数据中心服务。该公司运营了世界上以对等数目计算的最大IPv6网络。其中大多数是原生IPv6对等会话。该公司也提供免费IPv6隧穿服务，为IPv4用户或无法接入IPv6网络的用户通过隧道提供IPv6服务。该公司提供了针对IPv6教育及培训的证书。 这里我ping了一下，选择了新加坡的节点，可以看到he.net的server v4 与 v6 地址，我们试着从服务器ping一下 可以看到连接稳定 然后我们新建网卡用于我们的6in4隧道 /etc/network/interfaces 加入以下内容，注册网卡，&lt;&gt;内的内容根据你的实际情况变化 12345678910auto he-ipv6iface he-ipv6 inet6 v4tunneladdress &lt;IPv6&gt;::2netmask 64remote &lt;HE Server IPv4&gt;local &lt;阿里云内网 IPv4&gt;endpoint anyttl 255gateway &lt;IPv6&gt;::1down ip -6 route flush dev he-ipv6 重启网络后，可以亲切的看到我们的新网卡： 3.搭建nginx服务器我从nginx官网下载的当时为最新版的nginx1.19.3的tar.gz文件。然后tar -zxvf unzip一下。之后就是配置参数和编译了。我们需要和ipv6和https模块。 12 ./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-ipv6make &amp;&amp; make install 它提示我新版nginx自带v6模块，不用再--with-ipv6了。 然后我们配置一下nginx.conf, 监听一下ipv6的80端口。 1vim /usr/local/nginx/conf/nginx.conf 修改如下 123456server { listen 80; listen [::]:80 ipv6only=on; server_name localhost; ...... 最后记得去阿里云安全组（类似端口防火墙）里面，把80和443（之后要用）出入站规则打开 4.从任意支持v6的设备使用ipv6地址访问我把自己博客的域名拆过来，临时绑个AAAA，绑上了he.net分配给我server的ipv6地址 测试 http://ipv6-test.com/validate.php 直接通过http://[IPV6 HOST]的方式访问或使用域名访问 一个小问题：后来我发现时不时的从外网ping主机v6ping不通，ping he的server却能ping通，即： 1234from a remote hostping 2001:470:35:81a::1 okping 2001:470:35:81a::2 timeover 即he.net与我的阿里服务器的连接断了，我尝试从阿里云的服务器ping 1234from my serverping6 2001:470:35:81a::1 okping6 2001:470:35:81a::2 ok 当然ok，这是在ping自己 而且一旦尝试从服务器去ping he的v6 server后，从外网又能ping通了。说明 2001:470:35:81a::1 到我的服务器的线路又通了。我猜测一段时间我服务器没有往he发包的话，隧道会处于不活跃状态而关闭，于是暴力解之：隔1分钟ping一下 123crontab -e*/1 * * * * ping6 2001:470:35:81a::1 -c 1 &gt;&gt;/ping.log 现在连接就稳定多了。（不过服务器毕竟在海外，还是偶尔会抽风ORZ）","link":"/Network/aliyun-ipv6/"}],"tags":[{"name":"math","slug":"math","link":"/tags/math/"},{"name":"closestpoint","slug":"closestpoint","link":"/tags/closestpoint/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"intersection","slug":"intersection","link":"/tags/intersection/"},{"name":"ray tracing","slug":"ray-tracing","link":"/tags/ray-tracing/"},{"name":"graphic","slug":"graphic","link":"/tags/graphic/"},{"name":"css","slug":"css","link":"/tags/css/"},{"name":"highlight.js","slug":"highlight-js","link":"/tags/highlight-js/"},{"name":"ssl","slug":"ssl","link":"/tags/ssl/"},{"name":"ipv6","slug":"ipv6","link":"/tags/ipv6/"}],"categories":[{"name":"Math","slug":"Math","link":"/categories/Math/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"Web","slug":"Web","link":"/categories/Web/"},{"name":"Graphic","slug":"Graphic","link":"/categories/Graphic/"},{"name":"Geometry","slug":"Math/Geometry","link":"/categories/Math/Geometry/"},{"name":"FrontEnd","slug":"Web/FrontEnd","link":"/categories/Web/FrontEnd/"},{"name":"Network","slug":"Network","link":"/categories/Network/"}]}